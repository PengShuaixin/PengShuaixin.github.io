<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Niclas</title>
  
  <subtitle>Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.niclas.cn/"/>
  <updated>2018-12-24T13:35:14.342Z</updated>
  <id>https://blog.niclas.cn/</id>
  
  <author>
    <name>PengShuaixin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spark中的三种分布式部署方式对比（粗粒度模式、细粒度模式）</title>
    <link href="https://blog.niclas.cn/post/Spark%E4%B8%AD%E7%9A%84%E4%B8%89%E7%A7%8D%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F%E5%AF%B9%E6%AF%94%EF%BC%88%E7%B2%97%E7%B2%92%E5%BA%A6%E6%A8%A1%E5%BC%8F%E3%80%81%E7%BB%86%E7%B2%92%E5%BA%A6%E6%A8%A1%E5%BC%8F%EF%BC%89/"/>
    <id>https://blog.niclas.cn/post/Spark中的三种分布式部署方式对比（粗粒度模式、细粒度模式）/</id>
    <published>2018-12-24T05:39:30.000Z</published>
    <updated>2018-12-24T13:35:14.342Z</updated>
    
    <content type="html"><![CDATA[<p>本文来自<span class="exturl" data-url="aHR0cDovL2Rvbmd4aWNoZW5nLm9yZy8=" title="http://dongxicheng.org/">董的博客<i class="fa fa-external-link"></i></span>,原文地址: <span class="exturl" data-url="aHR0cDovL2Rvbmd4aWNoZW5nLm9yZy9mcmFtZXdvcmstb24teWFybi9hcGFjaGUtc3BhcmstY29tcGFyaW5nLXRocmVlLWRlcGxveWluZy13YXlzLw==" title="http://dongxicheng.org/framework-on-yarn/apache-spark-comparing-three-deploying-ways/">http://dongxicheng.org/framework-on-yarn/apache-spark-comparing-three-deploying-ways/<i class="fa fa-external-link"></i></span></p><hr><p>目前Apache Spark支持三种分布式部署方式，分别是<strong>standalone、spark on mesos和 spark on YARN</strong><br>其中，第一种类似于MapReduce 1.0所采用的模式，内部实现了容错性和资源管理，后两种则是未来发展的趋势，部分容错性和资源管理交由统一的资源管理系统完成：让Spark运行在一个通用的资源管理系统之上，这样可以与其他计算框架，比如MapReduce，公用一个集群资源，最大的好处是降低运维成本和提高资源利用率（资源按需分配）。<br>本文将介绍这三种部署方式，并比较其优缺点。</p><h2 id="standalone模式"><a href="#standalone模式" class="headerlink" title="standalone模式"></a>standalone模式</h2><p>即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。从一定程度上说，该模式是其他两种的基础。借鉴Spark开发模式，我们可以得到一种开发新型计算框架的一般思路：先设计出它的standalone模式，为了快速开发，起初不需要考虑服务（比如:master/slave）的容错性，之后再开发相应的wrapper，将standalone模式下的服务原封不动的部署到资源管理系统yarn或者mesos上，由资源管理系统负责服务本身的容错。目前Spark在standalone模式下是没有任何单点故障问题的，这是借助zookeeper实现的，思想类似于Hbase master单点故障解决方案。将Spark standalone与MapReduce比较，会发现它们两个在架构上是完全一致的：</p><p>1)  都是由master/slaves服务组成的，且起初master均存在单点故障，后来均通过zookeeper解决（Apache MRv1的JobTracker仍存在单点问题，但CDH版本得到了解决）；</p><p>2) 各个节点上的资源被抽象成粗粒度的slot，有多少slot就能同时运行多少task。不同的是，MapReduce将slot分为map slot和reduce slot，它们分别只能供Map Task和Reduce Task使用，而不能共享，这是MapReduce资源利率低效的原因之一，而Spark则更优化一些，它不区分slot类型，只有一种slot，可以供各种类型的Task使用，这种方式可以提高资源利用率，但是不够灵活，不能为不同类型的Task定制slot资源。总之，这两种方式各有优缺点。</p><h2 id="Spark-On-Mesos模式"><a href="#Spark-On-Mesos模式" class="headerlink" title="Spark On Mesos模式"></a>Spark On Mesos模式</h2><p>这是很多公司采用的模式，官方推荐这种模式（当然，原因之一是血缘关系）。正是由于Spark开发之初就考虑到支持Mesos，因此，目前而言，Spark运行在Mesos上会比运行在YARN上更加灵活，更加自然。目前在Spark On Mesos环境中，用户可选择两种调度模式之一运行自己的应用程序（可参考Andrew Xia的“<span class="exturl" data-url="aHR0cDovL3ZkaXNrLndlaWJvLmNvbS9zL3ptX2VJVlAtVHB5cUs=" title="http://vdisk.weibo.com/s/zm_eIVP-TpyqK">Mesos Scheduling Mode on Spark<i class="fa fa-external-link"></i></span>”）：</p><p>1)   <strong>粗粒度模式（Coarse-grained Mode）</strong>：每个应用程序的运行环境由一个Dirver和若干个Executor组成，其中，每个Executor占用若干资源，内部可运行多个Task（对应多少个“slot”）。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中要一直占用这些资源，即使不用，最后程序运行结束后，回收这些资源。举个例子，比如你提交应用程序时，指定使用5个executor运行你的应用程序，每个executor占用5GB内存和5个CPU，每个executor内部设置了5个slot，则Mesos需要先为executor分配资源并启动它们，之后开始调度任务。另外，在程序运行过程中，mesos的master和slave并不知道executor内部各个task的运行情况，executor直接将任务状态通过内部的通信机制汇报给Driver，从一定程度上可以认为，每个应用程序利用mesos搭建了一个虚拟集群自己使用。</p><p>2)   <strong>细粒度模式（Fine-grained Mode）</strong>：鉴于粗粒度模式会造成大量资源浪费，Spark On Mesos还提供了另外一种调度模式：细粒度模式，这种模式类似于现在的云计算，思想是按需分配。与粗粒度模式一样，应用程序启动时，先会启动executor，但每个executor占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos会为每个executor动态分配资源，每分配一些，便可以运行一个新任务，单个Task运行完之后可以马上释放对应的资源。每个Task会汇报状态给Mesos slave和Mesos Master，便于更加细粒度管理和容错，这种调度模式类似于MapReduce调度模式，每个Task完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。</p><h2 id="Spark-On-YARN模式"><a href="#Spark-On-YARN模式" class="headerlink" title="Spark On YARN模式"></a>Spark On YARN模式</h2><p>这是一种最有前景的部署模式。但限于YARN自身的发展，目前仅支持粗粒度模式（Coarse-grained Mode）。这是由于YARN上的Container资源是不可以动态伸缩的，一旦Container启动之后，可使用的资源不能再发生变化，不过这个已经在YARN计划（具体参考：<span class="exturl" data-url="aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9ZQVJOLTExOTfvvInkuK3kuobjgII=" title="https://issues.apache.org/jira/browse/YARN-1197）中了。">https://issues.apache.org/jira/browse/YARN-1197）中了。<i class="fa fa-external-link"></i></span></p><p>总之，这三种分布式部署方式各有利弊，通常需要根据公司情况决定采用哪种方案。进行方案选择时，往往要考虑公司的技术路线（采用Hadoop生态系统还是其他生态系统）、服务器资源（资源有限的话就不要考虑standalone模式了）、相关技术人才储备等。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文来自&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cDovL2Rvbmd4aWNoZW5nLm9yZy8=&quot; title=&quot;http://dongxicheng.org/&quot;&gt;董的博客&lt;i class=&quot;fa fa-external-link&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="Spark" scheme="https://blog.niclas.cn/categories/Spark/"/>
    
    
      <category term="Spark" scheme="https://blog.niclas.cn/tags/Spark/"/>
    
      <category term="粗粒度" scheme="https://blog.niclas.cn/tags/%E7%B2%97%E7%B2%92%E5%BA%A6/"/>
    
      <category term="细粒度" scheme="https://blog.niclas.cn/tags/%E7%BB%86%E7%B2%92%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>IntelliJ IDEA 2018.3常用配置图解</title>
    <link href="https://blog.niclas.cn/post/IntelliJ-IDEA-2018-3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/"/>
    <id>https://blog.niclas.cn/post/IntelliJ-IDEA-2018-3常用配置图解/</id>
    <published>2018-12-22T03:54:33.000Z</published>
    <updated>2018-12-24T13:44:02.203Z</updated>
    
    <content type="html"><![CDATA[<h1 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h1><p>IntelliJ IDEA 2018.3</p><hr><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="IDEA的优势（相对Eclipse）"><a href="#IDEA的优势（相对Eclipse）" class="headerlink" title="IDEA的优势（相对Eclipse）"></a>IDEA的优势（相对Eclipse）</h2><p>1.强大的整合能力。比如：Git、Maven、Spring等<br>2.提示功能的快速、便捷<br>3.提示功能的范围广<br>4.好用的快捷键和代码模板<br>5.精准搜索</p><h2 id="安装目录结构"><a href="#安装目录结构" class="headerlink" title="安装目录结构"></a>安装目录结构</h2><p><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/1.png" alt="在这里插入图片描述"></p><ul><li>bin<br>容器，执行文件和启动参数等</li><li>help<br>快捷键文档和其他帮助文档</li><li>jre64<br>64 位java 运行环境</li><li>lib<br>idea 依赖的类库</li><li>license<br>各个插件许可</li><li>plugin<br>插件<h2 id="设置目录结构"><a href="#设置目录结构" class="headerlink" title="设置目录结构"></a>设置目录结构</h2><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/2.png" alt="在这里插入图片描述"><br>当你不小心把IntelliJ IDEA 改坏了，删掉该目录，重启软件之后会重新生成默认配置的软件。</li></ul><hr><h1 id="常用配置"><a href="#常用配置" class="headerlink" title="常用配置"></a>常用配置</h1><p>首先进入设置页面，快捷键：Ctrl+Alt+S<br><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/3.png" alt="在这里插入图片描述"><br>目录结构如图：<br><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/4.png" alt="在这里插入图片描述"></p><h2 id="Appearance-amp-Behavior"><a href="#Appearance-amp-Behavior" class="headerlink" title="Appearance &amp; Behavior"></a>Appearance &amp; Behavior</h2><h3 id="设置主题、字体"><a href="#设置主题、字体" class="headerlink" title="设置主题、字体"></a>设置主题、字体</h3><p><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/5.png" alt="在这里插入图片描述"><br>编辑区主题的设置以及通过插件更换主题的方法在这里就不作说明的，感兴趣的可以自己去研究一下。</p><h2 id="Editor-General"><a href="#Editor-General" class="headerlink" title="Editor - General"></a>Editor - General</h2><h3 id="设置鼠标滚轮修改字体大小"><a href="#设置鼠标滚轮修改字体大小" class="headerlink" title="设置鼠标滚轮修改字体大小"></a>设置鼠标滚轮修改字体大小</h3><p><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/6.png" alt="在这里插入图片描述"></p><h3 id="设置鼠标悬浮提示"><a href="#设置鼠标悬浮提示" class="headerlink" title="设置鼠标悬浮提示"></a>设置鼠标悬浮提示</h3><p>上图所示:Show quick documentation on mouse move,勾选该选项</p><h3 id="设置自动导包功能"><a href="#设置自动导包功能" class="headerlink" title="设置自动导包功能"></a>设置自动导包功能</h3><p><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/7.png" alt="在这里插入图片描述"><br>Add unambiguous imports on the fly：自动导入不明确的结构<br>Optimize imports on the fly：自动帮我们优化导入的包</p><h3 id="忽略大小写提示"><a href="#忽略大小写提示" class="headerlink" title="忽略大小写提示"></a>忽略大小写提示</h3><p><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/8.png" alt="在这里插入图片描述"></p><ul><li><p>IntelliJ IDEA 的代码提示和补充功能有一个特性：区分大小写。如上图标注所示，默认就是 First letter 区分大小写的。</p></li><li><p>区分大小写的情况是这样的：比如我们在 Java 代码文件中输入 stringBuffer， IntelliJ IDEA 默认是不会帮我们提示或是代码补充的，但是如果我们输入StringBuffer 就可以进行代码提示和补充。</p></li><li><p>如果想不区分大小写的话，去掉勾选即可</p></li></ul><h3 id="设置取消单行显示tabs-的操作"><a href="#设置取消单行显示tabs-的操作" class="headerlink" title="设置取消单行显示tabs 的操作"></a>设置取消单行显示tabs 的操作</h3><p>在打开很多文件的时候，IntelliJ IDEA 默认是把所有打开的文件名 Tab 单行显示的。去掉如图勾选框即可取消单行显示:<br><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/9.png" alt="在这里插入图片描述"></p><h3 id="设置默认的字体、字体大小、字体行间距"><a href="#设置默认的字体、字体大小、字体行间距" class="headerlink" title="设置默认的字体、字体大小、字体行间距"></a>设置默认的字体、字体大小、字体行间距</h3><p><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/10.png" alt="在这里插入图片描述"></p><h2 id="Editor-File-and-Code-Templates"><a href="#Editor-File-and-Code-Templates" class="headerlink" title="Editor - File and Code Templates"></a>Editor - File and Code Templates</h2><h3 id="修改类头的文档注释信息"><a href="#修改类头的文档注释信息" class="headerlink" title="修改类头的文档注释信息"></a>修改类头的文档注释信息</h3><p><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/11.png" alt="在这里插入图片描述"></p><p>常用的预设的变量:<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$&#123;PACKAGE_NAME&#125;</span> - the name of the target package where the new class <span class="keyword">or</span><span class="built_in"> interface </span>will be created.  <span class="variable">$&#123;PROJECT_NAME&#125;</span> - the name of the current project.  </span><br><span class="line"><span class="variable">$&#123;FILE_NAME&#125;</span> - the name of the PHP file that will be created.  </span><br><span class="line"><span class="variable">$&#123;NAME&#125;</span> - the name of the new file which you specify <span class="keyword">in</span> the New File dialog box during the file creation. <span class="variable">$&#123;USER&#125;</span> - the login name of the current user.  </span><br><span class="line"><span class="variable">$&#123;DATE&#125;</span> - the current<span class="built_in"> system </span>date.  </span><br><span class="line"><span class="variable">$&#123;TIME&#125;</span> - the current<span class="built_in"> system </span>time.  </span><br><span class="line"><span class="variable">$&#123;YEAR&#125;</span> - the current year.  </span><br><span class="line"><span class="variable">$&#123;MONTH&#125;</span> - the current month.  </span><br><span class="line"><span class="variable">$&#123;DAY&#125;</span> - the current day of the month.  </span><br><span class="line"><span class="variable">$&#123;HOUR&#125;</span> - the current hour.  </span><br><span class="line"><span class="variable">$&#123;MINUTE&#125;</span> - the current minute.  </span><br><span class="line"><span class="variable">$&#123;PRODUCT_NAME&#125;</span> - the name of the IDE <span class="keyword">in</span> which the file will be created.  </span><br><span class="line"><span class="variable">$&#123;MONTH_NAME_SHORT&#125;</span> - the first 3 letters of the month name. Example: Jan, Feb, etc.  </span><br><span class="line"><span class="variable">$&#123;MONTH_NAME_FULL&#125;</span> - full name of a month. Example: January, February, etc.</span><br></pre></td></tr></table></figure></p><h2 id="Editor-–-File-Encodings"><a href="#Editor-–-File-Encodings" class="headerlink" title="Editor – File Encodings"></a>Editor – File Encodings</h2><h3 id="设置项目文件编码"><a href="#设置项目文件编码" class="headerlink" title="设置项目文件编码"></a>设置项目文件编码</h3><p>Transparent native-to-ascii conversion 主要用于转换 ascii，一般都要勾选，不然 Properties 文件中的注释显示的都不会是中文。<br><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/12.png" alt="在这里插入图片描述"></p><h3 id="设置当前源文件的编码"><a href="#设置当前源文件的编码" class="headerlink" title="设置当前源文件的编码"></a>设置当前源文件的编码</h3><p>对单独文件的编码修改还可以点击右下角的编码设置区。如果代码内容中包含中文，则会弹出如上的操作选择。其中：<br>①Reload 表示使用新编码重新加载，新编码不会保存到文件中，重新打开此文<br>件，旧编码是什么依旧还是什么。<br>②Convert 表示使用新编码进行转换，新编码会保存到文件中，重新打开此文件，<br>新编码是什么则是什么。<br>③含有中文的代码文件，Convert 之后可能会使中文变成乱码，所以在转换成请做好备份，不然可能出现转换过程变成乱码，无法还原。<br><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/13.png" alt="在这里插入图片描述"></p><h2 id="设置省点模式"><a href="#设置省点模式" class="headerlink" title="设置省点模式"></a>设置省点模式</h2><p>IntelliJ IDEA 有一种叫做 省电模式 的状态，开启这种模式之后 IntelliJ IDEA 会关掉代码检查和代码提示等功能。所以一般也可认为这是一种 阅读模式，如果你在开发过程中遇到突然代码文件不能进行检查和提示，可以来看看这里是否有开启该功能。<br><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/14.png" alt="在这里插入图片描述"></p><h2 id="变量类型提示-Scala开发中比较方便"><a href="#变量类型提示-Scala开发中比较方便" class="headerlink" title="变量类型提示(Scala开发中比较方便)"></a>变量类型提示(Scala开发中比较方便)</h2><p>在编写代码的过程中如果我们使用简写方式,开启该功能之后IDEA会自动展示完整的形式,包括变量的类型<br><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/IntelliJ%20IDEA%202018.3%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%9B%BE%E8%A7%A3/15.png" alt="在这里插入图片描述"></p><h1 id="IDEA常用快捷键"><a href="#IDEA常用快捷键" class="headerlink" title="IDEA常用快捷键"></a>IDEA常用快捷键</h1><figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line">alt +enter     导包</span><br><span class="line">ctrl + x  剪切</span><br><span class="line">Ctrl + d 快速复制</span><br><span class="line">Ctrl + c 复制</span><br><span class="line">Ctrl + y 删除</span><br><span class="line"></span><br><span class="line">alt + F4 关闭IDEA</span><br><span class="line"></span><br><span class="line">ctrl + shift + F  全文搜索  类似eclipse中的ctrl+H</span><br><span class="line">ctrl +alt +l   格式化 (L的小写)</span><br><span class="line">Ctrl + /   或  ctrl+shift +/   注释</span><br><span class="line">Ctrl + Alt + v  生成变量名 定义变量更方便</span><br><span class="line">或者在行尾添加.var 回车，生成变量名，并修改之     </span><br><span class="line">alt + t   可控制显示类型</span><br><span class="line"></span><br><span class="line">shift +f6   重命名</span><br><span class="line">ctrl +o   实现方法</span><br><span class="line">ctrl +i  重写方法</span><br><span class="line"></span><br><span class="line"><span class="keyword">double</span> shift  查找</span><br><span class="line">ctrl +n  查找类</span><br><span class="line"></span><br><span class="line">shift + Enter  在当前行下另起一行</span><br><span class="line">ctrl+shift + 上下箭头   往上下移动</span><br><span class="line"></span><br><span class="line">导入main方法的快捷键     psvm  回车   适用于java代码</span><br><span class="line"></span><br><span class="line">----------------------------------------------------------</span><br><span class="line"></span><br><span class="line">ctrl +alt +空格    代码提示</span><br><span class="line">ctrl+shift+F10      Run context configuration from editor  运行当前类的main方法</span><br><span class="line">shift+F10  Run      正常运行当前Application中显示的类</span><br><span class="line">shift+F9    Debug    Debug当前Applicaiton显示的类</span><br><span class="line">Alt+Shift+F10  Select configuration and run   调出Run里面的所有Application</span><br><span class="line">Alt+Shift+F9  Select configuration and debug   选择Application，并debug</span><br><span class="line"></span><br><span class="line">IDEA中输出System.out.println（）的快捷键是sout</span><br><span class="line"></span><br><span class="line">IDEA快捷键大全：</span><br><span class="line"></span><br><span class="line"><span class="built_in">CTRL</span>+N   查找类</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+N  查找文件</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+ALT+N 查 找类中的方法或变量</span><br><span class="line"><span class="built_in">CIRL</span>+B   找变量的来源</span><br><span class="line"><span class="built_in">CTRL</span>+ALT+B  找所有的子类</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+B  找变量的 类</span><br><span class="line"><span class="built_in">CTRL</span>+G   定位行</span><br><span class="line"><span class="built_in">CTRL</span>+F   在当前窗口查找文本</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+F  在指定窗口查找文本</span><br><span class="line"><span class="built_in">CTRL</span>+R   在 当前窗口替换文本</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+R  在指定窗口替换文本</span><br><span class="line">ALT+SHIFT+C  查找修改的文件</span><br><span class="line"><span class="built_in">CTRL</span>+E   最 近打开的文件</span><br><span class="line">F3   向下查找关键字出现位置类</span><br><span class="line">SHIFT+F3  向上一个关键字出现位置</span><br><span class="line">F4   查找变量来源</span><br><span class="line"><span class="built_in">CTRL</span>+ALT+F7  选 中的字符 查找工程出现的地方</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+O  弹出显示查找内容</span><br><span class="line"></span><br><span class="line">自动代码</span><br><span class="line">ALT+回车  导入包,自动修正</span><br><span class="line"><span class="built_in">CTRL</span>+ALT+L  格式化代码</span><br><span class="line"><span class="built_in">CTRL</span>+ALT+I  自 动缩进</span><br><span class="line"><span class="built_in">CTRL</span>+ALT+O  优化导入的类和包</span><br><span class="line">ALT+INSERT  生成代码(如GET,SET方法,构造函数等)</span><br><span class="line"><span class="built_in">CTRL</span>+E 或者ALT+SHIFT+C 最近更改的代码</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+SPACE 自动补全代码</span><br><span class="line"><span class="built_in">CTRL</span>+空格  代码提示</span><br><span class="line"><span class="built_in">CTRL</span>+ALT+SPACE  类 名或接口名提示</span><br><span class="line"><span class="built_in">CTRL</span>+P   方法参数提示</span><br><span class="line"><span class="built_in">CTRL</span>+J   自动代码</span><br><span class="line"><span class="built_in">CTRL</span>+ALT+T  把选中的代码放在 TRY&#123;&#125; IF&#123;&#125; ELSE&#123;&#125; 里</span><br><span class="line"> </span><br><span class="line">复制快捷方式</span><br><span class="line">F5   拷贝文件快捷方式</span><br><span class="line"><span class="built_in">CTRL</span>+D   复制行</span><br><span class="line"><span class="built_in">CTRL</span>+X   剪 切,删除行</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+V  可以复制多个文本</span><br><span class="line"> </span><br><span class="line">高亮</span><br><span class="line"><span class="built_in">CTRL</span>+F   选中的文字,高亮显示 上下跳到下一个或者上一个</span><br><span class="line">F2 或SHIFT+F2  高亮错误或警告快速定位</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+F7  高亮显示多个关键字.</span><br><span class="line"> </span><br><span class="line">其他快捷方式</span><br><span class="line"><span class="built_in">CIRL</span>+shift+U   大小写切换</span><br><span class="line"><span class="built_in">CTRL</span>+Z   倒退</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+Z  向 前</span><br><span class="line"><span class="built_in">CTRL</span>+ALT+F12  资源管理器打开文件夹</span><br><span class="line">ALT+F1   查找文件所在目录位置</span><br><span class="line">SHIFT+ALT+INSERT 竖 编辑模式</span><br><span class="line"><span class="built_in">CTRL</span>+/   注释<span class="comment">//  </span></span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+/  注释<span class="comment">/*...*/</span></span><br><span class="line"><span class="built_in">CTRL</span>+W   选中代码，连续按会 有其他效果</span><br><span class="line"><span class="built_in">CTRL</span>+B   快速打开光标处的类或方法</span><br><span class="line">ALT+ ←/→  切换代码视图</span><br><span class="line"><span class="built_in">CTRL</span>+ALT ←/→  返回上次编辑的位置</span><br><span class="line">ALT+ ↑/↓  在方法间快速移动定位</span><br><span class="line">SHIFT+F6  重构-重命名</span><br><span class="line"><span class="built_in">CTRL</span>+H   显 示类结构图</span><br><span class="line"><span class="built_in">CTRL</span>+Q   显示注释文档</span><br><span class="line">ALT+<span class="number">1</span>   快速打开或隐藏工程面板</span><br><span class="line"><span class="built_in">CTRL</span>+SHIFT+UP/DOWN 代码 向上/下移动。</span><br><span class="line"><span class="built_in">CTRL</span>+UP/DOWN  光标跳转到第一行或最后一行下</span><br><span class="line">ESC   光标返回编辑框</span><br><span class="line">SHIFT+ESC  光 标返回编辑框,关闭无用的窗口</span><br><span class="line">F1   帮助 千万别按,很卡!</span><br><span class="line"><span class="built_in">CTRL</span>+F4   非常重要 下班都用</span><br></pre></td></tr></table></figure><hr><p>若有更好的功能,欢迎在评论区补充^ - ^</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;软件版本&quot;&gt;&lt;a href=&quot;#软件版本&quot; class=&quot;headerlink&quot; title=&quot;软件版本&quot;&gt;&lt;/a&gt;软件版本&lt;/h1&gt;&lt;p&gt;IntelliJ IDEA 2018.3&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=
      
    
    </summary>
    
      <category term="开发工具" scheme="https://blog.niclas.cn/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="IDEA" scheme="https://blog.niclas.cn/tags/IDEA/"/>
    
      <category term="快捷键" scheme="https://blog.niclas.cn/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
    
      <category term="配置方法" scheme="https://blog.niclas.cn/tags/%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>HDFS基本原理与工作机制（一）——初识HDFS</title>
    <link href="https://blog.niclas.cn/post/HDFS%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%88%9D%E8%AF%86HDFS/"/>
    <id>https://blog.niclas.cn/post/HDFS基本原理与工作机制（一）——初识HDFS/</id>
    <published>2018-11-12T12:44:43.000Z</published>
    <updated>2018-12-24T13:15:17.139Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HDFS简介"><a href="#HDFS简介" class="headerlink" title="HDFS简介"></a>HDFS简介</h1><blockquote><p>HDFS 源于 Google 在2003年10月份发表的GFS（Google File System） 论文。 是 GFS 的一个克隆版本<br>HDFS（Hadoop Distributed File System）是Hadoop项目的核心子项目，是分布式计算中数据存储管理的基础，是基于流数据模式访问和处理超大文件的需求而开发的，可以运行于廉价的商用服务器上。它所具有的高容错、高可靠性、高可扩展性、高获得性、高吞吐率等特征为海量数据提供了不怕故障的存储，为超大数据集（Large Data Set）的应用处理带来了很多便利。</p></blockquote><hr><h1 id="HDFS存储数据的优缺点"><a href="#HDFS存储数据的优缺点" class="headerlink" title="HDFS存储数据的优缺点"></a>HDFS存储数据的优缺点</h1><h2 id="HDFS的优点"><a href="#HDFS的优点" class="headerlink" title="HDFS的优点"></a>HDFS的优点</h2><blockquote><ol><li>高容错性</li></ol><ul><li>数据自动保存多个副本。通过增加副本的形式，提高容错性。</li><li>某一个副本丢失以后，可以自动恢复，这是由 HDFS 内部机制实现的，我们不必关心。</li></ul><ol start="2"><li>适合批处理</li></ol><ul><li>通过移动计算而不是移动数据。</li><li>它会把数据位置暴露给计算框架。</li></ul><ol start="3"><li>适合大数据处理</li></ol><ul><li>处理数据达到 GB、TB、甚至PB级别的数据。</li><li>能够处理百万规模以上的文件数量，数量相当之大。</li><li>能够处理10K节点的规模。</li><li></li></ul><ol start="4"><li>流式文件访问</li></ol><ul><li>一次写入，多次读取。</li><li>文件一旦写入不能修改，只能追加。</li><li>能保证数据的一致性。</li></ul><ol start="5"><li>可构建在廉价机器上</li></ol><ul><li>通过多副本机制，提高可靠性。</li><li>提供了容错和恢复机制。比如某一个副本丢失，可以通过其它副本来恢复。</li></ul></blockquote><h2 id="HDFS的缺点"><a href="#HDFS的缺点" class="headerlink" title="HDFS的缺点"></a>HDFS的缺点</h2><blockquote><ol><li>无法低延时数据访问</li></ol><ul><li>无法毫秒级的来存储数据。</li><li>适合高吞吐率的场景，就是在某一时间内写入大量的数据。但是它在低延时的情况下是不行的，比如毫秒级以内读取数据</li></ul><ol start="2"><li>不适合小文件存储</li></ol><ul><li>存储大量小文件(这里的小文件是指小于HDFS系统的Block大小的文件（默认64M）)的话，它会占用 NameNode大量的内存来存储文件、目录和块信息。这样是不可取的，因为NameNode的内存总是有限的。</li><li>小文件存储的寻道时间会超过读取时间，它违反了HDFS的设计目标。</li></ul><ol start="3"><li>不支持并发写入、文件随机修改</li></ol><ul><li>一个文件只能有一个写，不允许多个线程同时写。</li><li>仅支持数据 append（追加），不支持文件的随机修改</li></ul></blockquote><p><strong>以上内容来自：<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vY29kZU9mTGlmZS9wLzUzNzUxMjAuaHRtbA==" title="https://www.cnblogs.com/codeOfLife/p/5375120.html">https://www.cnblogs.com/codeOfLife/p/5375120.html<i class="fa fa-external-link"></i></span></strong></p><hr><h1 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h1><h2 id="集群架构"><a href="#集群架构" class="headerlink" title="集群架构"></a>集群架构</h2><p><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/HDFS%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%88%9D%E8%AF%86HDFS/3.jpg" alt="与下文"></p><p>HDFS 采用Master/Slave的架构来存储数据，这种架构主要由四个部分组成，分别为HDFS Client、NameNode、DataNode和Secondary NameNode。这里重点介绍Secondary NameNode，其他架构部分参考下文<strong>高可用集群架构</strong></p><p><strong>Secondary NameNode</strong></p><p>并非 NameNode 的热备。当NameNode 挂掉的时候，它并不能马上替换 NameNode 并提供服务</p><p> <strong>SecondaryNameNode的工作情况：</strong> </p><blockquote><ol><li><p>SecondaryNameNode会定期和NameNode通信，请求其停止使用EditLog文件，暂时将新的写操作写到一个新的文件edit.new上来，这个操作是瞬间完成，上层写日志的函数完全感觉不到差别；</p></li><li><p>SecondaryNameNode通过HTTP GET方式从NameNode上获取到FsImage和EditLog文件，并下载到本地的相应目录下； </p></li><li><p>SecondaryNameNode将下载下来的FsImage载入到内存，然后一条一条地执行EditLog文件中的各项更新操作，使得内存中的FsImage保持最新；这个过程就是EditLog和FsImage文件合并；</p></li><li><p>SecondaryNameNode执行完（3）操作之后，会通过post方式将新的FsImage文件发送到NameNode节点上 </p></li><li>NameNode将从SecondaryNameNode接收到的新的FsImage替换旧的FsImage文件，同时将edit.new替换EditLog文件，通过这个过程EditLog就变小了<br><strong>此处内容来自:<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hqejcyOTgyNzE2MS9hcnRpY2xlL2RldGFpbHMvNzk0NjMxNDA=" title="https://blog.csdn.net/xjz729827161/article/details/79463140">https://blog.csdn.net/xjz729827161/article/details/79463140<i class="fa fa-external-link"></i></span></strong></li></ol></blockquote><h2 id="高可用集群架构"><a href="#高可用集群架构" class="headerlink" title="高可用集群架构"></a>高可用集群架构</h2><ul><li>HDFS HA（High Availability）是为了解决单点故障问题</li><li>HA集群设置两个名称节点，“活跃（Active）”和“待命（Standby）”</li><li>两种名称节点的状态同步，可以借助于一个共享存储系统来实现</li><li>一旦活跃名称节点出现故障，就可以立即切换到待命名称节点</li><li>Zookeeper确保一个名称节点在对外服务</li><li>名称节点维护映射信息，数据节点同时向两个名称节点汇报信息</li></ul><p><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/HDFS%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%88%9D%E8%AF%86HDFS/2.jpg" alt="在这里插入图片描述"></p><ol><li>主Master，整个Hadoop集群只能有一个</li></ol><ul><li><p>管理HDFS文件系统的命名空间</p></li><li><p>维护元数据信息</p></li><li><p>管理副本的配置和信息（默认三个副本）</p></li><li><p>处理客户端读写请求</p></li></ul><ol start="2"><li>Standby Name Node</li></ol><ul><li><p>Active Name Node的热备节点</p></li><li><p>Active Name Node故障时可快速切换成新的Active Name Node</p></li><li><p>周期性同步edits编辑日志，定期合并fsimage与edits到本地磁盘</p></li></ul><ol start="3"><li>Journal Node</li></ol><ul><li><p>可以被Active Name Node和StandBy Name Node同时访问，用以支持Active Name Node高可用</p></li><li><p>Active Name Node在文件系统被修改时，会向Journal Node写入操作日志（edits）</p></li><li><p>Standby Name Node同步Journal Node edits日志，使集群中的更新操作可以被共享和同步。</p></li></ul><ol start="4"><li>Data Node</li></ol><ul><li><p>Slave 工作节点，集群一般会启动多个</p></li><li><p>负责存储数据块和数据块校验</p></li><li><p>执行客户端的读写请求</p></li><li><p>通过心跳机制定期向NameNode汇报运行状态和本地所有块的列表信息</p></li><li><p>在集群启动时DataNode项NameNode提供存储Block块的列表信息</p></li></ul><ol start="5"><li>Block数据块</li></ol><ul><li><p>HDSF固定的最小的存储单元（默认128M，可配置修改）</p></li><li><p>写入到HDFS的文件会被切分成Block数据块（若文件大小小于数据块大小，则不会占用整个数据块）</p></li><li><p>默认配置下，每个block有三个副本</p></li></ul><ol start="6"><li>Client</li></ol><ul><li><p>与Name Node交互获取文件的元数据信息</p></li><li><p>与Data Node，读取或者写入数据</p></li><li><p>通过客户端可以管理HDFS  </p></li></ul><p><strong>更多详情见：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgzMDA5ODIy" title="https://blog.csdn.net/u010993514/article/details/83009822">https://blog.csdn.net/u010993514/article/details/83009822<i class="fa fa-external-link"></i></span></strong></p><hr><h1 id="HDFS副本存放策略"><a href="#HDFS副本存放策略" class="headerlink" title="HDFS副本存放策略"></a>HDFS副本存放策略</h1><p>namenode如何选择在哪个datanode 存储副本（replication）？这里需要对可靠性、写入带宽和读取带宽进行权衡。Hadoop对datanode存储副本有自己的副本策略，在其发展过程中一共有两个版本的副本策略，分别如下所示：<br><img src="https://blog-1-1251747390.cos.ap-beijing.myqcloud.com/HDFS%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%88%9D%E8%AF%86HDFS/4.jpg" alt="在这里插入图片描述"></p><p><strong>此处内容来自：<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vY29kZU9mTGlmZS9wLzUzNzUxMjAuaHRtbA==" title="https://www.cnblogs.com/codeOfLife/p/5375120.html">https://www.cnblogs.com/codeOfLife/p/5375120.html<i class="fa fa-external-link"></i></span></strong></p><hr><h1 id="Hadoop2-x新特性"><a href="#Hadoop2-x新特性" class="headerlink" title="Hadoop2.x新特性"></a>Hadoop2.x新特性</h1><ul><li>引入了NameNode Federation，解决了横向内存扩展</li><li>引入了Namenode HA，解决了namenode单点故障</li><li>引入了YARN，负责资源管理和调度</li><li>增加了ResourceManager HA解决了ResourceManager单点故障</li></ul><p><strong>更多详细信息：<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vY29kZU9mTGlmZS9wLzUzNzUxMjAuaHRtbA==" title="https://www.cnblogs.com/codeOfLife/p/5375120.html">https://www.cnblogs.com/codeOfLife/p/5375120.html<i class="fa fa-external-link"></i></span></strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HDFS简介&quot;&gt;&lt;a href=&quot;#HDFS简介&quot; class=&quot;headerlink&quot; title=&quot;HDFS简介&quot;&gt;&lt;/a&gt;HDFS简介&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;HDFS 源于 Google 在2003年10月份发表的GFS（Google Fi
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/tags/Hadoop/"/>
    
      <category term="HA" scheme="https://blog.niclas.cn/tags/HA/"/>
    
      <category term="NameNode" scheme="https://blog.niclas.cn/tags/NameNode/"/>
    
      <category term="DataNode" scheme="https://blog.niclas.cn/tags/DataNode/"/>
    
  </entry>
  
  <entry>
    <title>使用Shell脚本一键部署Hadoop</title>
    <link href="https://blog.niclas.cn/post/%E4%BD%BF%E7%94%A8Shell%E8%84%9A%E6%9C%AC%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2Hadoop/"/>
    <id>https://blog.niclas.cn/post/使用Shell脚本一键部署Hadoop/</id>
    <published>2018-10-26T07:46:53.000Z</published>
    <updated>2018-12-24T13:15:17.200Z</updated>
    
    <content type="html"><![CDATA[<h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><p>Linux系统版本：CentOS 7</p><hr><h1 id="实现功能"><a href="#实现功能" class="headerlink" title="实现功能"></a>实现功能</h1><p>1、Java环境一键配置<br>2、Hadoop单机版一键安装<br>3、Hadoop伪分布式一键安装<br>4、Hadoop集群部署<br>5、伪分布式hadoop初始化<br>6、集群设置SSH免密登录（使用hadoop用户操作）</p><hr><h1 id="脚本说明"><a href="#脚本说明" class="headerlink" title="脚本说明"></a>脚本说明</h1><p>部署Hadoop环境过程比较繁琐，还容易出错，写了一个Shell脚本用来一键部署，废话不多说，下面直接上代码。</p><p><strong>集群部署的方法暂时还没进行全面测试，后面测试后会持续更新</strong></p><p>若在使用过程中遇到什么问题或者是有好的改进方案欢迎在评论区指出</p><hr><h1 id="脚本代码"><a href="#脚本代码" class="headerlink" title="脚本代码"></a>脚本代码</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">JDKLINK=<span class="string">'http://download.oracle.com/otn-pub/java/jdk/8u191-b12/2787e4a523244c269598db4e85c51e0c/jdk-8u191-linux-x64.rpm'</span></span><br><span class="line">HADOOPLINK=<span class="string">'https://archive.apache.org/dist/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz'</span></span><br><span class="line">localIP=$(ip a | grep ens33 | awk <span class="string">'$1~/^inet.*/&#123;print $2&#125;'</span> | awk -F <span class="string">'/'</span> <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line">ip_arrays=()</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化环境</span></span><br><span class="line"><span class="function"><span class="title">installWget</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'初始化安装环境....'</span></span><br><span class="line">wget</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 1 ]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始下载wget'</span></span><br><span class="line">yum -y install wget</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#wget下载JDK进行安装</span></span><br><span class="line"><span class="function"><span class="title">installJDK</span></span>()&#123;</span><br><span class="line">ls /usr/<span class="built_in">local</span> | grep <span class="string">'jdk.*[rpm]$'</span></span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始下载JDK.......'</span></span><br><span class="line">wget --no-check-certificate --no-cookies --header <span class="string">"Cookie: oraclelicense=accept-securebackup-cookie"</span> <span class="variable">$JDKLINK</span></span><br><span class="line">mv $(ls | grep <span class="string">'jdk.*[rpm]$'</span>) /usr/<span class="built_in">local</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">chmod 751 /usr/<span class="built_in">local</span>/$(ls /usr/<span class="built_in">local</span> | grep <span class="string">'jdk.*[rpm]$'</span>)</span><br><span class="line">rpm -ivh /usr/<span class="built_in">local</span>/$(ls /usr/<span class="built_in">local</span> | grep <span class="string">'jdk.*[rpm]$'</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#JDK环境变量配置</span></span><br><span class="line"><span class="function"><span class="title">pathJDK</span></span>()&#123;</span><br><span class="line"><span class="comment">#PATH设置</span></span><br><span class="line">grep -q <span class="string">"export PATH="</span> /etc/profile</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="comment">#末行插入</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'export PATH=$PATH:$JAVA_HOME/bin'</span>&gt;&gt;/etc/profile</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="comment">#行尾添加</span></span><br><span class="line">sed -i <span class="string">'/^export PATH=.*/s/$/:\$JAVA_HOME\/bin/'</span> /etc/profile</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">grep -q <span class="string">"export JAVA_HOME="</span> /etc/profile</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="comment">#导入配置</span></span><br><span class="line">filename=<span class="string">"<span class="variable">$(ls /usr/java | grep '^jdk.*[^rpm | gz]$' | sed -n '1p')</span>"</span></span><br><span class="line">sed -i <span class="string">"/^export PATH=.*/i\export JAVA_HOME=\/usr\/java\/<span class="variable">$filename</span>"</span> /etc/profile</span><br><span class="line">sed -i <span class="string">'/^export PATH=.*/i\export JRE_HOME=$JAVA_HOME/jre'</span> /etc/profile</span><br><span class="line">sed -i <span class="string">'/^export PATH=.*/i\export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar'</span> /etc/profile</span><br><span class="line"><span class="comment">#echo "export JAVA_HOME=/usr/java/$filename"&gt;&gt;/etc/profile</span></span><br><span class="line"><span class="comment">#echo 'export JRE_HOME=$JAVA_HOME/jre'&gt;&gt;/etc/profile</span></span><br><span class="line"><span class="comment">#echo 'export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar'&gt;&gt;/etc/profile</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="comment">#替换原有配置</span></span><br><span class="line">filename=<span class="string">"<span class="variable">$(ls /usr/java | grep '^jdk.*[^rpm | gz]$' | sed -n '1p')</span>"</span></span><br><span class="line">sed -i <span class="string">"s/^export JAVA_HOME=.*/export JAVA_HOME=\/usr\/java\/<span class="variable">$filename</span>/"</span> /etc/profile</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#wget下载Hadoop进行解压(单机版)</span></span><br><span class="line"><span class="function"><span class="title">wgetHadoop</span></span>()&#123;</span><br><span class="line">ls /usr/<span class="built_in">local</span> | grep <span class="string">'hadoop.*[gz]$'</span></span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始下载hadoop安装包...'</span></span><br><span class="line">wget <span class="variable">$HADOOPLINK</span></span><br><span class="line">mv $(ls | grep <span class="string">'hadoop.*gz$'</span>) /usr/<span class="built_in">local</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">tar -zxvf /usr/<span class="built_in">local</span>/$(ls | grep <span class="string">'hadoop.*[gz]$'</span>)</span><br><span class="line">mv /usr/<span class="built_in">local</span>/$(ls | grep <span class="string">'hadoop.*[^gz]$'</span>) /usr/<span class="built_in">local</span>/hadoop</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#hadoop环境变量配置</span></span><br><span class="line"><span class="function"><span class="title">pathHadoop</span></span>()&#123;</span><br><span class="line"><span class="comment">#PATH设置</span></span><br><span class="line">grep -q <span class="string">"export PATH="</span> /etc/profile</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="comment">#末行插入</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin'</span>&gt;&gt;/etc/profile</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="comment">#行尾添加</span></span><br><span class="line">sed -i <span class="string">'/^export PATH=.*/s/$/:\$HADOOP_HOME\/bin:\$HADOOP_HOME\/sbin/'</span> /etc/profile</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="comment">#HADOOP_HOME设置</span></span><br><span class="line">grep -q <span class="string">"export HADOOP_HOME="</span> /etc/profile</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="comment">#在PATH前面一行插入HADOOP_HOME</span></span><br><span class="line">sed -i <span class="string">'/^export PATH=.*/i\export HADOOP_HOME=\/usr\/local\/hadoop'</span> /etc/profile</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="comment">#修改文件内的HADOOP_HOME</span></span><br><span class="line">sed -i <span class="string">'s/^export HADOOP_HOME=.*/export HADOOP_HOME=\/usr\/local\/hadoop/'</span> /etc/profile</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加hadoop用户并设置权限</span></span><br><span class="line"><span class="function"><span class="title">hadoopUserAdd</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'正在创建hadoop用户....'</span></span><br><span class="line">useradd hadoop</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'请设置hadoop用户密码....'</span></span><br><span class="line">passwd hadoop</span><br><span class="line">gpasswd -a hadoop root</span><br><span class="line">chmod 771 /usr</span><br><span class="line">chmod 771 /usr/<span class="built_in">local</span></span><br><span class="line">chown -R hadoop:hadoop /usr/<span class="built_in">local</span>/hadoop</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#单机版hadoop配置</span></span><br><span class="line"><span class="function"><span class="title">installHadoop</span></span>()&#123;</span><br><span class="line">installWget</span><br><span class="line">wgetHadoop</span><br><span class="line">pathHadoop</span><br><span class="line">hadoopUserAdd</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#伪分布式设置</span></span><br><span class="line"><span class="function"><span class="title">setHadoop</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="string">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="string">&lt;!--</span></span><br><span class="line"><span class="string">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="string">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="string">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="string">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="string">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="string">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="string">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="string">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="string">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="string">--&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;指定hadoop运行时产生文件的存储路径&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;hdfs namenode的通信地址,通信端口&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;/configuration&gt;'</span>&gt;<span class="variable">$HADOOP_HOME</span>/etc/hadoop/core-site.xml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="string">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="string">&lt;!--</span></span><br><span class="line"><span class="string">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="string">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="string">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="string">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="string">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="string">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="string">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="string">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="string">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="string">--&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="string">&lt;!-- 该文件指定与HDFS相关的配置信息。</span></span><br><span class="line"><span class="string">需要修改HDFS默认的块的副本属性，因为HDFS默认情况下每个数据块保存3个副本，</span></span><br><span class="line"><span class="string">而在伪分布式模式下运行时，由于只有一个数据节点，</span></span><br><span class="line"><span class="string">所以需要将副本个数改为1；否则Hadoop程序会报错。 --&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;dfs.replication&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;1&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;指定HDFS存储数据的副本数目，默认情况下是3份&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;file:/usr/local/hadoop/hadoopdata/namenode&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;namenode存放数据的目录&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;file:/usr/local/hadoop/hadoopdata/datanode&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;datanode存放block块的目录&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;dfs.permissions.enabled&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;关闭权限验证&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;/configuration&gt;'</span>&gt;<span class="variable">$HADOOP_HOME</span>/etc/hadoop/hdfs-site.xml</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="string">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="string">&lt;!--</span></span><br><span class="line"><span class="string">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="string">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="string">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="string">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="string">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="string">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="string">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="string">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="string">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="string">--&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="string">&lt;!-- 在该配置文件中指定与MapReduce作业相关的配置属性，需要指定JobTracker运行的主机地址--&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;yarn&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;指定mapreduce运行在yarn上&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;/configuration&gt;'</span>&gt;<span class="variable">$HADOOP_HOME</span>/etc/hadoop/mapred-site.xml</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="string">&lt;!--</span></span><br><span class="line"><span class="string">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="string">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="string">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="string">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="string">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="string">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="string">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="string">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="string">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="string">--&gt;</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;mapreduce执行shuffle时获取数据的方式&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;/configuration&gt;'</span>&gt;<span class="variable">$HADOOP_HOME</span>/etc/hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'localhost'</span>&gt;<span class="variable">$HADOOP_HOME</span>/etc/hadoop/slaves</span><br><span class="line">sed -i <span class="string">'s/export JAVA_HOME=.*/\#&amp;/'</span> <span class="variable">$HADOOP_HOME</span>/etc/hadoop/hadoop-env.sh</span><br><span class="line">sed -i <span class="string">"/#export JAVA_HOME=.*/a export JAVA_HOME=<span class="variable">$JAVA_HOME</span>"</span> <span class="variable">$HADOOP_HOME</span>/etc/hadoop/hadoop-env.sh</span><br><span class="line">chown -R hadoop:hadoop <span class="variable">$HADOOP_HOME</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#完全分布式设置</span></span><br><span class="line"><span class="function"><span class="title">setHadoop2</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="string">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="string">&lt;!--</span></span><br><span class="line"><span class="string">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="string">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="string">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="string">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="string">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="string">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="string">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="string">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="string">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="string">--&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;指定hadoop运行时产生文件的存储路径&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;hdfs://'</span><span class="variable">$1</span><span class="string">':9000&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;hdfs namenode的通信地址,通信端口&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;/configuration&gt;'</span>&gt;<span class="variable">$HADOOP_HOME</span>/etc/hadoop/core-site.xml</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="string">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="string">&lt;!--</span></span><br><span class="line"><span class="string">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="string">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="string">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="string">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="string">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="string">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="string">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="string">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="string">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="string">--&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="string">&lt;!-- 该文件指定与HDFS相关的配置信息。</span></span><br><span class="line"><span class="string">需要修改HDFS默认的块的副本属性，因为HDFS默认情况下每个数据块保存3个副本，</span></span><br><span class="line"><span class="string">而在伪分布式模式下运行时，由于只有一个数据节点，</span></span><br><span class="line"><span class="string">所以需要将副本个数改为1；否则Hadoop程序会报错。 --&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;dfs.replication&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;3&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;指定HDFS存储数据的副本数目，默认情况下是3份&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;file:/usr/local/hadoop/hadoopdata/namenode&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;namenode存放数据的目录&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;file:/usr/local/hadoop/hadoopdata/datanode&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;datanode存放block块的目录&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;dfs.secondary.http.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;'</span><span class="variable">$2</span><span class="string">':50090&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;secondarynamenode 运行节点的信息，和 namenode 不同节点&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;dfs.permissions.enabled&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;false&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;关闭权限验证&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;/configuration&gt;'</span>&gt;<span class="variable">$HADOOP_HOME</span>/etc/hadoop/hdfs-site.xml</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="string">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="string">&lt;!--</span></span><br><span class="line"><span class="string">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="string">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="string">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="string">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="string">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="string">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="string">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="string">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="string">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="string">--&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="string">&lt;!-- 在该配置文件中指定与MapReduce作业相关的配置属性，需要指定JobTracker运行的主机地址--&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;yarn&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;指定mapreduce运行在yarn上&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;/configuration&gt;'</span>&gt;<span class="variable">$HADOOP_HOME</span>/etc/hadoop/mapred-site.xml</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="string">&lt;!--</span></span><br><span class="line"><span class="string">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="string">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="string">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="string">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="string">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="string">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="string">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="string">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="string">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="string">--&gt;</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;'</span><span class="variable">$1</span><span class="string">'&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;yarn总管理器的IPC通讯地址&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;property&gt;</span></span><br><span class="line"><span class="string">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span></span><br><span class="line"><span class="string">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span></span><br><span class="line"><span class="string">&lt;description&gt;mapreduce执行shuffle时获取数据的方式&lt;/description&gt;</span></span><br><span class="line"><span class="string">&lt;/property&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">&lt;/configuration&gt;'</span>&gt;<span class="variable">$HADOOP_HOME</span>/etc/hadoop/yarn-site.xml</span><br><span class="line">rm -rf <span class="variable">$HADOOP_HOME</span>/etc/hadoop/slaves</span><br><span class="line">touch <span class="variable">$HADOOP_HOME</span>/etc/hadoop/slaves</span><br><span class="line">int=0</span><br><span class="line"><span class="keyword">while</span>(( <span class="variable">$&#123;int&#125;</span>&lt;<span class="variable">$&#123;#ip_arrays[*]&#125;</span> ))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"><span class="comment">#echo "while is run"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;ip_arrays[$int]&#125;</span>"</span>&gt;&gt;<span class="variable">$HADOOP_HOME</span>/etc/hadoop/slaves</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'写入slaves配置失败'</span></span><br><span class="line"><span class="built_in">break</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">let</span> <span class="string">"int++"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">sed -i <span class="string">'s/export JAVA_HOME=.*/\#&amp;/'</span> <span class="variable">$HADOOP_HOME</span>/etc/hadoop/hadoop-env.sh</span><br><span class="line">sed -i <span class="string">"/#export JAVA_HOME=.*/a export JAVA_HOME=<span class="variable">$JAVA_HOME</span>"</span> <span class="variable">$HADOOP_HOME</span>/etc/hadoop/hadoop-env.sh</span><br><span class="line">chown -R hadoop:hadoop <span class="variable">$HADOOP_HOME</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line"><span class="function"><span class="title">stopFirewalld</span></span>()&#123;</span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#IP校验,返回值0校验合法，1不合法。</span></span><br><span class="line"><span class="function"><span class="title">checkIPAddr</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$1</span>|grep <span class="string">"^[0-9]\&#123;1,3\&#125;\.\([0-9]\&#123;1,3\&#125;\.\)\&#123;2\&#125;[0-9]\&#123;1,3\&#125;$"</span> &gt; /dev/null; </span><br><span class="line"><span class="comment">#IP地址必须为全数字 </span></span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ] </span><br><span class="line"><span class="keyword">then</span> </span><br><span class="line"><span class="built_in">return</span> 1 </span><br><span class="line"><span class="keyword">fi</span> </span><br><span class="line">ipaddr=<span class="variable">$1</span> </span><br><span class="line">a=`<span class="built_in">echo</span> <span class="variable">$ipaddr</span>|awk -F . <span class="string">'&#123;print $1&#125;'</span>`  <span class="comment">#以"."分隔，取出每个列的值 </span></span><br><span class="line">b=`<span class="built_in">echo</span> <span class="variable">$ipaddr</span>|awk -F . <span class="string">'&#123;print $2&#125;'</span>` </span><br><span class="line">c=`<span class="built_in">echo</span> <span class="variable">$ipaddr</span>|awk -F . <span class="string">'&#123;print $3&#125;'</span>` </span><br><span class="line">d=`<span class="built_in">echo</span> <span class="variable">$ipaddr</span>|awk -F . <span class="string">'&#123;print $4&#125;'</span>` </span><br><span class="line"><span class="keyword">for</span> num <span class="keyword">in</span> <span class="variable">$a</span> <span class="variable">$b</span> <span class="variable">$c</span> <span class="variable">$d</span> </span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$num</span> -gt 255 ] || [ <span class="variable">$num</span> -lt 0 ]    <span class="comment">#每个数值必须在0-255之间 </span></span><br><span class="line"><span class="keyword">then</span> </span><br><span class="line"><span class="built_in">return</span> 1 </span><br><span class="line"><span class="keyword">fi</span> </span><br><span class="line"><span class="keyword">done</span> </span><br><span class="line"><span class="built_in">return</span> 0 </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#控制台输入集群IP</span></span><br><span class="line"><span class="function"><span class="title">ipInput</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"本机IP地址为：<span class="variable">$localIP</span>"</span></span><br><span class="line">int=0</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'输入完成后，输入ip值为0可退出'</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">read</span> -p <span class="string">"输入第`expr <span class="variable">$&#123;int&#125;</span> + 1`台的IP:"</span> ip</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$ip</span>"</span> == <span class="string">"0"</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">break</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">checkIPAddr <span class="variable">$ip</span></span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">ip_arrays[<span class="variable">$int</span>]=<span class="variable">$ip</span></span><br><span class="line"><span class="comment">#echo $int</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'输入的IP不合法,重新进行配置....'</span></span><br><span class="line">ipInput</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">let</span> <span class="string">"int++"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#scp设置免密登录</span></span><br><span class="line"><span class="function"><span class="title">scpOutput</span></span>()&#123;</span><br><span class="line">int=0</span><br><span class="line"><span class="keyword">while</span>(( <span class="variable">$&#123;int&#125;</span>&lt;<span class="variable">$&#123;#ip_arrays[*]&#125;</span> ))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">scp -r ~/.ssh <span class="variable">$&#123;ip_arrays[$int]&#125;</span>:~/</span><br><span class="line"><span class="built_in">let</span> <span class="string">"int++"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#SSH免密登录</span></span><br><span class="line"><span class="function"><span class="title">setSSH</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'---------------配置ssh免密登录----------------------'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'------------一路回车即可生成秘钥--------------------'</span></span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'----------秘钥生成完成，开始生成公钥----------------'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'根据提示输入相应的信息'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'----------------------------------------------------'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'Are you sure you want to continue connecting (yes/no)?'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'------------------输入"yes"-------------------------'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'hadoop@localhost s password:'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'--------------输入hadoop用户密码--------------------'</span></span><br><span class="line">ssh-copy-id localhost</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#控制台选择本机角色</span></span><br><span class="line"><span class="function"><span class="title">nameOrData</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'--------------------------'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'1、namenode'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'2、datanode'</span></span><br><span class="line"><span class="built_in">read</span> -p <span class="string">'请选择本机的角色[1-2]:'</span> n</span><br><span class="line"><span class="keyword">case</span> <span class="variable">$n</span> <span class="keyword">in</span></span><br><span class="line">1)<span class="built_in">return</span> 0</span><br><span class="line">;;</span><br><span class="line">2)<span class="built_in">return</span> 1</span><br><span class="line">;;</span><br><span class="line">*)<span class="built_in">echo</span> <span class="string">'输入错误！！！'</span></span><br><span class="line">nameOrData</span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置hosts文件</span></span><br><span class="line"><span class="function"><span class="title">setHosts</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始配置/etc/hosts文件'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'本机IP地址为：'</span><span class="variable">$localIP</span><span class="string">''</span></span><br><span class="line"><span class="built_in">read</span> -p <span class="string">'请输入本机主机名(hostname):'</span> hostname</span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">''</span><span class="variable">$localIP</span><span class="string">'\t'</span><span class="variable">$hostname</span><span class="string">''</span>&gt;&gt;/etc/hosts</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'根据提示输入其他主机名(hostname)'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'-----------------------------------'</span></span><br><span class="line">int=0</span><br><span class="line"><span class="keyword">while</span>(( <span class="variable">$&#123;int&#125;</span>&lt;<span class="variable">$&#123;#ip_arrays[*]&#125;</span> ))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'IP：'</span><span class="variable">$&#123;ip_arrays[$int]&#125;</span><span class="string">''</span></span><br><span class="line"><span class="built_in">read</span> -p <span class="string">"请输入主机名："</span> hostname</span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">''</span><span class="variable">$&#123;ip_arrays[$int]&#125;</span><span class="string">'\t'</span><span class="variable">$hostname</span><span class="string">''</span>&gt;&gt;/etc/hosts</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'-----------------------------------'</span></span><br><span class="line"><span class="built_in">let</span> <span class="string">"int++"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#1、Java环境一键配置</span></span><br><span class="line"><span class="function"><span class="title">javaInstall</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始检查本机环境'</span></span><br><span class="line">java -version</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line">installWget</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始配置JDK，请耐心等待......'</span></span><br><span class="line">installJDK</span><br><span class="line">pathJDK</span><br><span class="line">java -version</span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'JDK配置完成'</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'安装失败，请重新尝试或手动安装'</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'已经配置该环境'</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#2、Hadoop单机版一键安装</span></span><br><span class="line"><span class="function"><span class="title">hadoopInstall</span></span>()&#123;</span><br><span class="line">javaInstall</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始检查本机环境'</span></span><br><span class="line">hadoop</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line">installHadoop</span><br><span class="line">hadoop</span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'hadoop单机版配置完成'</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'安装失败，请重新尝试或手动安装'</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'已经配置该环境'</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#3、Hadoop伪分布式一键安装</span></span><br><span class="line"><span class="function"><span class="title">hadoopInstall2</span></span>()&#123;</span><br><span class="line">javaInstall</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始检查本机环境'</span></span><br><span class="line">hadoop</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line">installHadoop</span><br><span class="line">hadoop</span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'hadoop单机版配置完成，开始配置伪分布式'</span></span><br><span class="line">setHadoop</span><br><span class="line">stopFirewalld</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'配置完成....使用hadoop用户初始化'</span></span><br><span class="line">su hadoop</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'安装失败，请重新尝试或手动安装'</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'hadoop单机版已经安装，开始配置伪分布式'</span></span><br><span class="line">setHadoop</span><br><span class="line">stopFirewalld</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'配置完成....使用hadoop用户初始化'</span></span><br><span class="line">su hadoop</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#4、Hadoop集群部署</span></span><br><span class="line"><span class="function"><span class="title">hadoopInstall3</span></span>()&#123;</span><br><span class="line">nameOrData</span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="comment">#记录IP</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'输入datanode的IP'</span></span><br><span class="line">ipInput</span><br><span class="line"><span class="comment">#namenode配置</span></span><br><span class="line"><span class="comment">#1安装单机版hadoop</span></span><br><span class="line">hadoopInstall</span><br><span class="line"><span class="comment">#2导入集群配置文件</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始导入配置文件'</span></span><br><span class="line">setHadoop2 <span class="variable">$&#123;localIP&#125;</span> <span class="variable">$&#123;ip_arrays[0]&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'配置导入完成'</span></span><br><span class="line"><span class="comment">#3关闭防火墙</span></span><br><span class="line">stopFirewalld</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'防火墙已关闭'</span></span><br><span class="line"><span class="comment">#上传主机配置到datanode</span></span><br><span class="line">int=0</span><br><span class="line"><span class="keyword">while</span>(( <span class="variable">$&#123;int&#125;</span>&lt;<span class="variable">$&#123;#ip_arrays[*]&#125;</span> ))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"开始给第`expr <span class="variable">$&#123;int&#125;</span> + 1`台datanode传送配置文件和安装包"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"IP为：<span class="variable">$&#123;ip_arrays[$&#123;int&#125;</span>]&#125;"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"传送过程需手动输入远程主机root密码"</span></span><br><span class="line"><span class="comment">#scp传送安装包</span></span><br><span class="line">scp $(<span class="built_in">pwd</span>)/install.sh <span class="variable">$&#123;ip_arrays[$int]&#125;</span>:/usr/<span class="built_in">local</span></span><br><span class="line">scp /usr/<span class="built_in">local</span>/$(ls | grep <span class="string">'jdk.*[rpm]$'</span>) <span class="variable">$&#123;ip_arrays[$int]&#125;</span>:/usr/<span class="built_in">local</span></span><br><span class="line">scp -r /usr/<span class="built_in">local</span>/hadoop <span class="variable">$&#123;ip_arrays[$int]&#125;</span>:/usr/<span class="built_in">local</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;ip_arrays[$int]&#125;</span>文件上传完成....."</span></span><br><span class="line"><span class="built_in">let</span> <span class="string">"int++"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">setHosts</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'请登录datanode主机执行该脚本继续完成datanode配置，脚本存储目录/usr/local'</span></span><br><span class="line"><span class="keyword">elif</span> [ $? -eq 1 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="comment">#安装Java</span></span><br><span class="line">javaInstall</span><br><span class="line"><span class="comment">#配置Hadoop环境变量</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'配置环境变量'</span></span><br><span class="line">pathHadoop</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'环境变量配置完成'</span></span><br><span class="line"><span class="comment">#添加用户</span></span><br><span class="line">hadoopUserAdd</span><br><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">stopFirewalld</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'防火墙已关闭'</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'测试安装情况.....'</span></span><br><span class="line">java -version</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'请手动执行source /etc/profile'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'执行java -version确认JDK安装情况'</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">hadoop version</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'请手动执行source /etc/profile'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'执行hadoop version确认hadoop安装情况'</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'datanode配置完成'</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'发生错误！！！'</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#6、集群设置SSH免密登录（使用hadoop用户操作）</span></span><br><span class="line"><span class="function"><span class="title">setSSHS</span></span>()&#123;</span><br><span class="line"><span class="comment">#本机设置免密</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始设置本机免密....'</span></span><br><span class="line">setSSH</span><br><span class="line"><span class="comment">#输入其他电脑IP</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始设置其他主机....'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'输入其他主机ip'</span></span><br><span class="line">ipInput</span><br><span class="line"><span class="comment">#用scp将秘钥发到其他主机</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'开始发送秘钥到其他主机...'</span></span><br><span class="line">scpOutput</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#控制台输入选项</span></span><br><span class="line"><span class="function"><span class="title">consoleInput</span></span>()&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'请输入选项[1-4]'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'1、Java环境一键配置'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'2、Hadoop单机版一键安装'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'3、Hadoop伪分布式一键安装'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'4、Hadoop集群部署'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'5、hadoop初始化（在namenode主机上执行）'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'6、集群设置SSH免密登录（使用hadoop用户操作）'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'请输入选项[1-6]'</span></span><br><span class="line"><span class="built_in">read</span> aNum</span><br><span class="line"><span class="keyword">case</span> <span class="variable">$aNum</span> <span class="keyword">in</span></span><br><span class="line">1)  javaInstall</span><br><span class="line">;;</span><br><span class="line">2)  hadoopInstall</span><br><span class="line">;;</span><br><span class="line">3)  hadoopInstall2</span><br><span class="line">;;</span><br><span class="line">4)  hadoopInstall3</span><br><span class="line">;;</span><br><span class="line">5)  <span class="built_in">echo</span> <span class="string">'Hadoop初始化'</span></span><br><span class="line">hdfs namenode -format</span><br><span class="line">;;</span><br><span class="line">6)  setSSHS</span><br><span class="line">;;</span><br><span class="line">*)  <span class="built_in">echo</span> <span class="string">'没有该选项，请重新输入!!!退出请按Ctrl+c'</span></span><br><span class="line">consoleInput</span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'------------------欢迎使用一键安装------------------'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'为保证安装过程顺利进行，请使用root用户执行该脚本'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'该脚本增加了本地安装包自动安装'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'如果需要脚本安装本地安装包，请将安装包放在/usr/local下'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'hadoop安装包要求以hadoop开头的.tar.gz包'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'JDK安装包要求以jdk开头的.rpm包'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'----------------------------------------------------'</span></span><br><span class="line">consoleInput</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;测试环境&quot;&gt;&lt;a href=&quot;#测试环境&quot; class=&quot;headerlink&quot; title=&quot;测试环境&quot;&gt;&lt;/a&gt;测试环境&lt;/h1&gt;&lt;p&gt;Linux系统版本：CentOS 7&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&quot;实现功能&quot;&gt;&lt;a href=&quot;#实现功能&quot; clas
      
    
    </summary>
    
      <category term="Linux" scheme="https://blog.niclas.cn/categories/Linux/"/>
    
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/tags/Hadoop/"/>
    
      <category term="Linux" scheme="https://blog.niclas.cn/tags/Linux/"/>
    
      <category term="Hadoop部署" scheme="https://blog.niclas.cn/tags/Hadoop%E9%83%A8%E7%BD%B2/"/>
    
      <category term="Shell" scheme="https://blog.niclas.cn/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 7常用基本命令整理</title>
    <link href="https://blog.niclas.cn/post/CentOS-7%E5%B8%B8%E7%94%A8%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"/>
    <id>https://blog.niclas.cn/post/CentOS-7常用基本命令整理/</id>
    <published>2018-10-20T04:04:22.000Z</published>
    <updated>2018-12-24T13:15:17.055Z</updated>
    
    <content type="html"><![CDATA[<h1 id="重启命令"><a href="#重启命令" class="headerlink" title="重启命令"></a>重启命令</h1><ul><li><p><strong>立刻重启(root用户使用)</strong></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br><span class="line"></span><br><span class="line"><span class="built_in">shutdown</span> -r now</span><br><span class="line"></span><br><span class="line">init <span class="number">6</span></span><br></pre></td></tr></table></figure></li><li><p><strong>10分钟后自动重启(root用户使用)</strong></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">shutdown</span> -r <span class="number">10</span></span><br></pre></td></tr></table></figure></li><li><p><strong>在时间为20:35时候重启(root用户使用)</strong></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">shutdown</span> -r <span class="number">20</span>:<span class="number">35</span></span><br></pre></td></tr></table></figure></li><li><p><strong>如果是通过shutdown命令设置重启的话，可以取消重启</strong></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">shutdown</span> -c</span><br></pre></td></tr></table></figure></li></ul><hr><h1 id="关机命令"><a href="#关机命令" class="headerlink" title="关机命令"></a>关机命令</h1><ul><li><p><strong>立刻关机(root用户使用)</strong></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">halt</span><br><span class="line"></span><br><span class="line">poweroff</span><br><span class="line"></span><br><span class="line"><span class="built_in">shutdown</span> -h now</span><br><span class="line"></span><br><span class="line">init <span class="number">0</span></span><br></pre></td></tr></table></figure></li><li><p><strong>10分钟后自动关机</strong></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">shutdown</span> -h <span class="number">10</span></span><br></pre></td></tr></table></figure></li></ul><hr><h1 id="hostname命令"><a href="#hostname命令" class="headerlink" title="hostname命令"></a>hostname命令</h1><h2 id="查看主机名"><a href="#查看主机名" class="headerlink" title="查看主机名"></a>查看主机名</h2><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">hostname</span></span><br></pre></td></tr></table></figure><h2 id="设置主机名"><a href="#设置主机名" class="headerlink" title="设置主机名"></a>设置主机名</h2><ul><li><p><strong>临时修改</strong></p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">hostname</span> 主机名</span><br></pre></td></tr></table></figure></li><li><p><strong>永久修改</strong></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">vi</span> /etc/<span class="built_in">hostname</span></span><br></pre></td></tr></table></figure></li></ul><hr><h1 id="网络服务"><a href="#网络服务" class="headerlink" title="网络服务"></a>网络服务</h1><ul><li><p><strong>查看IP信息</strong></p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ip a</span></span><br></pre></td></tr></table></figure></li><li><p><strong>网络连通性测试</strong></p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping <span class="string">[选项]</span> 目标主机</span><br></pre></td></tr></table></figure></li><li><p><strong>设置网络信息</strong></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>sysconfig<span class="regexp">/network-scripts/i</span>fcfg-ens33</span><br></pre></td></tr></table></figure></li><li><p><strong>重启network网络服务</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service<span class="built_in"> network </span>restart</span><br></pre></td></tr></table></figure></li></ul><h1 id="防火墙设置"><a href="#防火墙设置" class="headerlink" title="防火墙设置"></a>防火墙设置</h1><ul><li><p><strong>查看防火墙状态</strong></p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">systemctl status firewalld</span></span><br></pre></td></tr></table></figure></li><li><p><strong>关闭防火墙</strong></p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="literal">start</span> firewalld</span><br></pre></td></tr></table></figure></li><li><p><strong>禁止开机启动</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="builtin-name">disable</span> firewalld</span><br></pre></td></tr></table></figure></li></ul><h1 id="主机映射文件"><a href="#主机映射文件" class="headerlink" title="主机映射文件"></a>主机映射文件</h1><ul><li><strong>修改主机名与IP映射关系</strong><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>hosts</span><br></pre></td></tr></table></figure></li></ul><h1 id="目录操作命令"><a href="#目录操作命令" class="headerlink" title="目录操作命令"></a>目录操作命令</h1><ul><li><p><strong>查看工作目录（Print Working Directory）</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">pwd</span></span><br></pre></td></tr></table></figure></li><li><p><strong>切换工作目录（Change Directory）</strong></p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd <span class="string">[目录位置]</span></span><br></pre></td></tr></table></figure></li><li><p><strong>列表（List）显示目录内容</strong></p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls<span class="string">[选项]</span>... <span class="string">[目录或文件名]</span></span><br></pre></td></tr></table></figure></li></ul><p>常用命令选项<br>    -l ：详细信息显示<br>    -a：显示所有子目录和文件的信息，包括隐藏文件<br>    -A：类似于“-a”，但不显示“.”和“..”目录的信息<br>    -R：递归显示内容</p><ul><li><p><strong>创建新的目录（Make Directory）</strong></p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir <span class="string">[-p]</span> <span class="string">[/路径/]</span>目录名</span><br></pre></td></tr></table></figure></li><li><p><strong>统计目录及文件的空间占用情况（estimate file space  usage）</strong></p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">du <span class="string">[选项]</span>... <span class="string">[目录或文件名]</span></span><br></pre></td></tr></table></figure></li></ul><p>常用命令选项<br>    -a：统计时包括所有的文件，而不仅仅只统计目录<br>    -h：以更易读的字节单位（K、M等）显示信息<br>    -s：只统计每个参数所占用空间总的大小</p><h1 id="文件操作命令"><a href="#文件操作命令" class="headerlink" title="文件操作命令"></a>文件操作命令</h1><ul><li><p><strong>新建空文件，或更新文件时间标记</strong></p><figure class="highlight irpf90"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">touch</span> 文件名</span><br></pre></td></tr></table></figure></li><li><p><strong>查看文件类型</strong></p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">file</span> 文件名</span><br></pre></td></tr></table></figure></li><li><p><strong>复制（copy）文件或目录</strong></p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp <span class="string">[选项]</span> 源文件或目录… 目标文件或目录</span><br></pre></td></tr></table></figure></li></ul><p>常用命令选项<br>    -r：递归复制整个目录树<br>    -p：保持源文件的属性不变<br>    -f：强制覆盖目标同名文件或目录<br>    -i：需要覆盖文件或目录时进行提醒</p><ul><li><strong>删除（Remove）文件或目录</strong><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm <span class="string">[选项]</span> 文件或目录</span><br></pre></td></tr></table></figure></li></ul><p>常用命令选项<br>    -f：强行删除文件，不进行提醒<br>    -i：删除文件时提醒用户确认<br>    -r：递归删除整个目录树</p><ul><li><strong>移动（Move）文件或目录</strong><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv <span class="string">[选项]</span>... 源文件或目录… 目标文件或目录</span><br></pre></td></tr></table></figure></li></ul><p>如果目标位置与源位置相同，则相当于改名</p><ul><li><strong>显示系统命令所在目录</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">which</span> &lt;选项&gt; <span class="built_in">command</span>（命令名称）</span><br></pre></td></tr></table></figure></li></ul><p>常用命令选项<br>    -a：将所有由PATH路径中可以找到的指令均列出，而不止第一个被找到的指令名称</p><ul><li><strong>find查找</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find <span class="tag">&lt;<span class="name">路径</span>&gt;</span> <span class="tag">&lt;<span class="name">选项</span>&gt;</span> [表达式]</span><br></pre></td></tr></table></figure></li></ul><p>find查找的特点<br>从指定路径下递归向下搜索文件<br>支持按照各种条件方式查找<br>支持对查找到的文件再进一步的使用指令操作<br>（例如：删除、统计大小、复制等）  </p><p>常用命令选项<br>    -name    根据文件名查找<br>    -user    根据文件拥有者查找<br>    -group    根据文件所属组寻找文件<br>    -perm    根据文件权限查找文件<br>    -size    根据文件大小查找文件<br>    -type    根据文件类型查找（f-普通文件，c-字符设备文件，b-块设备文件，l-链接文件，d-目录）<br>    -o    表达式或<br>    -and    表达式与</p><hr><h1 id="文件内容操作命令"><a href="#文件内容操作命令" class="headerlink" title="文件内容操作命令"></a>文件内容操作命令</h1><ul><li><p><strong>显示出文件的全部内容</strong></p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">cat</span></span><br></pre></td></tr></table></figure></li><li><p><strong>全屏方式分页显示文件内容</strong></p><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">more</span></span><br></pre></td></tr></table></figure></li></ul><p>交互操作方法<br>按Enter键向下逐行滚动<br>按空格键向下翻一屏、按b键向上翻一屏<br>按q键退出</p><ul><li><p><strong>与more命令相同</strong></p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">less</span></span><br></pre></td></tr></table></figure></li><li><p><strong>查看文件开头的一部分内容（默认为10行）</strong></p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -<span class="built_in">n</span> 文件名</span><br></pre></td></tr></table></figure></li><li><p><strong>查看文件结尾的少部分内容（默认为10行）</strong></p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -<span class="built_in">n</span> 文件名</span><br></pre></td></tr></table></figure></li><li><p><strong>统计文件中的单词数量（Word Count）等信息</strong></p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wc <span class="string">[选项]</span> 目标文件</span><br></pre></td></tr></table></figure></li></ul><p>常用命令选项<br>-l：统计行数<br>-w：统计单词个数<br>-c：统计字节数</p><ul><li><strong>查找文件里符合条件的字符串</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep [选项] <span class="tag">&lt;<span class="name">关键字</span>&gt;</span> <span class="tag">&lt;<span class="name">文件…</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><p>常用选项<br>-c:计算匹配关键字的行数<br>-i:忽略字符大小写的差别<br>-n:显示匹配的行及其行号<br>-s:不显示不存在或不匹配文本的错误信息<br>-h: 查询多个文件时不显示文件名<br>-l:查询文件时只显示匹配字符所在的文件名<br>–color=auto:将找到的关键字部分加上颜色显示</p><h1 id="压缩命令"><a href="#压缩命令" class="headerlink" title="压缩命令"></a>压缩命令</h1><ul><li><strong>压缩（解压）文件或目录，压缩文件后缀为gz</strong><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gzip <span class="string">[选项]</span> 压缩（解压缩）的文件名</span><br></pre></td></tr></table></figure></li></ul><p>常用选项<br>-d将压缩文件解压（decompress）<br>-l显示压缩文件的大小，未压缩文件的大小，压缩比（list）<br>-v显示文件名和压缩比（verbose）<br>-num用指定的数字num调整压缩的速度，-1或–fast表示最快压缩方法（低压缩比），-9或–best表示最慢压缩方法（高压缩比）。系统缺省值为6</p><ul><li><strong>压缩（解压）文件或目录，压缩文件后缀为bz2</strong><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bzip2 <span class="string">[-cdz]</span> 文档名</span><br></pre></td></tr></table></figure></li></ul><p>常用选项<br>-c将压缩的过程产生的数据输出到屏幕上<br>-d解压缩的参数（decompress）<br>-z压缩的参数（compress）<br>-num 用指定的数字num调整压缩的速度，-1或–fast表示最快压缩方法（低压缩比），-9或–best表示最慢压缩方法（高压缩比）。系统缺省值为6</p><ul><li><strong>压缩、解压文件</strong><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">tar</span> <span class="selector-attr">[cvf]</span>...压缩名 文件名（压缩文件）</span><br><span class="line"><span class="selector-tag">tar</span> <span class="selector-attr">[xvf]</span>...文件名<span class="selector-class">.tar</span>（解压文件）</span><br></pre></td></tr></table></figure></li></ul><p>常用命令选项<br>-c：创建 .tar 格式的包文件<br>-x：解开.tar格式的包文件<br>-v：输出详细信息<br>-f：表示使用归档文件</p><h1 id="文本编辑器"><a href="#文本编辑器" class="headerlink" title="文本编辑器"></a>文本编辑器</h1><ul><li><strong>vi编辑器</strong><br>类Unix系统中默认的文本编辑器<br>vi可以执行输出、删除、查找、替换、块操作等众多文本操作，  而且用户可以根据自己的需要对其进行定制<br>维护Linux系统中的各种配置文件</li><li>vim编辑器<br>vi编辑器的增强版本，习惯上也称为vi</li><li><strong>插入命令</strong><br><img src="/post/CentOS-7常用基本命令整理/1.png" alt="在这里插入图片描述"></li><li><p><strong>定位命令</strong><br><img src="/post/CentOS-7常用基本命令整理/2.png" alt="在这里插入图片描述"></p></li><li><p><strong>删除命令</strong><br>dd:删除当前行<br>ndd:删除光标所在当前行向下数n行<br>D:删除当前行光标所在的位置后面的字符<br>x:向后删除光标所在位置的字符<br>X:向前删除光标前面的字符<br>nX:删除前面的n个字符，光标所在的字符将不会被删</p></li><li><p><strong>复制和粘贴命令</strong><br>yy或Y:复制当前行<br>nyy或nY：复制以下n行<br>p:在光标后面插入buffer中的内容<br>P:在光标前面插入buffer中的内容</p></li><li><p><strong>替换和撤销命令</strong><br>r:取代光标所在处的字符<br>R:从光标所在处开始替换字符，按esc结束<br>u:撤销上一步操作</p></li><li><p><strong>定位命令</strong><br>h:左移一个字符<br>l:右移一个字符<br>j:下移一行<br>k:上移一行<br>$:移至行尾<br>0:移至行首<br>nG:移到第n行</p></li><li><strong>替换操作</strong><br>: s /old/new    将当前行中查找到的第一个字符“old” 串替换为“new”<br>: s /old/new/g    将当前行中查找到的所有字符串“old” 替换为“new”<br>:#,# s/old/new/g     在行号“#,#”范围内替换所有的字符串“old”为“new”<br>:% s/old/new/g    在整个文件范围内替换所有的字符串“old”为“new”<br>:%s/old/new    查找文件中所有行第一次出现的old，替换为new</li><li><strong>其他命令</strong><br>:W[文件路径]保存当前文件<br>:q 如果未对文件做改动则退出<br>:q! 放弃存储名退出<br>:wq或:x 保存退出<h1 id="可视模式"><a href="#可视模式" class="headerlink" title="可视模式"></a>可视模式</h1>v：可视模式<br>V：可视行模式<br>Ctrl+v：可视块模式<br>注意：<br>在所有可视模式中，d和x键可以用删除选定的内容<br>在可视块模式中，选中所需行，按I键输入内容，之后按两次esc键，可在所有选定行光标处添加同样的内容。<h1 id="用户和组"><a href="#用户和组" class="headerlink" title="用户和组"></a>用户和组</h1><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2></li><li><strong>保存用户信息的文件：</strong><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/etc/</span>passwd</span><br></pre></td></tr></table></figure></li></ul><p>用于保存用户的帐号基本信息<br>每一行对应一个用户的帐号记录,一行有7个段位，用“：”隔开<br><img src="/post/CentOS-7常用基本命令整理/3.png" alt="在这里插入图片描述"></p><ul><li><strong>保存密码的文件：</strong><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/etc/</span>shadow</span><br></pre></td></tr></table></figure></li></ul><p>用于保存密码字串、密码有效期等信息<br>每一行对应一个用户的密码记录<br><img src="/post/CentOS-7常用基本命令整理/4.png" alt="在这里插入图片描述"></p><ul><li><strong>保存用户组的文件：</strong><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/etc/g</span>roup</span><br></pre></td></tr></table></figure></li></ul><p>保存组账号基本信息<br>文件每一行表示一组记录，包括组名、GID和组的成员，（组成员显示次组成员）<br><img src="/post/CentOS-7常用基本命令整理/5.png" alt="在这里插入图片描述"></p><ul><li><strong>保存用户组密码的文件：</strong><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/etc/g</span>shadow</span><br></pre></td></tr></table></figure></li></ul><p>保存组帐号的密码信息<br>用户组<br>用户组密码，如果是空或者有“！”，表示没有密码<br>用户组管理者<br>组成员，用逗号“，”隔开</p><ul><li><p><strong>用户配置文件：</strong></p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/etc/</span><span class="keyword">default</span><span class="regexp">/useradd</span></span><br></pre></td></tr></table></figure></li><li><p><strong>用户角色</strong><br>root用户，系统唯一，可以操作系统任何文件和命令，拥有最高权限，UID=0<br>虚拟用户(系统账户)，不具有登录系统能力，但却是系统运行不可缺少的用户。如：bin、daemon、ftp、mail等，UID为1—499之间<br>普通真实用户，可以登录系统，权限有限，靠管理员创建，UID为500—60000之间</p></li></ul><h2 id="用户管理"><a href="#用户管理" class="headerlink" title="用户管理"></a>用户管理</h2><ul><li><strong>添加用户命令</strong><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">useradd</span></span><br></pre></td></tr></table></figure></li></ul><p>-u 指定组ID（uid）<br>-g 指定所属的组名（gid）<br>-G 指定多个组，用逗号“，”分开（Groups）<br>-c 用户描述（comment）<br>-e 失效时间（expire date）</p><ul><li><strong>设置密码</strong><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd   <span class="string">[选项]</span>  &lt;用户名&gt;</span><br></pre></td></tr></table></figure></li></ul><p>-d：清空用户的密码，使之无需密码即可登录<br>-l：锁定用户帐号<br>-S：查看用户帐号的状态（是否被锁定）<br>-u：解锁用户帐号<br>-x:    最大密码使用时间（天）<br>-n:    最小密码使用时间（天）</p><ul><li><strong>修改用户命令</strong></li></ul><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">usermod</span></span><br></pre></td></tr></table></figure><p>-l 修改用户名 （login）usermod -l a b（b改为a）<br>-g 添加组 usermod -g sys tom<br>-G添加多个组 usermod -G sys,root tom<br>–L 锁定用户账号密码（Lock）<br>–U 解锁用户账号（Unlock）</p><ul><li><strong>删除用户命令</strong></li></ul><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">userdel   <span class="string">[选项]</span>  用户名</span><br></pre></td></tr></table></figure><p>-r 删除账号时同时删除目录（remove）</p><hr><h2 id="组管理"><a href="#组管理" class="headerlink" title="组管理"></a>组管理</h2><ul><li><strong>添加组</strong><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">groupadd</span></span><br></pre></td></tr></table></figure></li></ul><p>-g 指定gid</p><ul><li><strong>修改用户组的属性</strong><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">groupmod <span class="string">[选项]</span>  &lt;用户名&gt;</span><br></pre></td></tr></table></figure></li></ul><p>-g：设置想要使用的GID<br>-o：使用已经存在的GID<br>-n：设置想要使用的群组名称</p><ul><li><strong>添加/删除组成员</strong><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpasswd  <span class="string">[选项]</span>  组帐号名</span><br></pre></td></tr></table></figure></li></ul><p>-a：向组内添加一个用户<br>-d：从组内删除一个用户成员<br>-M：定义组成员列表，以逗号分隔</p><ul><li><strong>删除组账号</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">groupdel   <span class="tag">&lt;<span class="name">组账号名</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><p>只能删除那些没有被任何用户指定为主组的组</p><ul><li><strong>显示用户所属组</strong><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">groups <span class="string">[用户名]</span></span><br></pre></td></tr></table></figure></li></ul><hr><h1 id="权限和权限值"><a href="#权限和权限值" class="headerlink" title="权限和权限值"></a>权限和权限值</h1><p>读( r )：读取文件的内容；列出目录里的对象<br>写( w )：允许修改文件；在目录里面新建或者删除文件<br>执行( x )：允许执行文件；允许进入目录里</p><p>除了用字母rwx来表示权限，还可以使用3位数字来表 达文件或目录的权限<br>读：4<br>写：2<br>执行：1</p><h2 id="chmod命令"><a href="#chmod命令" class="headerlink" title="chmod命令"></a>chmod命令</h2><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod [ugoa] [+-=] [rwx] <span class="keyword">file</span>/<span class="keyword">dir</span> 或 chmod nnn <span class="keyword">file</span>/<span class="keyword">dir</span></span><br></pre></td></tr></table></figure><p>u:属主  g:属组  o:其他用户  a:所有用户<br>+:添加权限  -:删除权限  =:赋予权限<br>nnn:三位八进制的权限<br>-R 递归修改指定目录下的所有子文件及文件夹的权限<br>-f 强制改变文件访问特权；如果是文件的拥有者，则得  不到任何错误信息</p><h2 id="chown命令"><a href="#chown命令" class="headerlink" title="chown命令"></a>chown命令</h2><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chown 属主 <span class="keyword">file</span>/<span class="keyword">dir</span> </span><br><span class="line">chown :属组 <span class="keyword">file</span>/<span class="keyword">dir</span></span><br><span class="line">chown 属主:属组 <span class="keyword">file</span>/<span class="keyword">dir</span></span><br></pre></td></tr></table></figure><p>-R：递归的修改指定目录下所有文件、子目录的归属</p><hr><h1 id="软件包管理"><a href="#软件包管理" class="headerlink" title="软件包管理"></a>软件包管理</h1><h2 id="RPM命令使用"><a href="#RPM命令使用" class="headerlink" title="RPM命令使用"></a>RPM命令使用</h2><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">rpm</span></span><br></pre></td></tr></table></figure><p>-i：安装应用程序（install）<br>-e：卸载应用程序（erase）<br>-vh：显示安装进度；（verbose   hash）<br>-U：升级软件包；（update）<br>-qa: 显示所有已安装软件包（query all）</p><h2 id="YUM命令"><a href="#YUM命令" class="headerlink" title="YUM命令"></a>YUM命令</h2><p>Yum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE、CentOS中的Shell前端软件包管理器。基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，无须繁琐地一次次下载、安装。<br><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">yum</span>  <span class="comment">install</span>  <span class="comment">gcc</span><span class="literal">-</span><span class="comment">c</span><span class="literal">+</span><span class="literal">+</span></span><br><span class="line"><span class="comment">yum</span>  <span class="comment">remove</span>  <span class="comment">gcc</span><span class="literal">-</span><span class="comment">c</span><span class="literal">+</span><span class="literal">+</span></span><br><span class="line"><span class="comment">yum</span>  <span class="comment">update</span>  <span class="comment">gcc</span><span class="literal">-</span><span class="comment">c</span><span class="literal">+</span><span class="literal">+</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;重启命令&quot;&gt;&lt;a href=&quot;#重启命令&quot; class=&quot;headerlink&quot; title=&quot;重启命令&quot;&gt;&lt;/a&gt;重启命令&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;立刻重启(root用户使用)&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;hi
      
    
    </summary>
    
      <category term="Linux" scheme="https://blog.niclas.cn/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://blog.niclas.cn/tags/Linux/"/>
    
      <category term="Linux命令" scheme="https://blog.niclas.cn/tags/Linux%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 7部署Hadoop集群（HA高可用集群）</title>
    <link href="https://blog.niclas.cn/post/CentOS-7%E9%83%A8%E7%BD%B2Hadoop%E9%9B%86%E7%BE%A4%EF%BC%88HA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%89/"/>
    <id>https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/</id>
    <published>2018-10-12T03:00:25.000Z</published>
    <updated>2018-12-24T13:46:23.842Z</updated>
    
    <content type="html"><![CDATA[<h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><p>Linux系统版本：CentOS 7 64位</p><p>Hadoop版本：<span class="exturl" data-url="aHR0cHM6Ly9hcmNoaXZlLmFwYWNoZS5vcmcvZGlzdC9oYWRvb3AvY29tbW9uL2hhZG9vcC0yLjcuMy8=" title="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.3/">hadoop-2.7.3<i class="fa fa-external-link"></i></span></p><p>Java版本：<span class="exturl" data-url="aHR0cHM6Ly93d3cub3JhY2xlLmNvbS90ZWNobmV0d29yay9qYXZhL2phdmFzZS9kb3dubG9hZHMvamRrOC1kb3dubG9hZHMtMjEzMzE1MS5odG1s" title="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">jdk-8u181-linux-x64<i class="fa fa-external-link"></i></span></p><p>ZooKeeper版本：<span class="exturl" data-url="aHR0cDovL21pcnJvcnMuc2h1LmVkdS5jbi9hcGFjaGUvem9va2VlcGVyL3pvb2tlZXBlci0zLjQuMTAv" title="http://mirrors.shu.edu.cn/apache/zookeeper/zookeeper-3.4.10/">zookeeper-3.4.10.tar.gz<i class="fa fa-external-link"></i></span></p><p>配置HA高可用集群建议先看一下完全分布式集群的部署过程，整个流程大致一样。</p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTM1ODM0" title="https://blog.csdn.net/u010993514/article/details/82935834">CentOS 7部署Hadoop集群（完全分布式）<i class="fa fa-external-link"></i></span></p><hr><h1 id="Hadoop-组织框架"><a href="#Hadoop-组织框架" class="headerlink" title="Hadoop 组织框架"></a>Hadoop 组织框架</h1><p>Hadoop主要包括两部分：</p><blockquote><p>一部分是HDFS（Hadoop Distributed File System），主要负责分布式存储和计算；</p><p>另一部分是YARN（Yet Another Resource Negotiator， 从Hadoop2.0开始引入），主要负责集群的资源管理和调度。</p></blockquote><h2 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h2><blockquote><p><strong>架构图：</strong></p><p><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/2018101111564592.jpg" alt=""></p><p><strong>1. Active Name Node</strong></p><p>主Master，整个Hadoop集群只能有一个</p><p>管理HDFS文件系统的命名空间</p><p>维护元数据信息</p><p>管理副本的配置和信息（默认三个副本）</p><p>处理客户端读写请求</p><p><strong>2. Standby Name Node</strong></p><p>Active Name Node的热备节点</p><p>Active Name Node故障时可快速切换成新的Active Name Node</p><p>周期性同步edits编辑日志，定期合并fsimage与edits到本地磁盘</p><p><strong>3. Journal Node</strong></p><p>可以被Active Name Node和StandBy Name Node同时访问，用以支持Active Name Node高可用</p><p>Active Name Node在文件系统被修改时，会向Journal Node写入操作日志（edits）</p><p>Standby Name Node同步Journal Node edits日志，使集群中的更新操作可以被共享和同步。</p><p><strong>4. Data Node</strong></p><p>Slave 工作节点，集群一般会启动多个</p><p>负责存储数据块和数据块校验</p><p>执行客户端的读写请求</p><p>通过心跳机制定期向NameNode汇报运行状态和本地所有块的列表信息</p><p>在集群启动时DataNode项NameNode提供存储Block块的列表信息</p><p><strong>5. Block数据块</strong></p><p>HDSF固定的最小的存储单元（默认128M，可配置修改）</p><p>写入到HDFS的文件会被切分成Block数据块（若文件大小小于数据块大小，则不会占用整个数据块）</p><p>默认配置下，每个block有三个副本</p><p><strong>6. Client</strong></p><p>与Name Node交互获取文件的元数据信息</p><p>与Data Node，读取或者写入数据</p><p>通过客户端可以管理HDFS</p></blockquote><h2 id="YARN架构"><a href="#YARN架构" class="headerlink" title="YARN架构"></a>YARN架构</h2><blockquote><p><strong>架构图：</strong></p><p><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181011115137233.jpg" alt=""></p><p><strong>1. Resource Manager</strong></p><p>整个集群只有一个Master。Slave可以有多个，支持高可用</p><p>处理客户端Client请求</p><p>启动／管理／监控ApplicationMaster</p><p>监控NodeManager</p><p>资源的分配和调度</p><p><strong>2. Node Manager</strong></p><p>每个节点只有一个，一般与Data Node部署在同一台机器上且一一对应</p><p>定时向Resource Manager汇报本机资源的使用状况</p><p>处理来自Resource Manager的作业请求，为作业分配Container</p><p>处理来自Application Master的请求，启动和停止Container</p><p><strong>3. Application Master</strong></p><p>每个任务只有一个，负责任务的管理，资源的申请和任务调度</p><p>与Resource Manager协商，为任务申请资源</p><p>与Node Manager通信，启动／停止任务</p><p>监控任务的运行状态和失败处理</p><p><strong>4. Container</strong></p><p>任务运行环境的抽象，只有在分配任务时才会抽象生成一个Container</p><p>负责任务运行资源和环境的维护（节点，内存，CPU）</p><p>负责任务的启动</p><p>虽然在架构图中没有画出，但Hadoop高可用都是基于Zookeeper来实现的。如NameNode高可用，Block高可用，ResourceManager高可用等</p><p>以上部分内容来自：<span class="exturl" data-url="aHR0cHM6Ly9iYWlqaWFoYW8uYmFpZHUuY29tL3M/aWQ9MTU4OTE3NTU1NDI0NjEwMTYxOSZhbXA7d2ZyPXNwaWRlciZhbXA7Zm9yPXBj" title="https://baijiahao.baidu.com/s?id=1589175554246101619&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1589175554246101619&amp;wfr=spider&amp;for=pc<i class="fa fa-external-link"></i></span></p></blockquote><hr><h1 id="HA集群部署规划"><a href="#HA集群部署规划" class="headerlink" title="HA集群部署规划"></a>HA集群部署规划</h1><table><thead><tr><th style="text-align:center">主机名称</th><th style="text-align:center">IP地址</th><th style="text-align:center">用户名称</th><th style="text-align:center">进程</th><th style="text-align:center">安装的软件</th></tr></thead><tbody><tr><td style="text-align:center">node200</td><td style="text-align:center">192.168.33.200</td><td style="text-align:center">hadoop</td><td style="text-align:center">NameNode（Active）、ResourceManager（StandBy）、ZKFC、JobHistoryServer</td><td style="text-align:center">JDK、Hadoop</td></tr><tr><td style="text-align:center">node201</td><td style="text-align:center">192.168.33.201</td><td style="text-align:center">hadoop</td><td style="text-align:center">NameNode（StandBy）、ResourceManager（Active）、ZKFC、WebProxyServer</td><td style="text-align:center">JDK、Hadoop</td></tr><tr><td style="text-align:center">node202</td><td style="text-align:center">192.168.33.202</td><td style="text-align:center">hadoop</td><td style="text-align:center">DataNode、NodeManager、JournalNode、QuorumPeerMain</td><td style="text-align:center">JDK、Hadoop、Zookeeper</td></tr><tr><td style="text-align:center">node203</td><td style="text-align:center">192.168.33.203</td><td style="text-align:center">hadoop</td><td style="text-align:center">DataNode、NodeManager、JournalNode、QuorumPeerMain</td><td style="text-align:center">JDK、Hadoop、Zookeeper</td></tr><tr><td style="text-align:center">node204</td><td style="text-align:center">192.168.33.204</td><td style="text-align:center">hadoop</td><td style="text-align:center">DataNode、NodeManager、JournalNode、QuorumPeerMain</td><td style="text-align:center">JDK、Hadoop、Zookeeper</td></tr></tbody></table><p><strong>规划说明：</strong></p><blockquote><p>HDFS HA通常由两个NameNode组成，一个处于Active状态，另一个处于Standby状态。</p><p>Active NameNode对外提供服务，而Standby NameNode则不对外提供服务，仅同步Active NameNode的状态，以便能够在它失败时快速进行切换。</p><p>Hadoop 2.0官方提供了两种HDFS HA的解决方案，一种是NFS，另一种是QJM。这里我们使用简单的QJM。在该方案中，主备NameNode之间通过一组JournalNode同步元数据信息，一条数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode，这里还配置了一个Zookeeper集群，用于ZKFC故障转移，当Active NameNode挂掉了，会自动切换Standby NameNode为Active状态。</p><p>YARN的ResourceManager也存在单点故障问题，这个问题在hadoop-2.4.1得到了解决：有两个ResourceManager，一个是Active，一个是Standby，状态由Zookeeper进行协调。</p><p>YARN框架下的MapReduce可以开启JobHistoryServer来记录历史任务信息，否则只能查看当前正在执行的任务信息。</p><p>Zookeeper的作用是负责HDFS中NameNode主备节点的选举，和YARN框架下ResourceManaer主备节点的选举。</p><p>部分内容来自：<span class="exturl" data-url="aHR0cHM6Ly93d3cubGludXhpZGMuY29tL0xpbnV4LzIwMTYtMDgvMTM0MTgwLmh0bQ==" title="https://www.linuxidc.com/Linux/2016-08/134180.htm">https://www.linuxidc.com/Linux/2016-08/134180.htm<i class="fa fa-external-link"></i></span></p></blockquote><hr><h1 id="自动故障转移"><a href="#自动故障转移" class="headerlink" title="自动故障转移"></a>自动故障转移</h1><blockquote><p><strong>Zookeeper集群作用：</strong></p><p>一是故障监控。每个NameNode将会和Zookeeper建立一个持久session，如果NameNode失效，那么此session将会过期失效，此后Zookeeper将会通知另一个Namenode，然后触发Failover；</p><p>二是NameNode选举。ZooKeeper提供了简单的机制来实现Acitve Node选举，如果当前Active失效，Standby将会获取一个特定的排他锁，那么获取锁的Node接下来将会成为Active。</p><p><strong>ZKFC：</strong></p><p>ZKFC是一个Zookeeper的客户端，它主要用来监测和管理NameNodes的状态，每个NameNode机器上都会运行一个ZKFC程序</p><p><strong>主要职责：</strong></p><p>一是健康监控。ZKFC间歇性的ping NameNode，得到NameNode返回状态，如果NameNode失效或者不健康，那么ZKFS将会标记其为不健康；</p><p>二是Zookeeper会话管理。当本地NaneNode运行良好时，ZKFC将会持有一个Zookeeper session，如果本地NameNode为Active，它同时也持有一个“排他锁”znode，如果session过期，那么次lock所对应的znode也将被删除；</p><p>三是选举。当集群中其中一个NameNode宕机，Zookeeper会自动将另一个激活。</p><p>此处内容来自：<span class="exturl" data-url="aHR0cHM6Ly93d3cubGludXhpZGMuY29tL0xpbnV4LzIwMTYtMDgvMTM0MTgwLmh0bQ==" title="https://www.linuxidc.com/Linux/2016-08/134180.htm">https://www.linuxidc.com/Linux/2016-08/134180.htm<i class="fa fa-external-link"></i></span></p></blockquote><hr><h1 id="关于集群主机时间"><a href="#关于集群主机时间" class="headerlink" title="关于集群主机时间"></a>关于集群主机时间</h1><p>因为高可用集群的机制，<strong>各主机在集群中的时间需一致</strong>。</p><p>在下面Linux搭建前将虚拟机进行设置，设置方法如下：<br><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181011134257285.jpg" alt=""></p><p>安装完成后对每台主机的时间进行确认，确保每台主机时间一致。</p><hr><h1 id="Linux环境搭建"><a href="#Linux环境搭建" class="headerlink" title="Linux环境搭建"></a>Linux环境搭建</h1><p>按如下方法部署五台主机，主机名与IP地址的对应关系见上文<strong>集群部署规划</strong></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI0ODcx" title="https://blog.csdn.net/u010993514/article/details/82924871">VMware虚拟机安装Linux系统<i class="fa fa-external-link"></i></span></p><p>配置完成之后各主机IP、主机名与时间信息如下：（<strong>时间不一致的自己百度同步集群时间的方法</strong>）</p><p><strong>命令：</strong><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看系统ip信息</span></span><br><span class="line">ip a</span><br><span class="line"><span class="comment">#查看系统时间</span></span><br><span class="line">date</span><br></pre></td></tr></table></figure></p><p><strong>执行结果：</strong><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node200 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:6a:0e:74 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.200/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe6a:e74/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@node200 ~]# date</span><br><span class="line">2018年 10月 11日 星期四 16:57:56 CST</span><br></pre></td></tr></table></figure></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node201 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:60:36:3c brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.201/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe60:363c/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@node201 ~]# date</span><br><span class="line">2018年 10月 11日 星期四 16:57:48 CST</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node202 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:41:4a:f4 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.202/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe41:4af4/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@node202 ~]# date</span><br><span class="line">2018年 10月 11日 星期四 16:58:00 CST</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node203 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:53:27:40 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.203/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe53:2740/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@node203 ~]# date</span><br><span class="line">2018年 10月 11日 星期四 16:58:01 CST</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node204 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:6e:ad:fa brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.204/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe6e:adfa/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@node204 ~]# date</span><br><span class="line">2018年 10月 11日 星期四 16:57:54 CST</span><br></pre></td></tr></table></figure><p><strong>网络测试：</strong></p><p>配置完成之后测试各主机网络互通情况，在每台主机上执行下面两条命令，运行过程中按Ctrl+C可以终止进程，下面就不贴测试效果了<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ping 192.168.33.1</span><br><span class="line">ping www.baidu.com</span><br></pre></td></tr></table></figure></p><hr><h1 id="配置Java环境"><a href="#配置Java环境" class="headerlink" title="配置Java环境"></a>配置Java环境</h1><p><strong>node200、node201、node202、node203、node204都需要安装</strong></p><p>为上面安装的系统配置Java环境变量，本文中就写关键配置步骤与执行命令了，想了解详细的配置过程可以查看：</p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI2NTE0" title="https://blog.csdn.net/u010993514/article/details/82926514">Linux系统下安装Java环境<i class="fa fa-external-link"></i></span></p><p>为了方便，本文就直接使用rpm包安装了，/etc/profile文件暂时不进行配置，到后面配置hadoop单机版时再进行配置</p><p><strong>[1-3]均使用root用户执行</strong></p><p>1、将安装包jdk-8u181-linux-x64.rpm上传到/usr/local目录下</p><p>2、安装rpm包，先设置权限，然后执行rpm命令安装<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod <span class="number">755</span> /usr/local/jdk<span class="number">-8</span>u181-linux-x64.rpm</span><br><span class="line">rpm -ivh /usr/local/jdk<span class="number">-8</span>u181-linux-x64.rpm</span><br></pre></td></tr></table></figure></p><p>3、校验安装情况<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -<span class="built_in">version</span></span><br></pre></td></tr></table></figure></p><hr><h1 id="安装单机版Hadoop"><a href="#安装单机版Hadoop" class="headerlink" title="安装单机版Hadoop"></a>安装单机版Hadoop</h1><p><strong>node200、node201、node202、node203、node204都需要安装</strong></p><p>详细步骤查看：Hadoop部署（三）——CentOS 7部署Hadoop（单机版），这里只简单介绍安装步骤</p><p><strong>[1-5]均使用root用户执行</strong></p><p>1、将压缩包hadoop-2.7.3.tar.gz上传到/usr/local目录下</p><p>2、解压压缩包，进入/usr/local目录，对文件夹重命名<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf /usr/local/hadoop<span class="number">-2.7</span><span class="number">.3</span>.tar.gz</span><br><span class="line">cd /usr/local</span><br><span class="line">mv hadoop<span class="number">-2.7</span><span class="number">.3</span> hadoop</span><br></pre></td></tr></table></figure></p><p>3、创建hadoop用户和hadoop用户组，并设置hadoop用户密码<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">useradd hadoop</span></span><br><span class="line"><span class="attribute">passwd hadoop</span></span><br></pre></td></tr></table></figure></p><p>4、为hadoop用户添加sudo权限<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>sudoers</span><br></pre></td></tr></table></figure></p><p>在root用户下面一行加上hadoop    ALL=(ALL)    ALL，保存并退出（这里需要用wq!强制保存退出）<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Next comes the main part: which users can run what software on</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># which machines (the sudoers file can be shared between multiple</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># systems).</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Syntax:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># user MACHINE=COMMANDS</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># The COMMANDS section may have other options added to it.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allow root to run any commands anywhere</span></span></span><br><span class="line">root    ALL=(ALL)   ALL</span><br><span class="line">hadoop  ALL=(ALL)   ALL</span><br></pre></td></tr></table></figure></p><p>5、将hadoop文件夹的主：组设置成hadoop，/usr目录与/usr/local目录所属主：组均为root，默认权限为755，也就是说其他用户（hadoop）没有写入（w）权限，在这里我们需要将这两个目录其他用户的权限设置为7<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">chown</span> -R hadoop:hadoop hadoop</span><br><span class="line"><span class="keyword">chmod</span> <span class="number">757</span> /usr</span><br><span class="line"><span class="keyword">chmod</span> <span class="number">757</span> /usr/<span class="keyword">local</span></span><br></pre></td></tr></table></figure></p><hr><h1 id="Zookeeper集群安装"><a href="#Zookeeper集群安装" class="headerlink" title="Zookeeper集群安装"></a>Zookeeper集群安装</h1><p><strong>在node202、node203、node204上安装</strong></p><p>Zookeeper是一个开源分布式协调服务，其独特的Leader-Follower集群结构，很好的解决了分布式单点问题。目前主要用于诸如：统一命名服务、配置管理、锁服务、集群管理等场景。大数据应用中主要使用Zookeeper的集群管理功能。</p><p><strong>[1-5]均使用root用户执行</strong></p><p>1、将压缩包zookeeper-3.4.10.tar.gz上传到node202的/usr/local目录下</p><p>2、解压压缩包，进入/usr/local目录，对文件夹重命名<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf /usr/local/zookeeper<span class="number">-3.4</span><span class="number">.10</span>.tar.gz</span><br><span class="line">cd /usr/local</span><br><span class="line">mv zookeeper<span class="number">-3.4</span><span class="number">.10</span> zookeeper</span><br></pre></td></tr></table></figure></p><p>3、修改zookeeper的配置文件，命令如下：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/zookeeper/conf/</span><br><span class="line">cp zoo_sample<span class="selector-class">.cfg</span> zoo.cfg</span><br><span class="line">vi zoo.cfg</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 客户端心跳时间(毫秒)</span></span><br><span class="line"><span class="attribute">tickTime</span>=2000</span><br><span class="line"><span class="comment"># 允许心跳间隔的最大时间</span></span><br><span class="line"><span class="attribute">initLimit</span>=10</span><br><span class="line"><span class="comment"># 同步时限</span></span><br><span class="line"><span class="attribute">syncLimit</span>=5</span><br><span class="line"><span class="comment"># 数据存储目录</span></span><br><span class="line"><span class="attribute">dataDir</span>=/usr/local/zookeeperdata</span><br><span class="line"><span class="comment"># 数据日志存储目录</span></span><br><span class="line"><span class="attribute">dataLogDir</span>=/usr/local/tmp/zookeeperlogs</span><br><span class="line"><span class="comment"># 端口号</span></span><br><span class="line"><span class="attribute">clientPort</span>=2181</span><br><span class="line"><span class="comment"># 集群节点和服务端口配置</span></span><br><span class="line">server.<span class="attribute">1</span>=node202:2888:3888</span><br><span class="line">server.<span class="attribute">2</span>=node203:2888:3888</span><br><span class="line">server.<span class="attribute">3</span>=node204:2888:3888</span><br><span class="line"><span class="comment"># 以下为优化配置</span></span><br><span class="line"><span class="comment"># 服务器最大连接数，默认为10，改为0表示无限制</span></span><br><span class="line"><span class="attribute">maxClientCnxns</span>=0</span><br><span class="line"><span class="comment"># 快照数</span></span><br><span class="line">autopurge.<span class="attribute">snapRetainCount</span>=3</span><br><span class="line"><span class="comment"># 快照清理时间，默认为0</span></span><br><span class="line">autopurge.<span class="attribute">purgeInterval</span>=1</span><br></pre></td></tr></table></figure></p><p>3、修改完zookeeper的配置文件，将<strong>node202</strong>上的zookeeper上传到<strong>其他两台</strong>服务器：<br><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@node202 conf]<span class="comment"># scp -r /usr/local/zookeeper 192.168.33.203:/usr/local/</span></span><br><span class="line">[root@node202 conf]<span class="comment"># scp -r /usr/local/zookeeper 192.168.33.204:/usr/local/</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#这儿输入yes回车</span></span><br><span class="line">Are you sure you want <span class="keyword">to</span> <span class="keyword">continue</span> connecting (<span class="literal">yes</span>/<span class="literal">no</span>)? <span class="literal">yes</span></span><br><span class="line"><span class="comment">#这里输入远程主机的root密码</span></span><br><span class="line">root@<span class="number">192.168</span>.<span class="number">33.204</span><span class="string">'s password:</span></span><br></pre></td></tr></table></figure></p><p>4、在三台主机上创建zookeeper数据存储目录：<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /usr/<span class="built_in">local</span>/zookeeperdata</span><br></pre></td></tr></table></figure></p><p>在文件夹下面创建一个文件，叫myid，并且在文件里写入server.X对应的X<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 集群节点和服务端口配置</span></span><br><span class="line">server.<span class="attribute">1</span>=node202:2888:3888</span><br><span class="line">server.<span class="attribute">2</span>=node203:2888:3888</span><br><span class="line">server.<span class="attribute">3</span>=node204:2888:3888</span><br></pre></td></tr></table></figure></p><p>上述配置中<strong>node202是1，node203是2，node204是3</strong>，所以按如下操作：</p><p>在<strong>node202</strong> 上执行：<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo <span class="string">"1"</span> &gt; <span class="regexp">/usr/</span>local<span class="regexp">/zookeeperdata/myi</span>d</span><br></pre></td></tr></table></figure></p><p>在<strong>node203</strong> 上执行：<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo <span class="string">"2"</span> &gt; <span class="regexp">/usr/</span>local<span class="regexp">/zookeeperdata/myi</span>d</span><br></pre></td></tr></table></figure></p><p>在<strong>node204</strong> 上执行：<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo <span class="string">"3"</span> &gt; <span class="regexp">/usr/</span>local<span class="regexp">/zookeeperdata/myi</span>d</span><br></pre></td></tr></table></figure></p><p>5、将zookeeper文件夹的主：组设置成hadoop<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R <span class="string">hadoop:</span>hadoop <span class="regexp">/usr/</span>local/zookeeper</span><br><span class="line">chown -R <span class="string">hadoop:</span>hadoop <span class="regexp">/usr/</span>local/zookeeperdata</span><br></pre></td></tr></table></figure></p><hr><h1 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h1><p><strong>node200、node201、node202、node203、node204都需要配置，第2步有所区别</strong></p><p><strong>[1-3]均使用root用户执行</strong></p><p>1、编辑/etc/profile文件<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">vi</span> /etc/<span class="keyword">profile</span></span><br></pre></td></tr></table></figure></p><p>2、在末尾加上如下代码</p><p><strong>node200、node201添加如下代码：</strong><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_181-amd64</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/usr/local/hadoop</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$JAVA_HOME</span>/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JRE_HOME</span>=<span class="variable">$JAVA_HOME</span>/jre</span><br></pre></td></tr></table></figure></p><p><strong>node202、node203、node204添加如下代码：</strong><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_181-amd64</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/usr/local/hadoop</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">ZOOKEEPER_HOME</span>=/usr/local/zookeeper</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$JAVA_HOME</span>/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZOOKEEPER_HOME/bin:$PATH</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JRE_HOME</span>=<span class="variable">$JAVA_HOME</span>/jre</span><br></pre></td></tr></table></figure></p><p>3、配置完环境变量之后保存退出，让环境变量立即生效<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span> <span class="regexp">/etc/</span>profile</span><br></pre></td></tr></table></figure></p><h1 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h1><p><strong>node200、node201、node202、node203、node204都需要配置</strong></p><p>CentOS 7使用的是firewalld作为防火墙，与CentOS 6 有所不同</p><p><strong>下面三步均使用root用户执行</strong></p><p>查看防火墙状态：<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">systemctl status firewalld</span></span><br></pre></td></tr></table></figure></p><p>关闭防火墙：<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">stop</span> firewalld</span><br></pre></td></tr></table></figure></p><p>关闭防火墙开机自动启动：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="builtin-name">disable</span> firewalld</span><br></pre></td></tr></table></figure></p><p>更多详情可以了解：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMzMzQ2" title="https://blog.csdn.net/u010993514/article/details/82933346">CentOS 7部署Hadoop（伪分布式）<i class="fa fa-external-link"></i></span></p><hr><h1 id="修改hosts文件"><a href="#修改hosts文件" class="headerlink" title="修改hosts文件"></a>修改hosts文件</h1><p>修改所有主机的/etc/hosts文件，这里使用root用户操作<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>hosts</span><br></pre></td></tr></table></figure></p><p>在文件最后面加上：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.200</span>    <span class="selector-tag">node200</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.201</span>    <span class="selector-tag">node201</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.202</span>    <span class="selector-tag">node202</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.203</span>    <span class="selector-tag">node203</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.204</span>    <span class="selector-tag">node204</span></span><br></pre></td></tr></table></figure></p><p><strong>注意：IP后面是Tab制表符，而不是空格，这里配置完后最好测试一下网络。如果复制粘贴配置完后无法ping通，可能是IP地址后面的空格问题。</strong></p><p>以下为测试方法：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ping node200</span><br><span class="line">ping node201</span><br><span class="line">ping node202</span><br><span class="line">ping node203</span><br><span class="line">ping node204</span><br></pre></td></tr></table></figure></p><hr><p><strong>配置到这里，我们切换到hadoop用户，使用hadoop用户进行下面的操作</strong></p><hr><h1 id="配置SSH免密登录"><a href="#配置SSH免密登录" class="headerlink" title="配置SSH免密登录"></a>配置SSH免密登录</h1><p>具体方法参照：</p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyMDgzMDI3" title="https://blog.csdn.net/u010993514/article/details/82083027">Linux系统配置SSH免密登录(多主机互通)<i class="fa fa-external-link"></i></span></p><p>这里贴关键代码，不展示操作过程：</p><p>在<strong>node200、node201、node202、node203、node204</strong>上分别操作，一路回车就可以了：<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> ~]<span class="variable">$ </span>ssh-keygen -t rsa</span><br><span class="line">[hadoop<span class="variable">@node201</span> ~]<span class="variable">$ </span>ssh-keygen -t rsa</span><br><span class="line">[hadoop<span class="variable">@node202</span> ~]<span class="variable">$ </span>ssh-keygen -t rsa</span><br><span class="line">[hadoop<span class="variable">@node203</span> ~]<span class="variable">$ </span>ssh-keygen -t rsa</span><br><span class="line">[hadoop<span class="variable">@node204</span> ~]<span class="variable">$ </span>ssh-keygen -t rsa</span><br></pre></td></tr></table></figure></p><p>在<strong>node200</strong>上操作：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ ssh-copy-id localhost</span><br><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ scp <span class="regexp">~/.ssh/</span>* <span class="string">node201:</span>~/.ssh</span><br><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ scp <span class="regexp">~/.ssh/</span>* <span class="string">node202:</span>~/.ssh</span><br><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ scp <span class="regexp">~/.ssh/</span>* <span class="string">node203:</span>~/.ssh</span><br><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ scp <span class="regexp">~/.ssh/</span>* <span class="string">node204:</span>~/.ssh</span><br></pre></td></tr></table></figure></p><hr><h1 id="修改Hadoop配置文件"><a href="#修改Hadoop配置文件" class="headerlink" title="修改Hadoop配置文件"></a>修改Hadoop配置文件</h1><p><strong>均使用hadoop用户操作，只需要在++node200++上修改即可</strong></p><p>先进入/usr/local/hadoop/etc/hadoop/文件<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ cd <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span></span><br></pre></td></tr></table></figure></p><p>1、修改hadoop-env.sh文件<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> hadoop]<span class="variable">$ </span>vi hadoop-env.sh</span><br></pre></td></tr></table></figure></p><p>找到export JAVA_HOME=${JAVA_HOME}，在前面加个#注释掉，将JAVA_HOME用路径代替，如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#export JAVA_HOME=$&#123;JAVA_HOME&#125;</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_181-amd64</span><br></pre></td></tr></table></figure></p><p>2、修改core-site.xml文件<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> hadoop]<span class="variable">$ </span>vi core-site.xml</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 指定hdfs的nameservices名称为mycluster，与hdfs-site.xml的HA配置相同 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">&lt;!-- 指定缓存文件存储的路径 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/tmp/hadoop/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">&lt;!-- 配置hdfs文件被永久删除前保留的时间（单位：分钟），默认值为0表明垃圾回收站功能关闭 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">&lt;!-- 指定zookeeper地址，配置HA时需要 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>node202:2181,node203:2181,node204:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>3、修改hdfs-site.xml<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> hadoop]<span class="variable">$ </span>vi hdfs-site.xml</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定hdfs元数据存储的路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/hadoopdata/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 指定hdfs数据存储的路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/hadoopdata/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 数据备份的个数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 关闭权限验证 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 开启WebHDFS功能（基于REST的接口服务） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- //////////////以下为HDFS HA的配置////////////// --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定hdfs的nameservices名称为mycluster --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 指定mycluster的两个namenode的名称分别为nn1,nn2 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置nn1,nn2的rpc通信端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node200:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node201:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置nn1,nn2的http通信端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node200:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node201:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 指定namenode元数据存储在journalnode中的路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://node202:8485;node203:8485;node204:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 指定journalnode日志文件存储的路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/tmp/journalnodelogs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 指定HDFS客户端连接active namenode的java类 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置隔离机制为ssh --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 指定秘钥的位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 开启自动故障转移 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>4、修改mapred-site.xml</p><p>/usr/local/hadoop/etc/hadoop文件夹中并没有mapred-site.xml文件，但提供了模板mapred-site.xml.template，将其复制一份重命名为mapred-site.xml 即可<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node200 hadoop]$ cp mapred-site<span class="selector-class">.xml</span><span class="selector-class">.template</span> mapred-site.xml</span><br><span class="line">[hadoop@node200 hadoop]$ vi mapred-site.xml</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定MapReduce计算框架使用YARN --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 指定jobhistory server的rpc地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node200:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 指定jobhistory server的http地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node200:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 开启uber模式（针对小作业的优化） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置启动uber模式的最大map数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxmaps<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>9<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置启动uber模式的最大reduce数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxreduces<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>5、修改yarn-site.xml<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@master200</span> hadoop]<span class="variable">$ </span>vi yarn-site.xml</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- NodeManager上运行的附属服务，需配置成mapreduce_shuffle才可运行MapReduce程序 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置Web Application Proxy安全代理（防止yarn被攻击） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.web-proxy.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node201:8888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 开启日志 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置日志删除时间为7天，-1为禁用，单位为秒 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 修改日志目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/tmp/hadooplogs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!--配置nodemanager可用的资源内存 </span></span><br><span class="line"><span class="comment">&lt;property&gt;</span></span><br><span class="line"><span class="comment">&lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;</span></span><br><span class="line"><span class="comment">&lt;value&gt;2048&lt;/value&gt;</span></span><br><span class="line"><span class="comment">&lt;/property&gt;</span></span><br><span class="line"><span class="comment">配置nodemanager可用的资源CPU </span></span><br><span class="line"><span class="comment">&lt;property&gt;</span></span><br><span class="line"><span class="comment">&lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;</span></span><br><span class="line"><span class="comment">&lt;value&gt;2&lt;/value&gt;</span></span><br><span class="line"><span class="comment">&lt;/property&gt; </span></span><br><span class="line"><span class="comment"> --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- //////////////以下为YARN HA的配置////////////// --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启YARN HA --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 启用自动故障转移 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 指定YARN HA的名称 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarncluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 指定两个resourcemanager的名称 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置rm1，rm2的主机 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node201<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node200<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置YARN的http端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node201:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node200:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置zookeeper的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node202:2181,node203:2181,node204:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置zookeeper的存储位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-state-store.parent-path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/zookeeperdata/rmstore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 开启yarn resourcemanager restart --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置resourcemanager的状态存储到zookeeper中 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 开启yarn nodemanager restart --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 配置nodemanager IPC的通信端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:45454<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>6、修改slaves文件<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> hadoop]<span class="variable">$ </span>vi slaves</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">node202</span></span><br><span class="line"><span class="symbol">node203</span></span><br><span class="line"><span class="symbol">node204</span></span><br></pre></td></tr></table></figure></p><p><strong>上述关键的配置文件我已经上传至：</strong><br><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1BlbmdTaHVhaXhpbi9oYWRvb3AtMi43LjNfY2VudG9zNw==" title="https://github.com/PengShuaixin/hadoop-2.7.3_centos7">https://github.com/PengShuaixin/hadoop-2.7.3_centos7<i class="fa fa-external-link"></i></span></p><p>可以直接下载下来，通过上传到Linux直接覆盖原来文件的方式进行配置</p><p>7、通过scp将配置文件上传到其他主机<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@node</span>200 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node201:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br><span class="line">[hadoop<span class="meta">@node</span>200 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node202:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br><span class="line">[hadoop<span class="meta">@node</span>200 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node203:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br><span class="line">[hadoop<span class="meta">@node</span>200 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node204:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br></pre></td></tr></table></figure></p><hr><h1 id="Hadoop集群的初始化"><a href="#Hadoop集群的初始化" class="headerlink" title="Hadoop集群的初始化"></a>Hadoop集群的初始化</h1><p>1、启动zookeeper集群（<strong>分别在node202、node203和node204上执行</strong>）<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer<span class="selector-class">.sh</span> start</span><br></pre></td></tr></table></figure></p><p>ps：zookeeper其他命令<br><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看状态</span></span><br><span class="line">zkServer.<span class="keyword">sh </span>status</span><br><span class="line"><span class="comment">#关闭</span></span><br><span class="line">zkServer.<span class="keyword">sh </span>stop</span><br></pre></td></tr></table></figure></p><p>启动后查看状态如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#node202</span></span><br><span class="line">[hadoop@node202 ~]$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/<span class="built_in">..</span>/conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line"><span class="comment">#node203</span></span><br><span class="line">[hadoop@node203 ~]$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/<span class="built_in">..</span>/conf/zoo.cfg</span><br><span class="line">Mode: leader</span><br><span class="line"></span><br><span class="line"><span class="comment">#node204</span></span><br><span class="line">[hadoop@node204 ~]$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/<span class="built_in">..</span>/conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line"><span class="comment">#只有一台主机为leader，剩下的都是follower</span></span><br><span class="line"><span class="comment">#zookeeper配置的主机数一般为2n+1台，且最少需要3台</span></span><br></pre></td></tr></table></figure></p><p>2、格式化ZKFC（在node200上执行）<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> ~]<span class="variable">$ </span>hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure></p><p>出现如下代码说明执行成功：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">11</span> INFO tools.<span class="string">DFSZKFailoverController:</span> Failover controller configured <span class="keyword">for</span> NameNode NameNode at node200/<span class="number">192.168</span><span class="number">.33</span><span class="number">.200</span>:<span class="number">9000</span></span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>zookeeper.version=<span class="number">3.4</span><span class="number">.6</span><span class="number">-1569965</span>, built on <span class="number">02</span><span class="regexp">/20/</span><span class="number">2014</span> <span class="number">09</span>:<span class="number">09</span> GMT</span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>host.name=node200</span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>java.version=<span class="number">1.8</span><span class="number">.0</span>_181</span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>java.vendor=Oracle Corporation</span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>java.home=<span class="regexp">/usr/</span>java<span class="regexp">/jdk1.8.0_181-amd64/</span>jre</span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>java.<span class="keyword">class</span>.path=<span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jaxb-impl-2.2.3-1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jaxb-api-2.2.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/stax-api-1.0-2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/activation-1.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jackson-core-asl-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jackson-mapper-asl-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jackson-jaxrs-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jackson-xc-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jersey-server-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/asm-3.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/log4j-1.2.17.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jets3t-0.9.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/httpclient-4.2.5.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/httpcore-4.2.5.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/java-xmlbuilder-0.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-lang-2.6.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-configuration-1.6.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-digester-1.8.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-beanutils-1.7.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-beanutils-core-1.8.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/slf4j-api-1.7.10.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/slf4j-log4j12-1.7.10.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/avro-1.7.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/paranamer-2.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/snappy-java-1.0.4.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-compress-1.4.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/xz-1.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/protobuf-java-2.5.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/gson-2.2.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/hadoop-auth-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/apacheds-kerberos-codec-2.0.0-M15.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/apacheds-i18n-2.0.0-M15.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/api-asn1-api-1.0.0-M20.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/api-util-1.0.0-M20.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/zookeeper-3.4.6.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/netty-3.6.2.Final.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/curator-framework-2.7.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/curator-client-2.7.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jsch-0.1.42.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/curator-recipes-2.7.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/htrace-core-3.1.0-incubating.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/junit-4.11.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/hamcrest-core-1.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/mockito-all-1.8.5.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/hadoop-annotations-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/guava-11.0.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jsr305-3.0.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-cli-1.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-math3-3.1.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/xmlenc-0.52.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-httpclient-3.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-logging-1.1.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-codec-1.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-io-2.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-net-3.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-collections-3.2.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/servlet-api-2.5.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jetty-6.1.26.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jetty-util-6.1.26.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jsp-api-2.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jersey-core-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jersey-json-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jettison-1.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>hadoop-common<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>common<span class="regexp">/hadoop-common-2.7.3-tests.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>hadoop-nfs<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span><span class="string">hdfs:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-codec<span class="number">-1.4</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>log4j<span class="number">-1.2</span><span class="number">.17</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-logging<span class="number">-1.1</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>netty<span class="number">-3.6</span><span class="number">.2</span>.Final.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>guava<span class="number">-11.0</span><span class="number">.2</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jsr305<span class="number">-3.0</span><span class="number">.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-cli<span class="number">-1.2</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>xmlenc<span class="number">-0.52</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-io<span class="number">-2.4</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>servlet-api<span class="number">-2.5</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jetty<span class="number">-6.1</span><span class="number">.26</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jetty-util<span class="number">-6.1</span><span class="number">.26</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jersey-core<span class="number">-1.9</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jackson-core-asl<span class="number">-1.9</span><span class="number">.13</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jackson-mapper-asl<span class="number">-1.9</span><span class="number">.13</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jersey-server<span class="number">-1.9</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>asm<span class="number">-3.2</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-lang<span class="number">-2.6</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>protobuf-java<span class="number">-2.5</span><span class="number">.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>htrace-core<span class="number">-3.1</span><span class="number">.0</span>-incubating.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-daemon<span class="number">-1.0</span><span class="number">.13</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>netty-all<span class="number">-4.0</span><span class="number">.23</span>.Final.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>xercesImpl<span class="number">-2.9</span><span class="number">.1</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>xml-apis<span class="number">-1.3</span><span class="number">.04</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>leveldbjni-all<span class="number">-1.8</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/hadoop-hdfs-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/hdfs/</span>hadoop-hdfs<span class="number">-2.7</span><span class="number">.3</span>-tests.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/hadoop-hdfs-nfs-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/zookeeper-3.4.6-tests.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-lang-2.6.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/guava-11.0.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jsr305-3.0.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-logging-1.1.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/protobuf-java-2.5.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-cli-1.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/log4j-1.2.17.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jaxb-api-2.2.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/stax-api-1.0-2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/activation-1.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-compress-1.4.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/xz-1.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/servlet-api-2.5.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-codec-1.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jetty-util-6.1.26.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jersey-core-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jersey-client-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jackson-core-asl-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jackson-mapper-asl-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jackson-jaxrs-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jackson-xc-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/guice-servlet-3.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/guice-3.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/javax.inject-1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/aopalliance-1.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-io-2.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jersey-server-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/asm-3.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jersey-json-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jettison-1.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jaxb-impl-2.2.3-1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jersey-guice-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/zookeeper-3.4.6.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/netty-3.6.2.Final.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/leveldbjni-all-1.8.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-collections-3.2.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jetty-6.1.26.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-api<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-common-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-server-common<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-server-nodemanager-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-server-web-proxy<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-server-resourcemanager<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-server-tests-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-client<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-applications-distributedshell<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-registry<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>protobuf-java<span class="number">-2.5</span><span class="number">.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>avro<span class="number">-1.7</span><span class="number">.4</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>jackson-core-asl<span class="number">-1.9</span><span class="number">.13</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>jackson-mapper-asl<span class="number">-1.9</span><span class="number">.13</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>paranamer<span class="number">-2.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>snappy-java<span class="number">-1.0</span><span class="number">.4</span><span class="number">.1</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>commons-compress<span class="number">-1.4</span><span class="number">.1</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>xz<span class="number">-1.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>hadoop-annotations<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>commons-io<span class="number">-2.4</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>jersey-core<span class="number">-1.9</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>jersey-server<span class="number">-1.9</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>asm<span class="number">-3.2</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>log4j<span class="number">-1.2</span><span class="number">.17</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>netty<span class="number">-3.6</span><span class="number">.2</span>.Final.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>leveldbjni-all<span class="number">-1.8</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>guice<span class="number">-3.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>javax.inject<span class="number">-1.</span><span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>aopalliance<span class="number">-1.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>jersey-guice<span class="number">-1.9</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>guice-servlet<span class="number">-3.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>junit<span class="number">-4.11</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>hamcrest-core<span class="number">-1.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-client-core-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/mapreduce/</span>hadoop-mapreduce-client-common<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-client-shuffle-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/mapreduce/</span>hadoop-mapreduce-client-app<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-client-hs-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/mapreduce/</span>hadoop-mapreduce-client-jobclient<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/mapreduce/</span>hadoop-mapreduce-examples<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/contrib/</span>capacity-scheduler<span class="comment">/*.jar</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop/lib/native</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:java.compiler=&lt;NA&gt;</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:os.name=Linux</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:os.arch=amd64</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:os.version=3.10.0-862.el7.x86_64</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:user.name=hadoop</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=node202:2181,node203:2181,node204:2181 sessionTimeout=5000 watcher=org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef@57a3af25</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ClientCnxn: Opening socket connection to server node202/192.168.33.202:2181. Will not attempt to authenticate using SASL (unknown error)</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ClientCnxn: Socket connection established to node202/192.168.33.202:2181, initiating session</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ClientCnxn: Session establishment complete on server node202/192.168.33.202:2181, sessionid = 0x16665c138780001, negotiated timeout = 5000</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO ha.ActiveStandbyElector: Successfully created /hadoop-ha/mycluster in ZK.</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Session: 0x16665c138780001 closed</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 WARN ha.ActiveStandbyElector: Ignoring stale result from old client with sessionId 0x16665c138780001</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ClientCnxn: EventThread shut down</span></span><br></pre></td></tr></table></figure></p><p>3、启动journalnode（<strong>分别在node202、node203和node204上执行</strong>）<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon<span class="selector-class">.sh</span> start journalnode</span><br></pre></td></tr></table></figure></p><p>执行过程如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node202 ~]$ hadoop-daemon.sh start journalnode</span><br><span class="line">starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node202.out</span><br><span class="line">[hadoop@node202 ~]$ jps</span><br><span class="line">1508 QuorumPeerMain</span><br><span class="line">3239 Jps</span><br><span class="line">3182 JournalNode</span><br><span class="line"> </span><br><span class="line">[hadoop@node203 ~]$ hadoop-daemon.sh start journalnode</span><br><span class="line">starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node203.out</span><br><span class="line">[hadoop@node203 ~]$ jps</span><br><span class="line">3289 Jps</span><br><span class="line">1484 QuorumPeerMain</span><br><span class="line">3231 JournalNode</span><br><span class="line"> </span><br><span class="line">[hadoop@node204 ~]$ hadoop-daemon.sh start journalnode</span><br><span class="line">starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node204.out</span><br><span class="line">[hadoop@node204 ~]$ jps</span><br><span class="line">3296 Jps</span><br><span class="line">1490 QuorumPeerMain</span><br><span class="line">3237 JournalNode</span><br><span class="line"> </span><br><span class="line"><span class="comment">#这里用jps命令确认JournalNode进程启动情况</span></span><br><span class="line"><span class="comment">#QuorumPeerMain是第1步操作启动的zookeeper的进程</span></span><br></pre></td></tr></table></figure></p><p>4、格式化HDFS（<strong>在node200上执行</strong>）<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> ~]<span class="variable">$ </span>hdfs namenode -format</span><br></pre></td></tr></table></figure></p><p>执行出现如下代码说明执行成功：<br><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node200 ~]$ hdfs namenode -format</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">22</span> INFO namenode.<span class="symbol">NameNode:</span> <span class="symbol">STARTUP_MSG:</span> </span><br><span class="line">/************************************************************</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span> Starting NameNode</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   host = node200/<span class="number">192.168</span>.<span class="number">33.200</span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   args = [-format]</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   version = <span class="number">2.7</span>.<span class="number">3</span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   classpath = <span class="regexp">/usr/local</span><span class="regexp">/hadoop/etc</span><span class="regexp">/hadoop:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jaxb-impl-2.2.3-1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jaxb-api-2.2.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/stax-api-1.0-2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/activation-1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-core-asl-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-mapper-asl-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-jaxrs-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-xc-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-server-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/asm-3.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/log4j-1.2.17.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jets3t-0.9.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/httpclient-4.2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/httpcore-4.2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/java-xmlbuilder-0.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-lang-2.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-configuration-1.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-digester-1.8.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-beanutils-1.7.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-beanutils-core-1.8.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/slf4j-api-1.7.10.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/slf4j-log4j12-1.7.10.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/avro-1.7.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/paranamer-2.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/snappy-java-1.0.4.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-compress-1.4.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/xz-1.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/protobuf-java-2.5.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/gson-2.2.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hadoop-auth-2.7.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/apacheds-kerberos-codec-2.0.0-M15.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/apacheds-i18n-2.0.0-M15.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/api-asn1-api-1.0.0-M20.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/api-util-1.0.0-M20.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/zookeeper-3.4.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/netty-3.6.2.Final.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-framework-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-client-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsch-0.1.42.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-recipes-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/htrace-core-3.1.0-incubating.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/junit-4.11.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hamcrest-core-1.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/mockito-all-1.8.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hadoop-annotations-2.7.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/guava-11.0.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsr305-3.0.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-cli-1.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-math3-3.1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/xmlenc-0.52.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-httpclient-3.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-logging-1.1.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-codec-1.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-io-2.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-net-3.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-collections-3.2.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/servlet-api-2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jetty-6.1.26.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jetty-util-6.1.26.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsp-api-2.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-core-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-json-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jettison-1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/hadoop</span>-common-<span class="number">2.7</span>.<span class="number">3</span>.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/common/hadoop-common-<span class="number">2.7</span>.<span class="number">3</span>-tests.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/common/hadoop-nfs-<span class="number">2.7</span>.<span class="number">3</span>.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/<span class="symbol">hdfs:</span>/usr/local/hadoop/share/hadoop/hdfs/<span class="class"><span class="keyword">lib</span>/<span class="title">commons</span>-<span class="title">codec</span>-1.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">logging</span>-1.1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">guava</span>-11.0.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jsr305</span>-3.0.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">cli</span>-1.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xmlenc</span>-0.52.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">servlet</span>-<span class="title">api</span>-2.5.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jetty</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jetty</span>-<span class="title">util</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">lang</span>-2.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">htrace</span>-<span class="title">core</span>-3.1.0-<span class="title">incubating</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">daemon</span>-1.0.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">netty</span>-<span class="title">all</span>-4.0.23.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xercesImpl</span>-2.9.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xml</span>-<span class="title">apis</span>-1.3.04.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-2.7.3-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-<span class="title">nfs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">zookeeper</span>-3.4.6-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">lang</span>-2.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guava</span>-11.0.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jsr305</span>-3.0.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">logging</span>-1.1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">cli</span>-1.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jaxb</span>-<span class="title">api</span>-2.2.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">stax</span>-<span class="title">api</span>-1.0-2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">activation</span>-1.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">compress</span>-1.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">xz</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">servlet</span>-<span class="title">api</span>-2.5.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">codec</span>-1.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jetty</span>-<span class="title">util</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">client</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">jaxrs</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">xc</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guice</span>-<span class="title">servlet</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guice</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">javax</span>.<span class="title">inject</span>-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">aopalliance</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">json</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jettison</span>-1.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jaxb</span>-<span class="title">impl</span>-2.2.3-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">guice</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">zookeeper</span>-3.4.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">collections</span>-3.2.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jetty</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">api</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">nodemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">web</span>-<span class="title">proxy</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">applicationhistoryservice</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">resourcemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">tests</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">client</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">sharedcachemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">applications</span>-<span class="title">distributedshell</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">applications</span>-<span class="title">unmanaged</span>-<span class="title">am</span>-<span class="title">launcher</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">registry</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">avro</span>-1.7.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">paranamer</span>-2.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">snappy</span>-<span class="title">java</span>-1.0.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">compress</span>-1.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">xz</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">hadoop</span>-<span class="title">annotations</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">guice</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">javax</span>.<span class="title">inject</span>-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">aopalliance</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">guice</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">guice</span>-<span class="title">servlet</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">junit</span>-4.11.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">hamcrest</span>-<span class="title">core</span>-1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">core</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">shuffle</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">app</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">hs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">jobclient</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">hs</span>-<span class="title">plugins</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">examples</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">jobclient</span>-2.7.3-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">contrib</span>/<span class="title">capacity</span>-<span class="title">scheduler</span>/*.<span class="title">jar</span></span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   build = <span class="symbol">https:</span>/<span class="regexp">/git-wip-us.apache.org/repos</span><span class="regexp">/asf/hadoop</span>.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by <span class="string">'root'</span> on <span class="number">2016</span>-<span class="number">08</span>-<span class="number">18</span><span class="symbol">T01:</span><span class="number">41</span>Z</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   java = <span class="number">1.8</span>.<span class="number">0_181</span></span><br><span class="line">************************************************************<span class="regexp">/</span></span><br><span class="line"><span class="regexp">18/</span><span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">22</span> INFO namenode.<span class="symbol">NameNode:</span> registered UNIX signal handlers <span class="keyword">for</span> [TERM, HUP, INT]</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">22</span> INFO namenode.<span class="symbol">NameNode:</span> createNameNode [-format]</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> WARN common.<span class="symbol">Util:</span> Path /usr/local/hadoopdata/namenode should be specified <span class="keyword">as</span> a URI in configuration files. Please update hdfs configuration.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> WARN common.<span class="symbol">Util:</span> Path /usr/local/hadoopdata/namenode should be specified <span class="keyword">as</span> a URI in configuration files. Please update hdfs configuration.</span><br><span class="line">Formatting using <span class="symbol">clusterid:</span> CID-<span class="number">882887</span>d1-b39c-<span class="number">419</span>c-<span class="number">8945</span>-f9c753f516ae</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> No KeyProvider found.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> fsLock is <span class="symbol">fair:</span><span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">DatanodeManager:</span> dfs.block.invalidate.limit=<span class="number">1000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">DatanodeManager:</span> dfs.namenode.datanode.registration.ip-hostname-check=<span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> dfs.namenode.startup.delay.block.deletion.sec is set to <span class="number">000</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00.000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> The block deletion will start around <span class="number">2018</span> 十月 <span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map BlocksMap</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> <span class="number">2.0</span>% max memory <span class="number">966.7</span> MB = <span class="number">19.3</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">21</span> = <span class="number">2097152</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> dfs.block.access.token.enable=<span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> defaultReplication         = <span class="number">3</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxReplication             = <span class="number">512</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> minReplication             = <span class="number">1</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxReplicationStreams      = <span class="number">2</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> replicationRecheckInterval = <span class="number">3000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> encryptDataTransfer        = <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxNumBlocksToLog          = <span class="number">1000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> fsOwner             = hadoop (<span class="symbol">auth:</span>SIMPLE)</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> supergroup          = supergroup</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> isPermissionEnabled = <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Determined nameservice <span class="symbol">ID:</span> mycluster</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> HA <span class="symbol">Enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Append <span class="symbol">Enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map INodeMap</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> <span class="number">1.0</span>% max memory <span class="number">966.7</span> MB = <span class="number">9.7</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">20</span> = <span class="number">1048576</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSDirectory:</span> ACLs enabled? <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSDirectory:</span> XAttrs enabled? <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSDirectory:</span> Maximum size <span class="keyword">of</span> an <span class="symbol">xattr:</span> <span class="number">16384</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">NameNode:</span> Caching file names occuring more than <span class="number">10</span> times</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map cachedBlocks</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> <span class="number">0.25</span>% max memory <span class="number">966.7</span> MB = <span class="number">2.4</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">18</span> = <span class="number">262144</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.threshold-pct = <span class="number">0.9990000128746033</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.min.datanodes = <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.extension     = <span class="number">30000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.window.num.buckets = <span class="number">10</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.num.users = <span class="number">10</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.windows.minutes = <span class="number">1</span>,<span class="number">5</span>,<span class="number">25</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Retry cache on namenode is enabled</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Retry cache will use <span class="number">0.03</span> <span class="keyword">of</span> total heap and retry cache entry expiry time is <span class="number">600000</span> millis</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map NameNodeRetryCache</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> <span class="number">0.029999999329447746</span>% max memory <span class="number">966.7</span> MB = <span class="number">297.0</span> KB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">15</span> = <span class="number">32768</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO namenode.<span class="symbol">FSImage:</span> Allocated new <span class="symbol">BlockPoolId:</span> BP-<span class="number">1162737530</span>-<span class="number">192.168</span>.<span class="number">33.200</span>-<span class="number">1539308185287</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO common.<span class="symbol">Storage:</span> Storage directory /usr/local/hadoopdata/namenode has been successfully formatted.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO namenode.<span class="symbol">FSImageFormatProtobuf:</span> Saving image file /usr/local/hadoopdata/namenode/current/fsimage.ckpt_0000000000000000000 using no compression</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO namenode.<span class="symbol">FSImageFormatProtobuf:</span> Image file /usr/local/hadoopdata/namenode/current/fsimage.ckpt_0000000000000000000 <span class="keyword">of</span> size <span class="number">352</span> bytes saved in <span class="number">0</span> seconds.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO namenode.<span class="symbol">NNStorageRetentionManager:</span> Going to retain <span class="number">1</span> images <span class="keyword">with</span> txid &gt;= <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO util.<span class="symbol">ExitUtil:</span> Exiting <span class="keyword">with</span> status <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO namenode.<span class="symbol">NameNode:</span> <span class="symbol">SHUTDOWN_MSG:</span> </span><br><span class="line">/************************************************************</span><br><span class="line"><span class="symbol">SHUTDOWN_MSG:</span> Shutting down NameNode at node200/<span class="number">192.168</span>.<span class="number">33.200</span></span><br><span class="line">************************************************************<span class="regexp">/</span></span><br></pre></td></tr></table></figure></p><p>5、将格式化后<strong>node200</strong>节点hadoop工作目录中的元数据目录复制到<strong>node201</strong>节点<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoopdata node201:/</span>usr<span class="regexp">/local/</span></span><br></pre></td></tr></table></figure></p><p>6、初始化完毕后可关闭journalnode（<strong>分别在node202、node203和node204上执行</strong>）<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon<span class="selector-class">.sh</span> stop journalnode</span><br></pre></td></tr></table></figure></p><hr><h1 id="Hadoop集群的启动"><a href="#Hadoop集群的启动" class="headerlink" title="Hadoop集群的启动"></a>Hadoop集群的启动</h1><p>配置了好久，看到可以启动了是不是特别开心，下面就一步步启动我们的集群吧</p><h2 id="启动步骤"><a href="#启动步骤" class="headerlink" title="启动步骤"></a>启动步骤</h2><p>1、启动zookeeper集群（<strong>分别在node202、node203和node204上执行</strong>）<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer<span class="selector-class">.sh</span> start</span><br></pre></td></tr></table></figure></p><p>在初始化过程中，如果启动了zookeeper没有关闭进程，在这里就不用重复启动了</p><p>2、启动HDFS（<strong>在node200上执行</strong>）<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> ~]<span class="variable">$ </span>start-dfs.sh</span><br></pre></td></tr></table></figure></p><p>此命令分别在<strong>node200、node201</strong>节点启动了<strong>NameNode</strong>和<strong>ZKFC</strong>，分别在<strong>node202、node203、node204</strong>节点启动了<strong>DataNode</strong>和<strong>JournalNode</strong>，如下所示。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node200 ~]$ start-dfs.sh</span><br><span class="line">Starting namenodes on [node200 node201]</span><br><span class="line">node200: starting namenode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-namenode-node200.out</span><br><span class="line">node201: starting namenode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-namenode-node201.out</span><br><span class="line">node204: starting datanode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-datanode-node204.out</span><br><span class="line">node202: starting datanode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-datanode-node202.out</span><br><span class="line">node203: starting datanode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-datanode-node203.out</span><br><span class="line">Starting journal nodes [node202 node203 node204]</span><br><span class="line">node202: starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node202.out</span><br><span class="line">node204: starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node204.out</span><br><span class="line">node203: starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node203.out</span><br><span class="line">Starting ZK Failover Controllers on NN hosts [node200 node201]</span><br><span class="line">node200: starting zkfc,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-zkfc-node200.out</span><br><span class="line">node201: starting zkfc,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-zkfc-node201.out</span><br></pre></td></tr></table></figure></p><p>3、启动YARN（<strong>在node201上执行</strong>）<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node201</span> ~]<span class="variable">$ </span>start-yarn.sh</span><br></pre></td></tr></table></figure></p><p>此命令在<strong>node201</strong>节点启动了<strong>ResourceManager</strong>，分别在<strong>node202、node203、node204</strong>节点启动了<strong>NodeManager</strong>。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node201 ~]$ start-yarn.sh</span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-resourcemanager-node201.out</span><br><span class="line">node202: starting nodemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-nodemanager-node202.out</span><br><span class="line">node203: starting nodemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-nodemanager-node203.out</span><br><span class="line">node204: starting nodemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-nodemanager-node204.out</span><br></pre></td></tr></table></figure></p><p>4、启动YARN的另一个ResourceManager（在<strong>node200</strong>执行，用于容灾）<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> ~]<span class="variable">$ </span>yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#执行过程如下</span></span><br><span class="line">starting resourcemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-resourcemanager-node200.out</span><br></pre></td></tr></table></figure><p>5、启动YARN的安全代理（在<strong>node201</strong>执行）<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node201</span> ~]<span class="variable">$ </span>yarn-daemon.sh start proxyserver</span><br></pre></td></tr></table></figure></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#执行过程如下</span></span><br><span class="line">starting proxyserver,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-proxyserver-node201.out</span><br></pre></td></tr></table></figure><p><strong>备注：proxyserver充当防火墙的角色，可以提高访问集群的安全性</strong></p><p>6、启动YARN的历史任务服务（在<strong>node200</strong>执行）<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#方法一：</span></span><br><span class="line">[hadoop@node200 ~]$ mr-jobhistory-daemon.sh start historyserver</span><br><span class="line"> </span><br><span class="line"><span class="comment">#执行过程如下</span></span><br><span class="line">starting historyserver,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/mapred-hadoop-historyserver-node200.out</span><br><span class="line"> </span><br><span class="line"><span class="comment">#方法二：</span></span><br><span class="line">[hadoop@node200 ~]$ yarn-daemon.sh start historyserver</span><br></pre></td></tr></table></figure></p><p>备注：<strong>yarn-daemon.sh start historyserver</strong>已被弃用；CDH版本似乎有个问题，即mapred-site.xml配置的的mapreduce.jobhistory.address和mapreduce.jobhistory.webapp.address参数似乎不起作用，实际对应的端口号是10200和8188，而且部需要配置就可以在任意节点上开启历史任务服务。</p><h2 id="集群进程查看"><a href="#集群进程查看" class="headerlink" title="集群进程查看"></a>集群进程查看</h2><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node200 ~]$ jps</span><br><span class="line"><span class="number">5313</span> DFSZKFailoverController</span><br><span class="line"><span class="number">5842</span> ResourceManager</span><br><span class="line"><span class="number">7049</span> Jps</span><br><span class="line"><span class="number">5002</span> NameNode</span><br><span class="line"><span class="number">6733</span> JobHistoryServer</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node201 ~]$ jps</span><br><span class="line"><span class="number">4726</span> NameNode</span><br><span class="line"><span class="number">4839</span> DFSZKFailoverController</span><br><span class="line"><span class="number">6794</span> Jps</span><br><span class="line"><span class="number">5181</span> ResourceManager</span><br><span class="line"><span class="number">6110</span> WebAppProxyServer</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node202 ~]$ jps</span><br><span class="line"><span class="number">1508</span> QuorumPeerMain</span><br><span class="line"><span class="number">5111</span> NodeManager</span><br><span class="line"><span class="number">4696</span> DataNode</span><br><span class="line"><span class="number">4794</span> JournalNode</span><br><span class="line"><span class="number">6318</span> Jps</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node203 ~]$ jps</span><br><span class="line"><span class="number">5080</span> NodeManager</span><br><span class="line"><span class="number">1484</span> QuorumPeerMain</span><br><span class="line"><span class="number">4668</span> DataNode</span><br><span class="line"><span class="number">4767</span> JournalNode</span><br><span class="line"><span class="number">6303</span> Jps</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node204 ~]$ jps</span><br><span class="line"><span class="number">1490</span> QuorumPeerMain</span><br><span class="line"><span class="number">6307</span> Jps</span><br><span class="line"><span class="number">4647</span> DataNode</span><br><span class="line"><span class="number">5064</span> NodeManager</span><br><span class="line"><span class="number">4746</span> JournalNode</span><br></pre></td></tr></table></figure><h2 id="Web界面截图"><a href="#Web界面截图" class="headerlink" title="Web界面截图"></a>Web界面截图</h2><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p><strong>node200：</strong><span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMjAwOjUwMDcwLw==" title="http://192.168.33.200:50070/">http://192.168.33.200:50070<i class="fa fa-external-link"></i></span>，可看到NameNode为active状态  </p><p><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181012103629681.jpg" alt=""></p><p><strong>node201：</strong><span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMjAxOjUwMDcwLw==" title="http://192.168.33.201:50070/">http://192.168.33.201:50070<i class="fa fa-external-link"></i></span>，可看到NameNode为standby状态  </p><p><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181012103909917.jpg" alt=""></p><h3 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h3><p><strong>node201:</strong><span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMjAxOjgwODgvY2x1c3Rlcg==" title="http://192.168.33.201:8088/cluster">http://192.168.33.201:8088<i class="fa fa-external-link"></i></span>，可看到ResourceManager为active状态 </p><p><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181012104647139.jpg" alt=""></p><p><strong>node200:</strong><span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMjAwOjgwODgvY2x1c3Rlcg==" title="http://192.168.33.200:8088/cluster">http://192.168.33.200:8088<i class="fa fa-external-link"></i></span>，此时ResourceManager为standby状态，</p><p>网页无法直接访问，会自动跳转到node201的页面</p><hr><h1 id="相关推荐"><a href="#相关推荐" class="headerlink" title="相关推荐"></a>相关推荐</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTE0ODI3" title="https://blog.csdn.net/u010993514/article/details/82914827">在Windows中安装Hadoop（非虚拟机安装）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMwMzUx" title="https://blog.csdn.net/u010993514/article/details/82930351">CentOS 7部署Hadoop（单机版）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMzMzQ2" title="https://blog.csdn.net/u010993514/article/details/82933346">CentOS 7部署Hadoop（伪分布式）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTM1ODM0" title="https://blog.csdn.net/u010993514/article/details/82935834">CentOS 7部署Hadoop集群（完全分布式）<i class="fa fa-external-link"></i></span></p><hr><p>到这里就配置完整个集群啦，若在配置过程中遇到什么问题，欢迎在下方评论区留言一起讨论！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;测试环境&quot;&gt;&lt;a href=&quot;#测试环境&quot; class=&quot;headerlink&quot; title=&quot;测试环境&quot;&gt;&lt;/a&gt;测试环境&lt;/h1&gt;&lt;p&gt;Linux系统版本：CentOS 7 64位&lt;/p&gt;
&lt;p&gt;Hadoop版本：&lt;span class=&quot;exturl&quot; da
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/tags/Hadoop/"/>
    
      <category term="Linux" scheme="https://blog.niclas.cn/tags/Linux/"/>
    
      <category term="HA高可用集群" scheme="https://blog.niclas.cn/tags/HA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/"/>
    
      <category term="Zookeeper" scheme="https://blog.niclas.cn/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 7部署Hadoop集群（完全分布式）</title>
    <link href="https://blog.niclas.cn/post/CentOS-7%E9%83%A8%E7%BD%B2Hadoop%E9%9B%86%E7%BE%A4%EF%BC%88%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%89/"/>
    <id>https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（完全分布式）/</id>
    <published>2018-10-04T08:49:42.000Z</published>
    <updated>2018-12-24T13:46:33.336Z</updated>
    
    <content type="html"><![CDATA[<h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><p>Linux系统版本：CentOS 7 64位</p><p>Hadoop版本：<span class="exturl" data-url="aHR0cHM6Ly9hcmNoaXZlLmFwYWNoZS5vcmcvZGlzdC9oYWRvb3AvY29tbW9uL2hhZG9vcC0yLjcuMy8=" title="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.3/">hadoop-2.7.3<i class="fa fa-external-link"></i></span></p><p>Java版本：<span class="exturl" data-url="aHR0cHM6Ly93d3cub3JhY2xlLmNvbS90ZWNobmV0d29yay9qYXZhL2phdmFzZS9kb3dubG9hZHMvamRrOC1kb3dubG9hZHMtMjEzMzE1MS5odG1s" title="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">jdk-8u181-linux-x64<i class="fa fa-external-link"></i></span></p><hr><h1 id="集群服务器节点与进程"><a href="#集群服务器节点与进程" class="headerlink" title="集群服务器节点与进程"></a>集群服务器节点与进程</h1><p>Hadoop中的HDFS和YARN都是主从结构，主从结构中的主节点和从节点有多重概念方式：</p><table><thead><tr><th style="text-align:center">主节点</th><th style="text-align:center">从节点</th></tr></thead><tbody><tr><td style="text-align:center">master</td><td style="text-align:center">slave</td></tr><tr><td style="text-align:center">管理者</td><td style="text-align:center">工作者</td></tr><tr><td style="text-align:center">leader</td><td style="text-align:center">followe</td></tr></tbody></table><p>Hadoop集群中各个角色的名称：</p><table><thead><tr><th style="text-align:center">服务</th><th style="text-align:center">主节点</th><th style="text-align:center">从节点</th></tr></thead><tbody><tr><td style="text-align:center">HDFS</td><td style="text-align:center">NameNode</td><td style="text-align:center">DataNode</td></tr><tr><td style="text-align:center">YARN</td><td style="text-align:center">ResourceManager</td><td style="text-align:center">NodeManager</td></tr></tbody></table><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p><strong>NameNode：</strong>主Master，整个Hadoop集群只能有一个，管理HDFS文件系统的命名空间，维护元数据信息，管理副本的配置和信息（默认三个副本），处理客户端读写请求。</p><p><strong>DataNode：</strong>Slave 工作节点，集群一般会启动多个，负责存储数据块和数据块校验，执行客户端的读写请求，通过心跳机制定期向NameNode汇报运行状态和本地所有块的列表信息，在集群启动时DataNode项NameNode提供存储Block块的列表信息。</p><h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><p><strong>ResourceManager：</strong>整个集群只有一个Master，Slave可以有多个，支持高可用，处理客户端Client请求，启动／管理／监控ApplicationMaster，监控NodeManager，资源的分配和调度。</p><p><strong>NodeManager：</strong>每个节点只有一个，一般与Data Node部署在同一台机器上且一一对应，定时向Resource Manager汇报本机资源的使用状况，处理来自Resource Manager的作业请求，为作业分配Container，处理来自Application Master的请求，启动和停止Container</p><p><strong>为增加集群的容灾性，将对SecondaryNameNode进行配置</strong></p><p><strong>SecondaryNameNode：</strong>备份所有数据分布情况，当Namenode服务器宕机（日常所说的死机）时，可通过该服务器来恢复数据。</p><hr><h1 id="集群部署规划"><a href="#集群部署规划" class="headerlink" title="集群部署规划"></a>集群部署规划</h1><table><thead><tr><th style="text-align:center">主机名称</th><th style="text-align:center">IP地址</th><th style="text-align:center">用户名称</th><th style="text-align:center">进程</th></tr></thead><tbody><tr><td style="text-align:center">node101</td><td style="text-align:center">192.168.33.101</td><td style="text-align:center">hadoop</td><td style="text-align:center">NameNode、ResourceManager</td></tr><tr><td style="text-align:center">node102</td><td style="text-align:center">192.168.33.102</td><td style="text-align:center">hadoop</td><td style="text-align:center">DataNode、NodeManager、SecondaryNameNode</td></tr><tr><td style="text-align:center">node103</td><td style="text-align:center">192.168.33.103</td><td style="text-align:center">hadoop</td><td style="text-align:center">DataNode、NodeManager</td></tr><tr><td style="text-align:center">node104</td><td style="text-align:center">192.168.33.104</td><td style="text-align:center">hadoop</td><td style="text-align:center">DataNode、NodeManager</td></tr></tbody></table><hr><h1 id="搭建Linux系统"><a href="#搭建Linux系统" class="headerlink" title="搭建Linux系统"></a>搭建Linux系统</h1><p>按如下方法部署四台主机，主机名与IP地址的对应关系见上文集群部署规划</p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI0ODcx" title="https://blog.csdn.net/u010993514/article/details/82924871">VMware虚拟机安装Linux系统<i class="fa fa-external-link"></i></span></p><p>配置完成之后各主机IP与主机名信息如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node101 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:81:55:83 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.101/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe81:5583/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node102 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:c2:52:70 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.102/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fec2:5270/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node103 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:9b:9e:e2 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.103/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe9b:9ee2/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node104 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:76:44:a4 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.104/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe76:44a4/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft foreve</span><br></pre></td></tr></table></figure><p>配置完成之后测试各主机网络互通情况，在每台主机上执行下面两条命令，运行过程中按Ctrl+C可以终止进程，下面就不贴测试效果了<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ping 192.168.33.1</span><br><span class="line">ping www.baidu.com</span><br></pre></td></tr></table></figure></p><hr><h1 id="配置Java环境"><a href="#配置Java环境" class="headerlink" title="配置Java环境"></a>配置Java环境</h1><p>为上面安装的系统配置Java环境变量，本文中就写关键配置步骤与执行命令了，想了解详细的配置过程可以查看：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI2NTE0" title="https://blog.csdn.net/u010993514/article/details/82926514">Linux系统下安装Java环境<i class="fa fa-external-link"></i></span></p><p>为了方便，本文就直接使用rpm包安装了，/etc/profile文件暂时不进行配置，到后面配置hadoop单机版时再进行配置</p><p><strong>[1-3]均使用root用户执行</strong></p><p>1、将安装包jdk-8u181-linux-x64.rpm上传到/usr/local目录下</p><p>2、安装rpm包，先设置权限，然后执行rpm命令安装<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod <span class="number">755</span> /usr/local/jdk<span class="number">-8</span>u181-linux-x64.rpm</span><br><span class="line">rpm -ivh /usr/local/jdk<span class="number">-8</span>u181-linux-x64.rpm</span><br></pre></td></tr></table></figure></p><p>3、校验安装情况<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -<span class="built_in">version</span></span><br></pre></td></tr></table></figure></p><hr><h1 id="安装单机版Hadoop"><a href="#安装单机版Hadoop" class="headerlink" title="安装单机版Hadoop"></a>安装单机版Hadoop</h1><p>详细步骤查看：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI2NTE0" title="https://blog.csdn.net/u010993514/article/details/82926514">Hadoop部署（二）——Linux系统下安装Java环境<i class="fa fa-external-link"></i></span>，这里只简单介绍安装步骤</p><p><strong>[1-5]均使用root用户执行</strong></p><p>1、将压缩包hadoop-2.7.3.tar.gz上传到/usr/local目录下  </p><p>2、解压压缩包，进入/usr/local目录，对文件夹重命名<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf /usr/local/hadoop<span class="number">-2.7</span><span class="number">.3</span>.tar.gz</span><br><span class="line">cd /usr/local</span><br><span class="line">mv hadoop<span class="number">-2.7</span><span class="number">.3</span> hadoop</span><br></pre></td></tr></table></figure></p><p>3、创建hadoop用户和hadoop用户组，并设置hadoop用户密码<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">useradd hadoop</span></span><br><span class="line"><span class="attribute">passwd hadoop</span></span><br></pre></td></tr></table></figure></p><p>4、为hadoop用户添加sudo权限<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>sudoers</span><br></pre></td></tr></table></figure></p><p>在root用户下面一行加上hadoop    ALL=(ALL)    ALL，保存并退出（这里需要用wq!强制保存退出）<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Next comes the main part: which users can run what software on</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># which machines (the sudoers file can be shared between multiple</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># systems).</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Syntax:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#      user    MACHINE=COMMANDS</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># The COMMANDS section may have other options added to it.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allow root to run any commands anywhere</span></span></span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">hadoop  ALL=(ALL)       ALL</span><br></pre></td></tr></table></figure></p><p>5、将hadoop文件夹的主：组设置成hadoop，/usr目录与/usr/local目录所属主：组均为root，默认权限为755，也就是说其他用户（hadoop）没有写入（w）权限，在这里我们需要将这两个目录其他用户的权限设置为7<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">chown</span> -R hadoop:hadoop hadoop</span><br><span class="line"><span class="keyword">chmod</span> <span class="number">757</span> /usr</span><br><span class="line"><span class="keyword">chmod</span> <span class="number">757</span> /usr/<span class="keyword">local</span></span><br></pre></td></tr></table></figure></p><hr><h1 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h1><p><strong>[1-3]均使用root用户执行</strong></p><p>1、编辑/etc/profile文件<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">vi</span> /etc/<span class="keyword">profile</span></span><br></pre></td></tr></table></figure></p><p>2、在末尾加上如下几行代码<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_181-amd64</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/usr/local/hadoop</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$JAVA_HOME</span>/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JRE_HOME</span>=<span class="variable">$JAVA_HOME</span>/jre</span><br></pre></td></tr></table></figure></p><p>3、配置完环境变量之后保存退出，让环境变量立即生效<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span> <span class="regexp">/etc/</span>profile</span><br></pre></td></tr></table></figure></p><hr><h1 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h1><p>CentOS 7使用的是firewalld作为防火墙，与CentOS 6 有所不同</p><p><strong>下面三步均使用root用户执行</strong></p><p><strong>查看防火墙状态：</strong><br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">systemctl status firewalld</span></span><br></pre></td></tr></table></figure></p><p><strong>关闭防火墙：</strong><br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">stop</span> firewalld</span><br></pre></td></tr></table></figure></p><p><strong>关闭防火墙开机自动启动：</strong><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="builtin-name">disable</span> firewalld</span><br></pre></td></tr></table></figure></p><p>更多详情可以了解：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMzMzQ2" title="https://blog.csdn.net/u010993514/article/details/82933346">CentOS 7部署Hadoop（伪分布式）<i class="fa fa-external-link"></i></span></p><hr><h1 id="修改hosts文件"><a href="#修改hosts文件" class="headerlink" title="修改hosts文件"></a>修改hosts文件</h1><p>修改所有主机的/etc/hosts文件，这里使用root用户操作<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>hosts</span><br></pre></td></tr></table></figure></p><p>在文件后面加上<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.101</span>    <span class="selector-tag">node101</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.102</span>    <span class="selector-tag">node102</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.103</span>    <span class="selector-tag">node103</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.104</span>    <span class="selector-tag">node104</span></span><br></pre></td></tr></table></figure></p><p><strong>注意：此处IP地址后面为Tab制表符，而不是空格</strong></p><hr><h1 id="配置SSH免密登录"><a href="#配置SSH免密登录" class="headerlink" title="配置SSH免密登录"></a>配置SSH免密登录</h1><p>所有步骤均使用hadoop用户进行操作，方法参照：</p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyMDgzMDI3" title="https://blog.csdn.net/u010993514/article/details/82083027">Linux系统配置SSH免密登录(多主机互通)<i class="fa fa-external-link"></i></span><br><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在每台主机上执行ssh-keygen -t rsa</span></span><br><span class="line">[hadoop@node101 ~]$ ssh-keygen -t rsa</span><br><span class="line">[hadoop@node102 ~]$ ssh-keygen -t rsa</span><br><span class="line">[hadoop@node103 ~]$ ssh-keygen -t rsa</span><br><span class="line">[hadoop@node104 ~]$ ssh-keygen -t rsa</span><br><span class="line"> </span><br><span class="line"><span class="comment">#生成authorized_keys</span></span><br><span class="line">[hadoop@node101 ~]$ ssh-copy-id localhost</span><br><span class="line"> </span><br><span class="line"><span class="comment">#将node101上的文件通过scp复制到其他主机，覆盖其他主机的密钥文件</span></span><br><span class="line"> </span><br><span class="line">[hadoop@node101 ~]$ scp -r ~<span class="regexp">/.ssh/</span>* <span class="number">192.168</span>.<span class="number">33.102</span>:~/.ssh</span><br><span class="line"> </span><br><span class="line">The authenticity <span class="keyword">of</span> host <span class="string">'192.168.33.102 (192.168.33.102)'</span> can<span class="string">'t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:mLD6JLZCaaM/4LNX5yw9zIpL0aJaiPLdcKau6gPJEzI.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:b5:ff:b7:d9:f7:76:77:57:df:a5:89:e9:63:63:d8:71.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">Warning: Permanently added '</span><span class="number">192.168</span>.<span class="number">33.102</span><span class="string">' (ECDSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">hadoop@192.168.33.102'</span>s password: </span><br><span class="line">scp: <span class="regexp">/home/hadoop/</span>.ssh: No such file <span class="keyword">or</span> directory</span><br><span class="line">[hadoop@node101 ~]$ scp -r ~<span class="regexp">/.ssh/</span>* <span class="number">192.168</span>.<span class="number">33.102</span>:~/.ssh</span><br><span class="line">hadoop@<span class="number">192.168</span>.<span class="number">33.102</span><span class="string">'s password: </span></span><br><span class="line"><span class="string">authorized_keys                                                                                    100%  396   326.1KB/s   00:00    </span></span><br><span class="line"><span class="string">id_rsa                                                                                             100% 1675     1.4MB/s   00:00    </span></span><br><span class="line"><span class="string">id_rsa.pub                                                                                         100%  396   508.2KB/s   00:00    </span></span><br><span class="line"><span class="string">known_hosts                                                                                        100%  347   594.5KB/s   00:00 </span></span><br><span class="line"><span class="string">   </span></span><br><span class="line"><span class="string">[hadoop@node101 ~]$ scp -r ~/.ssh/* 192.168.33.103:~/.ssh</span></span><br><span class="line"><span class="string">The authenticity of host '</span><span class="number">192.168</span>.<span class="number">33.103</span> (<span class="number">192.168</span>.<span class="number">33.103</span>)<span class="string">' can'</span>t be established.</span><br><span class="line">ECDSA key fingerprint <span class="keyword">is</span> SHA256:<span class="number">8jt</span>De6bMz1Ej/L00sRkVp2P9GEUUBGBYHChtbDQIVkE.</span><br><span class="line">ECDSA key fingerprint <span class="keyword">is</span> MD5:<span class="number">97</span>:<span class="number">9f</span>:d6:<span class="number">5e</span>:c1:<span class="number">88</span>:<span class="number">7f</span>:b6:f2:df:<span class="number">3b</span>:d7:cb:<span class="number">27</span>:c9:f3.</span><br><span class="line">Are you sure you want <span class="keyword">to</span> <span class="keyword">continue</span> connecting (<span class="literal">yes</span>/<span class="literal">no</span>)? <span class="literal">yes</span></span><br><span class="line">Warning: Permanently added <span class="string">'192.168.33.103'</span> (ECDSA) <span class="keyword">to</span> the list <span class="keyword">of</span> known hosts.</span><br><span class="line">hadoop@<span class="number">192.168</span>.<span class="number">33.103</span><span class="string">'s password: </span></span><br><span class="line"><span class="string">authorized_keys                                                                                    100%  396   415.9KB/s   00:00    </span></span><br><span class="line"><span class="string">id_rsa                                                                                             100% 1675     1.6MB/s   00:00    </span></span><br><span class="line"><span class="string">id_rsa.pub                                                                                         100%  396   514.7KB/s   00:00    </span></span><br><span class="line"><span class="string">known_hosts                                                                                        100%  523   554.1KB/s   00:00   </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">[hadoop@node101 ~]$ scp -r ~/.ssh/* 192.168.33.104:~/.ssh</span></span><br><span class="line"><span class="string">The authenticity of host '</span><span class="number">192.168</span>.<span class="number">33.104</span> (<span class="number">192.168</span>.<span class="number">33.104</span>)<span class="string">' can'</span>t be established.</span><br><span class="line">ECDSA key fingerprint <span class="keyword">is</span> SHA256:J2aFGIz5bWg1IirGYnQrhBDAuXvSUB9qJyLcxyB+CQ4.</span><br><span class="line">ECDSA key fingerprint <span class="keyword">is</span> MD5:eb:<span class="number">1e</span>:e6:af:af:<span class="number">5a</span>:<span class="number">11</span>:<span class="number">92</span>:e6:<span class="number">55</span>:ff:a3:<span class="number">09</span>:<span class="number">16</span>:<span class="number">55</span>:<span class="number">99.</span></span><br><span class="line">Are you sure you want <span class="keyword">to</span> <span class="keyword">continue</span> connecting (<span class="literal">yes</span>/<span class="literal">no</span>)? <span class="literal">yes</span></span><br><span class="line">Warning: Permanently added <span class="string">'192.168.33.104'</span> (ECDSA) <span class="keyword">to</span> the list <span class="keyword">of</span> known hosts.</span><br><span class="line">hadoop@<span class="number">192.168</span>.<span class="number">33.104</span><span class="string">'s password: </span></span><br><span class="line"><span class="string">authorized_keys                                                                                    100%  396   349.5KB/s   00:00    </span></span><br><span class="line"><span class="string">id_rsa                                                                                             100% 1675     1.9MB/s   00:00    </span></span><br><span class="line"><span class="string">id_rsa.pub                                                                                         100%  396   675.8KB/s   00:00    </span></span><br><span class="line"><span class="string">known_hosts                                                                                        100%  699   453.9KB/s   00:00</span></span><br></pre></td></tr></table></figure></p><hr><h1 id="修改Hadoop配置文件"><a href="#修改Hadoop配置文件" class="headerlink" title="修改Hadoop配置文件"></a>修改Hadoop配置文件</h1><p><strong>均使用hadoop用户操作，只需要在node101上修改即可</strong></p><p>先进入/usr/local/hadoop/etc/hadoop/文件<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@node</span>101 ~]$ cd <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span></span><br></pre></td></tr></table></figure></p><p>1、修改hadoop-env.sh文件<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node101</span> hadoop]<span class="variable">$ </span>vi hadoop-env.sh</span><br></pre></td></tr></table></figure></p><p>找到export JAVA_HOME=${JAVA_HOME}，在前面加个#注释掉，将JAVA_HOME用路径代替，如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#export JAVA_HOME=$&#123;JAVA_HOME&#125;</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_181-amd64</span><br></pre></td></tr></table></figure></p><p>2、修改core-site.xml文件<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@master100</span> hadoop]<span class="variable">$ </span>vi core-site.xml</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>指定hadoop运行时产生文件的存储路径<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node101:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>hdfs namenode的通信地址,通信端口<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>3、修改hdfs-site.xml<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node101</span> hadoop]<span class="variable">$ </span>vi hdfs-site.xml</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 该文件指定与HDFS相关的配置信息。</span></span><br><span class="line"><span class="comment">需要修改HDFS默认的块的副本属性，因为HDFS默认情况下每个数据块保存3个副本，</span></span><br><span class="line"><span class="comment">而在伪分布式模式下运行时，由于只有一个数据节点，</span></span><br><span class="line"><span class="comment">所以需要将副本个数改为1；否则Hadoop程序会报错。 --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>指定HDFS存储数据的副本数目，默认情况下是3份<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/hadoopdata/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>namenode存放数据的目录<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/hadoopdata/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>datanode存放block块的目录<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.secondary.http.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node102:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>secondarynamenode 运行节点的信息，和 namenode 不同节点<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>关闭权限验证<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>4、修改mapred-site.xml</p><p>/usr/local/hadoop/etc/hadoop文件夹中并没有mapred-site.xml文件，但提供了模板mapred-site.xml.template，将其复制一份重命名为mapred-site.xml 即可<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node101 hadoop]$ cp mapred-site<span class="selector-class">.xml</span><span class="selector-class">.template</span> mapred-site.xml</span><br><span class="line">[hadoop@node101 hadoop]$ vi mapred-site.xml</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 在该配置文件中指定与MapReduce作业相关的配置属性，需要指定JobTracker运行的主机地址--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>指定mapreduce运行在yarn上<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>5、修改yarn-site.xml<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@master100</span> hadoop]<span class="variable">$ </span>vi yarn-site.xml</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node101<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>yarn总管理器的IPC通讯地址<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>mapreduce执行shuffle时获取数据的方式<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>6、修改slaves文件<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node101</span> hadoop]<span class="variable">$ </span>vi slaves</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">node102</span></span><br><span class="line"><span class="symbol">node103</span></span><br><span class="line"><span class="symbol">node104</span></span><br></pre></td></tr></table></figure></p><p>上述配置文件我已经上传至：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1BlbmdTaHVhaXhpbi9oYWRvb3AtMi43LjNfY2VudG9zNw==" title="https://github.com/PengShuaixin/hadoop-2.7.3_centos7">https://github.com/PengShuaixin/hadoop-2.7.3_centos7<i class="fa fa-external-link"></i></span></p><p>可以直接下载下来，通过上传到Linux直接覆盖原来文件的方式进行配置</p><p>7、通过scp将配置文件上传到其他主机<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@node</span>101 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node102:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br><span class="line"> </span><br><span class="line">[hadoop<span class="meta">@node</span>101 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node103:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br><span class="line"> </span><br><span class="line">[hadoop<span class="meta">@node</span>101 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node104:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br></pre></td></tr></table></figure></p><hr><h1 id="HDFS初始化"><a href="#HDFS初始化" class="headerlink" title="HDFS初始化"></a>HDFS初始化</h1><p>Hadoop配置完后，用<strong>hadoop用户操作</strong>，在<strong>node101</strong>上格式化namenode<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node101</span> hadoop]<span class="variable">$ </span>hdfs namenode -format</span><br></pre></td></tr></table></figure></p><p>出现如下信息说明格式化成功：<br><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node101 hadoop]$ hdfs namenode -format</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">27</span> INFO namenode.<span class="symbol">NameNode:</span> <span class="symbol">STARTUP_MSG:</span> </span><br><span class="line">/************************************************************</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span> Starting NameNode</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   host = node101/<span class="number">192.168</span>.<span class="number">33.101</span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   args = [-format]</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   version = <span class="number">2.7</span>.<span class="number">3</span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   classpath = <span class="regexp">/usr/local</span><span class="regexp">/hadoop/etc</span><span class="regexp">/hadoop:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jaxb-impl-2.2.3-1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jaxb-api-2.2.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/stax-api-1.0-2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/activation-1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-core-asl-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-mapper-asl-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-jaxrs-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-xc-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-server-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/asm-3.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/log4j-1.2.17.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jets3t-0.9.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/httpclient-4.2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/httpcore-4.2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/java-xmlbuilder-0.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-lang-2.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-configuration-1.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-digester-1.8.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-beanutils-1.7.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-beanutils-core-1.8.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/slf4j-api-1.7.10.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/slf4j-log4j12-1.7.10.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/avro-1.7.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/paranamer-2.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/snappy-java-1.0.4.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-compress-1.4.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/xz-1.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/protobuf-java-2.5.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/gson-2.2.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hadoop-auth-2.7.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/apacheds-kerberos-codec-2.0.0-M15.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/apacheds-i18n-2.0.0-M15.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/api-asn1-api-1.0.0-M20.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/api-util-1.0.0-M20.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/zookeeper-3.4.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/netty-3.6.2.Final.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-framework-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-client-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsch-0.1.42.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-recipes-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/htrace-core-3.1.0-incubating.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/junit-4.11.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hamcrest-core-1.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/mockito-all-1.8.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hadoop-annotations-2.7.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/guava-11.0.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsr305-3.0.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-cli-1.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-math3-3.1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/xmlenc-0.52.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-httpclient-3.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-logging-1.1.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-codec-1.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-io-2.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-net-3.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-collections-3.2.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/servlet-api-2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jetty-6.1.26.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jetty-util-6.1.26.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsp-api-2.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-core-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-json-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jettison-1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/hadoop</span>-common-<span class="number">2.7</span>.<span class="number">3</span>.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/common/hadoop-common-<span class="number">2.7</span>.<span class="number">3</span>-tests.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/common/hadoop-nfs-<span class="number">2.7</span>.<span class="number">3</span>.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/<span class="symbol">hdfs:</span>/usr/local/hadoop/share/hadoop/hdfs/<span class="class"><span class="keyword">lib</span>/<span class="title">commons</span>-<span class="title">codec</span>-1.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">logging</span>-1.1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">guava</span>-11.0.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jsr305</span>-3.0.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">cli</span>-1.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xmlenc</span>-0.52.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">servlet</span>-<span class="title">api</span>-2.5.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jetty</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jetty</span>-<span class="title">util</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">lang</span>-2.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">htrace</span>-<span class="title">core</span>-3.1.0-<span class="title">incubating</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">daemon</span>-1.0.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">netty</span>-<span class="title">all</span>-4.0.23.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xercesImpl</span>-2.9.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xml</span>-<span class="title">apis</span>-1.3.04.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-2.7.3-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-<span class="title">nfs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">zookeeper</span>-3.4.6-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">lang</span>-2.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guava</span>-11.0.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jsr305</span>-3.0.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">logging</span>-1.1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">cli</span>-1.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jaxb</span>-<span class="title">api</span>-2.2.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">stax</span>-<span class="title">api</span>-1.0-2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">activation</span>-1.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">compress</span>-1.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">xz</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">servlet</span>-<span class="title">api</span>-2.5.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">codec</span>-1.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jetty</span>-<span class="title">util</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">client</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">jaxrs</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">xc</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guice</span>-<span class="title">servlet</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guice</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">javax</span>.<span class="title">inject</span>-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">aopalliance</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">json</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jettison</span>-1.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jaxb</span>-<span class="title">impl</span>-2.2.3-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">guice</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">zookeeper</span>-3.4.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">collections</span>-3.2.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jetty</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">api</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">nodemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">web</span>-<span class="title">proxy</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">applicationhistoryservice</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">resourcemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">tests</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">client</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">sharedcachemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">applications</span>-<span class="title">distributedshell</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">applications</span>-<span class="title">unmanaged</span>-<span class="title">am</span>-<span class="title">launcher</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">registry</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">avro</span>-1.7.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">paranamer</span>-2.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">snappy</span>-<span class="title">java</span>-1.0.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">compress</span>-1.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">xz</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">hadoop</span>-<span class="title">annotations</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">guice</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">javax</span>.<span class="title">inject</span>-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">aopalliance</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">guice</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">guice</span>-<span class="title">servlet</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">junit</span>-4.11.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">hamcrest</span>-<span class="title">core</span>-1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">core</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">shuffle</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">app</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">hs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">jobclient</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">hs</span>-<span class="title">plugins</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">examples</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">jobclient</span>-2.7.3-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">contrib</span>/<span class="title">capacity</span>-<span class="title">scheduler</span>/*.<span class="title">jar</span></span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   build = <span class="symbol">https:</span>/<span class="regexp">/git-wip-us.apache.org/repos</span><span class="regexp">/asf/hadoop</span>.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by <span class="string">'root'</span> on <span class="number">2016</span>-<span class="number">08</span>-<span class="number">18</span><span class="symbol">T01:</span><span class="number">41</span>Z</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   java = <span class="number">1.8</span>.<span class="number">0_181</span></span><br><span class="line">************************************************************<span class="regexp">/</span></span><br><span class="line"><span class="regexp">18/</span><span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">27</span> INFO namenode.<span class="symbol">NameNode:</span> registered UNIX signal handlers <span class="keyword">for</span> [TERM, HUP, INT]</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">27</span> INFO namenode.<span class="symbol">NameNode:</span> createNameNode [-format]</span><br><span class="line">Formatting using <span class="symbol">clusterid:</span> CID-f67c3bc3-<span class="number">0</span>ce6-<span class="number">4</span><span class="keyword">def</span>-<span class="number">8</span>b59-<span class="number">64</span>af51cb4f35</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO namenode.<span class="symbol">FSNamesystem:</span> No KeyProvider found.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO namenode.<span class="symbol">FSNamesystem:</span> fsLock is <span class="symbol">fair:</span><span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">DatanodeManager:</span> dfs.block.invalidate.limit=<span class="number">1000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">DatanodeManager:</span> dfs.namenode.datanode.registration.ip-hostname-check=<span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> dfs.namenode.startup.delay.block.deletion.sec is set to <span class="number">000</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00.000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> The block deletion will start around <span class="number">2018</span> 十月 <span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map BlocksMap</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO util.<span class="symbol">GSet:</span> <span class="number">2.0</span>% max memory <span class="number">966.7</span> MB = <span class="number">19.3</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">21</span> = <span class="number">2097152</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> dfs.block.access.token.enable=<span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> defaultReplication         = <span class="number">3</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxReplication             = <span class="number">512</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> minReplication             = <span class="number">1</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxReplicationStreams      = <span class="number">2</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> replicationRecheckInterval = <span class="number">3000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> encryptDataTransfer        = <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxNumBlocksToLog          = <span class="number">1000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO namenode.<span class="symbol">FSNamesystem:</span> fsOwner             = hadoop (<span class="symbol">auth:</span>SIMPLE)</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO namenode.<span class="symbol">FSNamesystem:</span> supergroup          = supergroup</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO namenode.<span class="symbol">FSNamesystem:</span> isPermissionEnabled = <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO namenode.<span class="symbol">FSNamesystem:</span> HA <span class="symbol">Enabled:</span> <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">28</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Append <span class="symbol">Enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map INodeMap</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> <span class="number">1.0</span>% max memory <span class="number">966.7</span> MB = <span class="number">9.7</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">20</span> = <span class="number">1048576</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSDirectory:</span> ACLs enabled? <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSDirectory:</span> XAttrs enabled? <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSDirectory:</span> Maximum size <span class="keyword">of</span> an <span class="symbol">xattr:</span> <span class="number">16384</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">NameNode:</span> Caching file names occuring more than <span class="number">10</span> times</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map cachedBlocks</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> <span class="number">0.25</span>% max memory <span class="number">966.7</span> MB = <span class="number">2.4</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">18</span> = <span class="number">262144</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.threshold-pct = <span class="number">0.9990000128746033</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.min.datanodes = <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.extension     = <span class="number">30000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.window.num.buckets = <span class="number">10</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.num.users = <span class="number">10</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.windows.minutes = <span class="number">1</span>,<span class="number">5</span>,<span class="number">25</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Retry cache on namenode is enabled</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Retry cache will use <span class="number">0.03</span> <span class="keyword">of</span> total heap and retry cache entry expiry time is <span class="number">600000</span> millis</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map NameNodeRetryCache</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> <span class="number">0.029999999329447746</span>% max memory <span class="number">966.7</span> MB = <span class="number">297.0</span> KB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">15</span> = <span class="number">32768</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSImage:</span> Allocated new <span class="symbol">BlockPoolId:</span> BP-<span class="number">148426469</span>-<span class="number">192.168</span>.<span class="number">33.101</span>-<span class="number">1538641289434</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO common.<span class="symbol">Storage:</span> Storage directory /usr/local/hadoop/hadoopdata/namenode has been successfully formatted.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSImageFormatProtobuf:</span> Saving image file /usr/local/hadoop/hadoopdata/namenode/current/fsimage.ckpt_0000000000000000000 using no compression</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">FSImageFormatProtobuf:</span> Image file /usr/local/hadoop/hadoopdata/namenode/current/fsimage.ckpt_0000000000000000000 <span class="keyword">of</span> size <span class="number">353</span> bytes saved in <span class="number">0</span> seconds.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">NNStorageRetentionManager:</span> Going to retain <span class="number">1</span> images <span class="keyword">with</span> txid &gt;= <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO util.<span class="symbol">ExitUtil:</span> Exiting <span class="keyword">with</span> status <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">04</span> <span class="number">16</span>:<span class="number">21</span>:<span class="number">29</span> INFO namenode.<span class="symbol">NameNode:</span> <span class="symbol">SHUTDOWN_MSG:</span> </span><br><span class="line">/************************************************************</span><br><span class="line"><span class="symbol">SHUTDOWN_MSG:</span> Shutting down NameNode at node101/<span class="number">192.168</span>.<span class="number">33.101</span></span><br><span class="line">************************************************************<span class="regexp">/</span></span><br></pre></td></tr></table></figure></p><hr><h1 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h1><p><strong>使用hadoop用户操作</strong></p><h2 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动HDFS</h2><p>注意：不管在集群中的那个节点都可以<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node101</span> hadoop]<span class="variable">$ </span>start-dfs.sh</span><br></pre></td></tr></table></figure></p><p>可看到如下信息：<br><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node101 hadoop]$ start-dfs.sh</span><br><span class="line">Starting namenodes <span class="keyword">on</span> [node101]</span><br><span class="line">The authenticity <span class="keyword">of</span> host <span class="symbol">'node101</span> (<span class="number">192.168</span>.<span class="number">33.101</span>)' can<span class="symbol">'t</span> be established.</span><br><span class="line">ECDSA key fingerprint <span class="keyword">is</span> SHA256:jXz9wiErwjKiKaa+PJoCRyecdM3jVnu+AW2PrZucWxk.</span><br><span class="line">ECDSA key fingerprint <span class="keyword">is</span> MD5:d1:a2:b4:<span class="number">6</span>d:<span class="number">30</span>:<span class="number">21</span>:d7:f8:<span class="number">3</span>c:<span class="number">17</span>:e8:<span class="number">43</span>:<span class="number">93</span>:<span class="number">6</span>c:<span class="number">5</span>e:da.</span><br><span class="line">Are you sure you want <span class="keyword">to</span> continue connecting (yes/no)? yes</span><br><span class="line">node101: <span class="literal">Warning</span>: Permanently added <span class="symbol">'node101</span>,<span class="number">192.168</span>.<span class="number">33.101</span>' (ECDSA) <span class="keyword">to</span> the list <span class="keyword">of</span> known hosts.</span><br><span class="line">node101: starting namenode, logging <span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-namenode-node101.<span class="keyword">out</span></span><br><span class="line">node103: starting datanode, logging <span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-datanode-node103.<span class="keyword">out</span></span><br><span class="line">node104: starting datanode, logging <span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-datanode-node104.<span class="keyword">out</span></span><br><span class="line">node102: starting datanode, logging <span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-datanode-node102.<span class="keyword">out</span></span><br><span class="line">Starting secondary namenodes [node102]</span><br><span class="line">node102: starting secondarynamenode, logging <span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-secondarynamenode-node102.<span class="keyword">out</span></span><br></pre></td></tr></table></figure></p><h2 id="启动YARN"><a href="#启动YARN" class="headerlink" title="启动YARN"></a>启动YARN</h2><p>注意：只能在主节点中进行启动</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node101</span> hadoop]<span class="variable">$ </span>start-yarn.sh</span><br></pre></td></tr></table></figure><p>可看到如下信息：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node101 hadoop]$ start-yarn.sh</span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-resourcemanager-node101.out</span><br><span class="line">node104: starting nodemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-nodemanager-node104.out</span><br><span class="line">node102: starting nodemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-nodemanager-node102.out</span><br><span class="line">node103: starting nodemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-nodemanager-node103.out</span><br></pre></td></tr></table></figure></p><hr><h1 id="查看服务器进程"><a href="#查看服务器进程" class="headerlink" title="查看服务器进程"></a>查看服务器进程</h1><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">jps</span></span><br></pre></td></tr></table></figure><p><strong>node101</strong><br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node101 hadoop]$ jps</span><br><span class="line"><span class="number">15713</span> Jps</span><br><span class="line"><span class="number">14847</span> NameNode</span><br><span class="line"><span class="number">15247</span> ResourceManager</span><br></pre></td></tr></table></figure></p><p><strong>node102</strong><br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node102 ~]$ jps</span><br><span class="line"><span class="number">15228</span> NodeManager</span><br><span class="line"><span class="number">14925</span> DataNode</span><br><span class="line"><span class="number">14989</span> SecondaryNameNode</span><br><span class="line"><span class="number">15567</span> Jps</span><br></pre></td></tr></table></figure></p><p><strong>node103</strong><br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node103 ~]$ jps</span><br><span class="line"><span class="number">14532</span> DataNode</span><br><span class="line"><span class="number">15143</span> Jps</span><br><span class="line"><span class="number">14766</span> NodeManager</span><br></pre></td></tr></table></figure></p><p><strong>node104</strong><br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node104 ~]$ jps</span><br><span class="line"><span class="number">15217</span> Jps</span><br><span class="line"><span class="number">14805</span> NodeManager</span><br><span class="line"><span class="number">14571</span> DataNode</span><br></pre></td></tr></table></figure></p><p>可以看到与我们<strong>集群规划</strong>所分配的进程是一致的</p><hr><h1 id="启动HDFS和YARN的web管理界面"><a href="#启动HDFS和YARN的web管理界面" class="headerlink" title="启动HDFS和YARN的web管理界面"></a>启动HDFS和YARN的web管理界面</h1><p><strong>HDFS :</strong> <span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMTAxOjUwMDcw" title="http://192.168.33.101:50070">http://192.168.33.101:50070<i class="fa fa-external-link"></i></span></p><p><strong>YARN :</strong> <span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMTAxOjgwODgv" title="http://192.168.33.101:8088/">http://192.168.33.101:8088<i class="fa fa-external-link"></i></span></p><h2 id="HDFS界面"><a href="#HDFS界面" class="headerlink" title="HDFS界面"></a>HDFS界面</h2><p><img src="/post/CentOS-7部署Hadoop集群（完全分布式）/2018100416411749.png" alt=""></p><h2 id="YARN界面"><a href="#YARN界面" class="headerlink" title="YARN界面"></a>YARN界面</h2><p><img src="/post/CentOS-7部署Hadoop集群（完全分布式）/20181004164133840.png" alt=""></p><h1 id="相关推荐"><a href="#相关推荐" class="headerlink" title="相关推荐"></a>相关推荐</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTE0ODI3" title="https://blog.csdn.net/u010993514/article/details/82914827">在Windows中安装Hadoop（非虚拟机安装）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMwMzUx" title="https://blog.csdn.net/u010993514/article/details/82930351">CentOS 7部署Hadoop（单机版）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMzMzQ2" title="https://blog.csdn.net/u010993514/article/details/82933346">CentOS 7部署Hadoop（伪分布式）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgzMDA5ODIy" title="https://blog.csdn.net/u010993514/article/details/83009822">CentOS 7部署Hadoop集群（HA高可用集群）<i class="fa fa-external-link"></i></span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;测试环境&quot;&gt;&lt;a href=&quot;#测试环境&quot; class=&quot;headerlink&quot; title=&quot;测试环境&quot;&gt;&lt;/a&gt;测试环境&lt;/h1&gt;&lt;p&gt;Linux系统版本：CentOS 7 64位&lt;/p&gt;
&lt;p&gt;Hadoop版本：&lt;span class=&quot;exturl&quot; da
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/tags/Hadoop/"/>
    
      <category term="Linux" scheme="https://blog.niclas.cn/tags/Linux/"/>
    
      <category term="Hadoop集群" scheme="https://blog.niclas.cn/tags/Hadoop%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 7部署Hadoop（伪分布式）</title>
    <link href="https://blog.niclas.cn/post/CentOS-7%E9%83%A8%E7%BD%B2Hadoop%EF%BC%88%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%89/"/>
    <id>https://blog.niclas.cn/post/CentOS-7部署Hadoop（伪分布式）/</id>
    <published>2018-10-03T14:01:03.000Z</published>
    <updated>2018-12-24T13:46:14.030Z</updated>
    
    <content type="html"><![CDATA[<h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><p>Linux系统版本：CentOS 7 64位</p><p>Hadoop版本：<span class="exturl" data-url="aHR0cHM6Ly9hcmNoaXZlLmFwYWNoZS5vcmcvZGlzdC9oYWRvb3AvY29tbW9uL2hhZG9vcC0yLjcuMy8=" title="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.3/">hadoop-2.7.3<i class="fa fa-external-link"></i></span></p><p>Java版本：<span class="exturl" data-url="aHR0cHM6Ly93d3cub3JhY2xlLmNvbS90ZWNobmV0d29yay9qYXZhL2phdmFzZS9kb3dubG9hZHMvamRrOC1kb3dubG9hZHMtMjEzMzE1MS5odG1s" title="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">jdk-8u181-linux-x64<i class="fa fa-external-link"></i></span></p><hr><h1 id="安装CentOS-7"><a href="#安装CentOS-7" class="headerlink" title="安装CentOS 7"></a>安装CentOS 7</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI0ODcx" title="https://blog.csdn.net/u010993514/article/details/82924871">VMware虚拟机安装Linux系统<i class="fa fa-external-link"></i></span></p><hr><h1 id="配置Java环境"><a href="#配置Java环境" class="headerlink" title="配置Java环境"></a>配置Java环境</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI2NTE0" title="https://blog.csdn.net/u010993514/article/details/82926514">Linux系统下安装Java环境<i class="fa fa-external-link"></i></span></p><hr><h1 id="配置单机版Hadoop"><a href="#配置单机版Hadoop" class="headerlink" title="配置单机版Hadoop"></a>配置单机版Hadoop</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMwMzUx" title="https://blog.csdn.net/u010993514/article/details/82930351">CentOS 7部署Hadoop（单机版）<i class="fa fa-external-link"></i></span></p><hr><h1 id="配置SSH免密登录"><a href="#配置SSH免密登录" class="headerlink" title="配置SSH免密登录"></a>配置SSH免密登录</h1><p>用hadoop用户登录进行下面的操作：</p><p>1、生成公钥私钥对，输入下面命令一直回车就可以了<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ssh-keygen -t rsa</span></span><br></pre></td></tr></table></figure></p><p>执行情况如下：<br><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@master100</span> ~]$ ssh-keygen -t rsa</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/home/hadoop/.ssh/id_rsa): </span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /home/hadoop/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:nx33fWWuccTRMo+zMzr/v4bMenWYFoPuFmOucqdwp90 hadoop<span class="meta">@master100</span></span><br><span class="line">The key's randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">|<span class="string">                 </span>|</span><br><span class="line">|<span class="string">                .</span>|</span><br><span class="line">|<span class="string">             .o..</span>|</span><br><span class="line">|<span class="string">            . o*.</span>|</span><br><span class="line">|<span class="string">        S  .. +=*</span>|</span><br><span class="line">|<span class="string">         . o=o+O+</span>|</span><br><span class="line">|<span class="string">        . ++=+B B</span>|</span><br><span class="line">|<span class="string">        .o.+*B B.</span>|</span><br><span class="line">|<span class="string">         o+*=oEo=</span>|</span><br><span class="line">+----[SHA256]-----+</span><br></pre></td></tr></table></figure></p><p>2、实现本地免密登录,将id_rsa.pub中的内容拷贝到authorized_keys<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-<span class="keyword">copy</span>-<span class="built_in">id</span> localhost</span><br></pre></td></tr></table></figure></p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master100 ~]$ ssh-copy-id localhost</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source <span class="keyword">of</span> <span class="keyword">key</span>(s) <span class="keyword">to</span> be installed: <span class="string">"/home/hadoop/.ssh/id_rsa.pub"</span></span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting <span class="keyword">to</span> log <span class="keyword">in</span> <span class="keyword">with</span> the <span class="keyword">new</span> <span class="keyword">key</span>(s), <span class="keyword">to</span> filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: <span class="number">1</span> <span class="keyword">key</span>(s) remain <span class="keyword">to</span> be installed -- <span class="keyword">if</span> you are prompted now it <span class="keyword">is</span> <span class="keyword">to</span> install the <span class="keyword">new</span> keys</span><br><span class="line">hadoop@localhost<span class="comment">'s password: //这里输入hadoop用户的密码</span></span><br><span class="line">Number <span class="keyword">of</span> <span class="keyword">key</span>(s) added: <span class="number">1</span></span><br><span class="line">Now <span class="keyword">try</span> logging <span class="keyword">into</span> the machine, <span class="keyword">with</span>:   <span class="string">"ssh 'localhost'"</span></span><br><span class="line"><span class="keyword">and</span> check <span class="keyword">to</span> make sure that only the <span class="keyword">key</span>(s) you wanted were added.</span><br></pre></td></tr></table></figure><p>~/.ssh目录下会生成一个新的文件:authorized_keys，如下：<br><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master100 ~]$ cd ~/.ssh</span><br><span class="line">[hadoop@master100 .ssh]$ ll</span><br><span class="line">总用量 16</span><br><span class="line">-rw-------.<span class="number"> 1 </span>hadoop hadoop <span class="number"> 398 </span>10月 <span class="number"> 3 </span>19:47 authorized_keys</span><br><span class="line">-rw-------.<span class="number"> 1 </span>hadoop hadoop<span class="number"> 1679 </span>10月 <span class="number"> 3 </span>19:46 id_rsa</span><br><span class="line">-rw-r--r--.<span class="number"> 1 </span>hadoop hadoop <span class="number"> 398 </span>10月 <span class="number"> 3 </span>19:46 id_rsa.pub</span><br><span class="line">-rw-r--r--.<span class="number"> 1 </span>hadoop hadoop <span class="number"> 171 </span>10月 <span class="number"> 3 </span>19:42 known_hosts</span><br></pre></td></tr></table></figure></p><p>3、完成上述步骤后就可以本地SSH免密登录了,运行下面代码出现一行登录时间就代表本地SSH免密登录成功<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ssh localhost</span></span><br></pre></td></tr></table></figure></p><p>下面是本地SSH免密登录成功的标志:<br><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[hadoop@master100 ~]</span>$ ssh localhost</span><br><span class="line">Last login: Wed Oct  <span class="number">3</span> <span class="number">19</span>:<span class="number">45</span>:<span class="number">11</span> <span class="number">2018</span> from <span class="number">192.168.33.2</span></span><br></pre></td></tr></table></figure></p><p>想了解更多，可以参考下文或者是自己百度相关知识</p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyMDgzMDI3" title="https://blog.csdn.net/u010993514/article/details/82083027">Linux系统配置SSH免密登录(多主机互通)<i class="fa fa-external-link"></i></span></p><hr><h1 id="修改Hadoop配置文件"><a href="#修改Hadoop配置文件" class="headerlink" title="修改Hadoop配置文件"></a>修改Hadoop配置文件</h1><p>1、进入/usr/local/hadoop/etc/hadoop/目录，可以看到如下配置文件，如果需要修改的文件不存在，那就创建一个，vi命令可以直接创建<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@master</span>100 ~]$ cd <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span></span><br></pre></td></tr></table></figure></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master100 hadoop]$ ll</span><br><span class="line">总用量 <span class="number">152</span></span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">4436</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> capacity-scheduler.xml</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">1335</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> configuration.xsl</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop   <span class="number">318</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> container-executor.cfg</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop   <span class="number">774</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> core-site.xml</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">3589</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> hadoop-env.cmd</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">4224</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> hadoop-env.sh</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">2598</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> hadoop-metrics2.properties</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">2490</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> hadoop-metrics.properties</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">9683</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> hadoop-policy.xml</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop   <span class="number">775</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> hdfs-site.xml</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">1449</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> httpfs-env.sh</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">1657</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> httpfs-log4j.properties</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop    <span class="number">21</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> httpfs-signature.secret</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop   <span class="number">620</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> httpfs-site.xml</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">3518</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> kms-acls.xml</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">1527</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> kms-env.sh</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">1631</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> kms-log4j.properties</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">5511</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> kms-site.xml</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop <span class="number">11237</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> log4j.properties</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop   <span class="number">931</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> mapred-env.cmd</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">1383</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> mapred-env.sh</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">4113</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> mapred-queues.xml.template</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop   <span class="number">758</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> mapred-site.xml.template</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop    <span class="number">10</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> slaves</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">2316</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> ssl-client.xml.example</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">2268</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> ssl-server.xml.example</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">2191</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> yarn-env.cmd</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop  <span class="number">4567</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> yarn-env.sh</span><br><span class="line">-rw-r--r--. <span class="number">1</span> hadoop hadoop   <span class="number">690</span> <span class="number">8</span>月  <span class="number">18</span> <span class="number">2016</span> yarn-site.xml</span><br></pre></td></tr></table></figure><p>2、修改core-site.xml文件<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@master100</span> hadoop]<span class="variable">$ </span>vi core-site.xml</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>指定hadoop运行时产生文件的存储路径<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>hdfs namenode的通信地址,通信端口<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>3、修改hdfs-site.xml<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">vi</span> <span class="selector-tag">hdfs-site</span><span class="selector-class">.xml</span></span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 该文件指定与HDFS相关的配置信息。</span></span><br><span class="line"><span class="comment">需要修改HDFS默认的块的副本属性，因为HDFS默认情况下每个数据块保存3个副本，</span></span><br><span class="line"><span class="comment">而在伪分布式模式下运行时，由于只有一个数据节点，</span></span><br><span class="line"><span class="comment">所以需要将副本个数改为1；否则Hadoop程序会报错。 --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>指定HDFS存储数据的副本数目，默认情况下是3份<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/hadoopdata/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>namenode存放数据的目录<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/hadoopdata/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>datanode存放block块的目录<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>关闭权限验证<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>4、修改mapred-site.xml</p><p>/usr/local/hadoop/etc/hadoop文件夹中并没有mapred-site.xml文件，但提供了模板mapred-site.xml.template，将其复制一份重命名为mapred-site.xml 即可<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master100 hadoop]$ cp mapred-site<span class="selector-class">.xml</span><span class="selector-class">.template</span> mapred-site.xml</span><br><span class="line"></span><br><span class="line">[hadoop@master100 hadoop]$ vi mapred-site.xml</span><br></pre></td></tr></table></figure></p><p>配置文件如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 在该配置文件中指定与MapReduce作业相关的配置属性，需要指定JobTracker运行的主机地址--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>指定mapreduce运行在yarn上<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>5、修改yarn-site.xml<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@master100</span> hadoop]<span class="variable">$ </span>vi yarn-site.xml</span><br></pre></td></tr></table></figure></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>mapreduce执行shuffle时获取数据的方式<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>6、为了防止运行时报错，修改一下hadoop-env.sh文件<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@master100</span> hadoop]<span class="variable">$ </span>vi hadoop-env.sh</span><br></pre></td></tr></table></figure></p><p>找到export JAVA_HOME=${JAVA_HOME}，在前面加个#注释掉，将JAVA_HOME用路径代替，如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#export JAVA_HOME=$&#123;JAVA_HOME&#125;</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_181-amd64</span><br></pre></td></tr></table></figure></p><p>上述配置文件我已经上传至：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1BlbmdTaHVhaXhpbi9oYWRvb3AtMi43LjNfY2VudG9zNw==" title="https://github.com/PengShuaixin/hadoop-2.7.3_centos7">https://github.com/PengShuaixin/hadoop-2.7.3_centos7<i class="fa fa-external-link"></i></span></p><p>可以直接下载下来，通过上传到Linux直接覆盖原来文件的方式进行配置</p><hr><h1 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h1><p>CentOS 7 使用的是firewalld作为防火墙，与CentOS 6 有所不同</p><p><strong>查看防火墙状态</strong>：<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">systemctl status firewalld</span></span><br></pre></td></tr></table></figure></p><p>如下状态说明正在运行：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@master</span>100 hadoop]$ systemctl status firewalld</span><br><span class="line">● firewalld.service - firewalld - dynamic firewall daemon</span><br><span class="line"><span class="symbol">   Loaded:</span> loaded (<span class="regexp">/usr/</span>lib<span class="regexp">/systemd/</span>system/firewalld.service; enabled; vendor <span class="string">preset:</span> enabled)</span><br><span class="line"><span class="symbol">   Active:</span> active (running) since 三 <span class="number">2018</span><span class="number">-10</span><span class="number">-03</span> <span class="number">19</span>:<span class="number">35</span>:<span class="number">22</span> CST; <span class="number">1</span>h <span class="number">49</span>min ago</span><br><span class="line"><span class="symbol">     Docs:</span> <span class="string">man:</span>firewalld(<span class="number">1</span>)</span><br><span class="line"> Main <span class="string">PID:</span> <span class="number">724</span> (firewalld)</span><br><span class="line"><span class="symbol">   CGroup:</span> <span class="regexp">/system.slice/</span>firewalld.service</span><br><span class="line">           └─<span class="number">724</span> <span class="regexp">/usr/</span>bin<span class="regexp">/python -Es /</span>usr<span class="regexp">/sbin/</span>firewalld --nofork --nopid</span><br></pre></td></tr></table></figure></p><p><strong>关闭防火墙：</strong><br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">stop</span> firewalld</span><br></pre></td></tr></table></figure></p><p>关闭之后状态如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master100 hadoop]$ systemctl stop firewalld</span><br><span class="line">==== AUTHENTICATING <span class="keyword">FOR</span> org.freedesktop.systemd1.manage-units ===</span><br><span class="line">Authentication is required <span class="keyword">to</span> manage<span class="built_in"> system </span>services <span class="keyword">or</span> units.</span><br><span class="line">Authenticating as: root</span><br><span class="line">Password: #这里需要输入root账户密码</span><br><span class="line">==== AUTHENTICATION COMPLETE ===</span><br><span class="line">[hadoop@master100 hadoop]$ systemctl status firewalld</span><br><span class="line">● firewalld.service - firewalld - dynamic<span class="built_in"> firewall </span>daemon</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled)</span><br><span class="line">   Active: inactive (dead) since 三 2018-10-03 21:27:34 CST; 40s ago</span><br><span class="line">     Docs: man:firewalld(1)</span><br><span class="line">  Process: 724 <span class="attribute">ExecStart</span>=/usr/sbin/firewalld --nofork --nopid <span class="variable">$FIREWALLD_ARGS</span> (<span class="attribute">code</span>=exited, <span class="attribute">status</span>=0/SUCCESS)</span><br><span class="line"> Main PID: 724 (<span class="attribute">code</span>=exited, <span class="attribute">status</span>=0/SUCCESS)</span><br></pre></td></tr></table></figure></p><p><strong>关闭防火墙开机自动启动</strong>：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="builtin-name">disable</span> firewalld</span><br></pre></td></tr></table></figure></p><p>执行过程如下：<br><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master100 hadoop]$ systemctl disable firewalld</span><br><span class="line"><span class="code"> </span></span><br><span class="line"><span class="section">==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-unit-files ===</span></span><br><span class="line">Authentication is required to manage system service or unit files.</span><br><span class="line">Authenticating as: root</span><br><span class="line">Password: #输入root用户密码</span><br><span class="line"><span class="section">==== AUTHENTICATION COMPLETE ===</span></span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.</span><br><span class="line">Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.</span><br><span class="line"><span class="section">==== AUTHENTICATING FOR org.freedesktop.systemd1.reload-daemon ===</span></span><br><span class="line">Authentication is required to reload the systemd state.</span><br><span class="line">Authenticating as: root</span><br><span class="line">Password: #输入root用户密码</span><br><span class="line"><span class="section">==== AUTHENTICATION COMPLETE ===</span></span><br><span class="line"><span class="code"> </span></span><br><span class="line">#查看开机启动状态，确认关闭成功</span><br><span class="line">[hadoop@master100 hadoop]$ systemctl is-enabled firewalld.service</span><br><span class="line">disabled</span><br></pre></td></tr></table></figure></p><p><strong>更多firewalld防火墙操作请参考：</strong></p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbW94aWFvYW4vcC81NjgzNzQzLmh0bWw=" title="https://www.cnblogs.com/moxiaoan/p/5683743.html">CentOS7使用firewalld打开关闭防火墙与端口<i class="fa fa-external-link"></i></span></p><hr><h1 id="HDFS初始化"><a href="#HDFS初始化" class="headerlink" title="HDFS初始化"></a>HDFS初始化</h1><p>Hadoop配置完后，格式化namenode<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@master100</span> hadoop]<span class="variable">$ </span>hdfs namenode -format</span><br></pre></td></tr></table></figure></p><p>出现如下信息说明格式化成功：<br><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"> [hadoop@master100 hadoop]$ hdfs namenode -format</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">NameNode:</span> <span class="symbol">STARTUP_MSG:</span> </span><br><span class="line">/************************************************************</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span> Starting NameNode</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   host = master100/<span class="number">192.168</span>.<span class="number">33.100</span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   args = [-format]</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   version = <span class="number">2.7</span>.<span class="number">3</span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   classpath = <span class="regexp">/usr/local</span><span class="regexp">/hadoop/etc</span><span class="regexp">/hadoop:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jaxb-impl-2.2.3-1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jaxb-api-2.2.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/stax-api-1.0-2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/activation-1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-core-asl-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-mapper-asl-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-jaxrs-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-xc-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-server-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/asm-3.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/log4j-1.2.17.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jets3t-0.9.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/httpclient-4.2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/httpcore-4.2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/java-xmlbuilder-0.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-lang-2.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-configuration-1.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-digester-1.8.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-beanutils-1.7.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-beanutils-core-1.8.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/slf4j-api-1.7.10.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/slf4j-log4j12-1.7.10.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/avro-1.7.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/paranamer-2.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/snappy-java-1.0.4.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-compress-1.4.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/xz-1.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/protobuf-java-2.5.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/gson-2.2.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hadoop-auth-2.7.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/apacheds-kerberos-codec-2.0.0-M15.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/apacheds-i18n-2.0.0-M15.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/api-asn1-api-1.0.0-M20.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/api-util-1.0.0-M20.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/zookeeper-3.4.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/netty-3.6.2.Final.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-framework-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-client-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsch-0.1.42.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-recipes-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/htrace-core-3.1.0-incubating.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/junit-4.11.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hamcrest-core-1.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/mockito-all-1.8.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hadoop-annotations-2.7.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/guava-11.0.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsr305-3.0.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-cli-1.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-math3-3.1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/xmlenc-0.52.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-httpclient-3.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-logging-1.1.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-codec-1.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-io-2.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-net-3.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-collections-3.2.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/servlet-api-2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jetty-6.1.26.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jetty-util-6.1.26.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsp-api-2.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-core-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-json-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jettison-1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/hadoop</span>-common-<span class="number">2.7</span>.<span class="number">3</span>.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/common/hadoop-common-<span class="number">2.7</span>.<span class="number">3</span>-tests.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/common/hadoop-nfs-<span class="number">2.7</span>.<span class="number">3</span>.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/<span class="symbol">hdfs:</span>/usr/local/hadoop/share/hadoop/hdfs/<span class="class"><span class="keyword">lib</span>/<span class="title">commons</span>-<span class="title">codec</span>-1.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">logging</span>-1.1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">guava</span>-11.0.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jsr305</span>-3.0.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">cli</span>-1.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xmlenc</span>-0.52.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">servlet</span>-<span class="title">api</span>-2.5.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jetty</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jetty</span>-<span class="title">util</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">lang</span>-2.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">htrace</span>-<span class="title">core</span>-3.1.0-<span class="title">incubating</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">daemon</span>-1.0.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">netty</span>-<span class="title">all</span>-4.0.23.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xercesImpl</span>-2.9.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xml</span>-<span class="title">apis</span>-1.3.04.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-2.7.3-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-<span class="title">nfs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">zookeeper</span>-3.4.6-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">lang</span>-2.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guava</span>-11.0.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jsr305</span>-3.0.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">logging</span>-1.1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">cli</span>-1.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jaxb</span>-<span class="title">api</span>-2.2.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">stax</span>-<span class="title">api</span>-1.0-2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">activation</span>-1.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">compress</span>-1.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">xz</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">servlet</span>-<span class="title">api</span>-2.5.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">codec</span>-1.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jetty</span>-<span class="title">util</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">client</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">jaxrs</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">xc</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guice</span>-<span class="title">servlet</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guice</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">javax</span>.<span class="title">inject</span>-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">aopalliance</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">json</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jettison</span>-1.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jaxb</span>-<span class="title">impl</span>-2.2.3-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">guice</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">zookeeper</span>-3.4.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">collections</span>-3.2.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jetty</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">api</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">nodemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">web</span>-<span class="title">proxy</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">applicationhistoryservice</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">resourcemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">tests</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">client</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">sharedcachemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">applications</span>-<span class="title">distributedshell</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">applications</span>-<span class="title">unmanaged</span>-<span class="title">am</span>-<span class="title">launcher</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">registry</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">avro</span>-1.7.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">paranamer</span>-2.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">snappy</span>-<span class="title">java</span>-1.0.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">compress</span>-1.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">xz</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">hadoop</span>-<span class="title">annotations</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">guice</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">javax</span>.<span class="title">inject</span>-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">aopalliance</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">guice</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">guice</span>-<span class="title">servlet</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">junit</span>-4.11.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">hamcrest</span>-<span class="title">core</span>-1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">core</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">shuffle</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">app</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">hs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">jobclient</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">hs</span>-<span class="title">plugins</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">examples</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">jobclient</span>-2.7.3-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">contrib</span>/<span class="title">capacity</span>-<span class="title">scheduler</span>/*.<span class="title">jar</span></span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   build = <span class="symbol">https:</span>/<span class="regexp">/git-wip-us.apache.org/repos</span><span class="regexp">/asf/hadoop</span>.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by <span class="string">'root'</span> on <span class="number">2016</span>-<span class="number">08</span>-<span class="number">18</span><span class="symbol">T01:</span><span class="number">41</span>Z</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   java = <span class="number">1.8</span>.<span class="number">0_181</span></span><br><span class="line">************************************************************<span class="regexp">/</span></span><br><span class="line"><span class="regexp">18/</span><span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">NameNode:</span> registered UNIX signal handlers <span class="keyword">for</span> [TERM, HUP, INT]</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">NameNode:</span> createNameNode [-format]</span><br><span class="line">Formatting using <span class="symbol">clusterid:</span> CID-<span class="number">54</span>d602ae-<span class="number">8</span>c60-<span class="number">49</span>f4-bcb9-<span class="number">8</span>a687ba97501</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">FSNamesystem:</span> No KeyProvider found.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">FSNamesystem:</span> fsLock is <span class="symbol">fair:</span><span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">DatanodeManager:</span> dfs.block.invalidate.limit=<span class="number">1000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">DatanodeManager:</span> dfs.namenode.datanode.registration.ip-hostname-check=<span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> dfs.namenode.startup.delay.block.deletion.sec is set to <span class="number">000</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00.000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> The block deletion will start around <span class="number">2018</span> 十月 <span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map BlocksMap</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO util.<span class="symbol">GSet:</span> <span class="number">2.0</span>% max memory <span class="number">966.7</span> MB = <span class="number">19.3</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">21</span> = <span class="number">2097152</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> dfs.block.access.token.enable=<span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> defaultReplication         = <span class="number">1</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxReplication             = <span class="number">512</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> minReplication             = <span class="number">1</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxReplicationStreams      = <span class="number">2</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> replicationRecheckInterval = <span class="number">3000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> encryptDataTransfer        = <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxNumBlocksToLog          = <span class="number">1000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">FSNamesystem:</span> fsOwner             = hadoop (<span class="symbol">auth:</span>SIMPLE)</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">FSNamesystem:</span> supergroup          = supergroup</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">FSNamesystem:</span> isPermissionEnabled = <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">FSNamesystem:</span> HA <span class="symbol">Enabled:</span> <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Append <span class="symbol">Enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map INodeMap</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO util.<span class="symbol">GSet:</span> <span class="number">1.0</span>% max memory <span class="number">966.7</span> MB = <span class="number">9.7</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">20</span> = <span class="number">1048576</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">FSDirectory:</span> ACLs enabled? <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">FSDirectory:</span> XAttrs enabled? <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">FSDirectory:</span> Maximum size <span class="keyword">of</span> an <span class="symbol">xattr:</span> <span class="number">16384</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">52</span> INFO namenode.<span class="symbol">NameNode:</span> Caching file names occuring more than <span class="number">10</span> times</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map cachedBlocks</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO util.<span class="symbol">GSet:</span> <span class="number">0.25</span>% max memory <span class="number">966.7</span> MB = <span class="number">2.4</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">18</span> = <span class="number">262144</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.threshold-pct = <span class="number">0.9990000128746033</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.min.datanodes = <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.extension     = <span class="number">30000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.window.num.buckets = <span class="number">10</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.num.users = <span class="number">10</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.windows.minutes = <span class="number">1</span>,<span class="number">5</span>,<span class="number">25</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Retry cache on namenode is enabled</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Retry cache will use <span class="number">0.03</span> <span class="keyword">of</span> total heap and retry cache entry expiry time is <span class="number">600000</span> millis</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map NameNodeRetryCache</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO util.<span class="symbol">GSet:</span> <span class="number">0.029999999329447746</span>% max memory <span class="number">966.7</span> MB = <span class="number">297.0</span> KB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">15</span> = <span class="number">32768</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO namenode.<span class="symbol">FSImage:</span> Allocated new <span class="symbol">BlockPoolId:</span> BP-<span class="number">938082284</span>-<span class="number">192.168</span>.<span class="number">33.100</span>-<span class="number">1538571953311</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO common.<span class="symbol">Storage:</span> Storage directory /usr/local/hadoop/hadoopdata/namenode has been successfully formatted.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO namenode.<span class="symbol">FSImageFormatProtobuf:</span> Saving image file /usr/local/hadoop/hadoopdata/namenode/current/fsimage.ckpt_0000000000000000000 using no compression</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO namenode.<span class="symbol">FSImageFormatProtobuf:</span> Image file /usr/local/hadoop/hadoopdata/namenode/current/fsimage.ckpt_0000000000000000000 <span class="keyword">of</span> size <span class="number">353</span> bytes saved in <span class="number">0</span> seconds.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO namenode.<span class="symbol">NNStorageRetentionManager:</span> Going to retain <span class="number">1</span> images <span class="keyword">with</span> txid &gt;= <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO util.<span class="symbol">ExitUtil:</span> Exiting <span class="keyword">with</span> status <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">53</span> INFO namenode.<span class="symbol">NameNode:</span> <span class="symbol">SHUTDOWN_MSG:</span> </span><br><span class="line">/************************************************************</span><br><span class="line"><span class="symbol">SHUTDOWN_MSG:</span> Shutting down NameNode at master100/<span class="number">192.168</span>.<span class="number">33.100</span></span><br><span class="line">************************************************************<span class="regexp">/</span></span><br></pre></td></tr></table></figure></p><hr><h1 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h1><p>执行命令：<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">start</span>-all.sh</span><br><span class="line"> </span><br><span class="line"><span class="comment">#或者是使用如下两条命令启动hadoop,第一条命令实际上操作的就是下面两条命令</span></span><br><span class="line"><span class="literal">start</span>-dfs.sh</span><br><span class="line"><span class="literal">start</span>-yarn.sh</span><br></pre></td></tr></table></figure></p><p>出现如下信息：<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master100 hadoop]$ start-all.sh</span><br><span class="line"> </span><br><span class="line"><span class="comment">#执行上述命令会出现如下信息</span></span><br><span class="line">This <span class="keyword">script</span> <span class="keyword">is</span> Deprecated. Instead use start-dfs.sh <span class="keyword">and</span> start-yarn.sh</span><br><span class="line">Starting namenodes <span class="keyword">on</span> [localhost]</span><br><span class="line">localhost: starting namenode, logging <span class="keyword">to</span> /usr/<span class="keyword">local</span>/hadoop/logs/hadoop-hadoop-namenode-master100.out</span><br><span class="line">localhost: starting datanode, logging <span class="keyword">to</span> /usr/<span class="keyword">local</span>/hadoop/logs/hadoop-hadoop-datanode-master100.out</span><br><span class="line">Starting secondary namenodes [<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>]</span><br><span class="line">The authenticity <span class="keyword">of</span> host '<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span> (<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>)' can't be established.</span><br><span class="line">ECDSA key fingerprint <span class="keyword">is</span> SHA256:smnjN2nAXE9l/kx1fQ2r3KBQt14TMjgaVlh+<span class="number">65</span>clSrA.</span><br><span class="line">ECDSA key fingerprint <span class="keyword">is</span> MD5:<span class="number">75</span>:f5:c8:d0:<span class="number">06</span>:c2:c8:<span class="number">0</span>d:<span class="number">25</span>:<span class="number">8</span>b:b9:d5:<span class="number">47</span>:<span class="number">8</span>c:<span class="number">3</span>a:f5.</span><br><span class="line"><span class="comment">#到这里时注意输入yes后回车</span></span><br><span class="line">Are you sure you want <span class="keyword">to</span> <span class="keyword">continue</span> connecting (yes/no)? yes</span><br><span class="line"><span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>: Warning: Permanently added '<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>' (ECDSA) <span class="keyword">to</span> <span class="keyword">the</span> <span class="built_in">list</span> <span class="keyword">of</span> known hosts.</span><br><span class="line"><span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>: starting secondarynamenode, logging <span class="keyword">to</span> /usr/<span class="keyword">local</span>/hadoop/logs/hadoop-hadoop-secondarynamenode-master100.out</span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager, logging <span class="keyword">to</span> /usr/<span class="keyword">local</span>/hadoop/logs/yarn-hadoop-resourcemanager-master100.out</span><br><span class="line">localhost: starting nodemanager, logging <span class="keyword">to</span> /usr/<span class="keyword">local</span>/hadoop/logs/yarn-hadoop-nodemanager-master100.out</span><br></pre></td></tr></table></figure></p><p>查看启动的进程：<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">jps</span></span><br></pre></td></tr></table></figure></p><p>出现如下进程说明Hadoop安装并启动成功<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master100 hadoop]$ jps</span><br><span class="line"><span class="number">6566</span> NameNode</span><br><span class="line"><span class="number">7399</span> Jps</span><br><span class="line"><span class="number">6664</span> DataNode</span><br><span class="line"><span class="number">7016</span> ResourceManager</span><br><span class="line"><span class="number">7114</span> NodeManager</span><br><span class="line"><span class="number">6862</span> SecondaryNameNode</span><br></pre></td></tr></table></figure></p><p>可以进入如下网页查看Namenode与ResourceManager<br><span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMTAwOjUwMDcw" title="http://192.168.33.100:50070">192.168.33.100:50070<i class="fa fa-external-link"></i></span></p><p><img src="/post/CentOS-7部署Hadoop（伪分布式）/20181003214720496.png" alt=""></p><p><span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMTAwOjgwODg=" title="http://192.168.33.100:8088">192.168.33.100:8088<i class="fa fa-external-link"></i></span></p><p><img src="/post/CentOS-7部署Hadoop（伪分布式）/20181003214744480.png" alt=""></p><hr><h1 id="关闭Hadoop"><a href="#关闭Hadoop" class="headerlink" title="关闭Hadoop"></a>关闭Hadoop</h1><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master100 sbin]$ <span class="keyword">stop</span>-<span class="keyword">all</span>.<span class="keyword">sh</span></span><br><span class="line"> </span><br><span class="line">This script <span class="keyword">is</span> Deprecated. Instead use <span class="keyword">stop</span>-dfs.<span class="keyword">sh</span> <span class="built_in">and</span> <span class="keyword">stop</span>-yarn.<span class="keyword">sh</span></span><br><span class="line">Stopping namenodes <span class="keyword">on</span> [localhost]</span><br><span class="line">localhos<span class="variable">t:</span> stopping namenode</span><br><span class="line">localhos<span class="variable">t:</span> stopping datanode</span><br><span class="line">Stopping secondary namenodes [<span class="number">0.0</span>.<span class="number">0.0</span>]</span><br><span class="line"><span class="number">0.0</span>.<span class="number">0.0</span>: stopping secondarynamenode</span><br><span class="line">stopping yarn daemons</span><br><span class="line">stopping resourcemanager</span><br><span class="line">localhos<span class="variable">t:</span> stopping nodemanager</span><br><span class="line"><span class="keyword">no</span> proxyserver <span class="keyword">to</span> <span class="keyword">stop</span></span><br></pre></td></tr></table></figure><hr><h1 id="相关推荐"><a href="#相关推荐" class="headerlink" title="相关推荐"></a>相关推荐</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTE0ODI3" title="https://blog.csdn.net/u010993514/article/details/82914827">在Windows中安装Hadoop（非虚拟机安装）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMwMzUx" title="https://blog.csdn.net/u010993514/article/details/82930351">CentOS 7部署Hadoop（单机版）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTM1ODM0" title="https://blog.csdn.net/u010993514/article/details/82935834">CentOS 7部署Hadoop集群（完全分布式）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgzMDA5ODIy" title="https://blog.csdn.net/u010993514/article/details/83009822">CentOS 7部署Hadoop集群（HA高可用集群）<i class="fa fa-external-link"></i></span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;测试环境&quot;&gt;&lt;a href=&quot;#测试环境&quot; class=&quot;headerlink&quot; title=&quot;测试环境&quot;&gt;&lt;/a&gt;测试环境&lt;/h1&gt;&lt;p&gt;Linux系统版本：CentOS 7 64位&lt;/p&gt;
&lt;p&gt;Hadoop版本：&lt;span class=&quot;exturl&quot; da
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/tags/Hadoop/"/>
    
      <category term="CentOS" scheme="https://blog.niclas.cn/tags/CentOS/"/>
    
      <category term="HDFS" scheme="https://blog.niclas.cn/tags/HDFS/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 7部署Hadoop（单机版）</title>
    <link href="https://blog.niclas.cn/post/CentOS-7%E9%83%A8%E7%BD%B2Hadoop%EF%BC%88%E5%8D%95%E6%9C%BA%E7%89%88%EF%BC%89/"/>
    <id>https://blog.niclas.cn/post/CentOS-7部署Hadoop（单机版）/</id>
    <published>2018-10-03T04:52:44.000Z</published>
    <updated>2018-12-24T13:45:56.101Z</updated>
    
    <content type="html"><![CDATA[<h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><p>Linux系统版本：CentOS 7 64位</p><p>Hadoop版本：hadoop-2.7.3</p><p>Java版本：jdk-8u181-linux-x64</p><hr><h1 id="Hadoop部署方式介绍"><a href="#Hadoop部署方式介绍" class="headerlink" title="Hadoop部署方式介绍"></a>Hadoop部署方式介绍</h1><p>Hadoop部署方式分三种：Standalone Mode（单机模式）、Pseudo-Distributed Mode（伪分布式模式）、Fully Distributed Mode（全分布式模式）</p><h2 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h2><p>单机模式是Hadoop的默认模式。这种模式在一台单机上运行，没有分布式文件系统，而是直接读写本地操作系统的文件系统。当首次解压Hadoop的源码包时，Hadoop无法了解硬件安装环境，便保守地选择了最小配置。在这种默认模式下所有3个XML文件均为空。当配置文件为空时，Hadoop会完全运行在本地。因为不需要与其他节点交互，单机模式就不使用HDFS，也不加载任何Hadoop的守护进程。该模式主要用于开发调试MapReduce程序的应用逻辑。</p><h2 id="伪分布模式"><a href="#伪分布模式" class="headerlink" title="伪分布模式"></a>伪分布模式</h2><p>这种模式也是在一台单机上运行，但用不同的Java进程模仿分布式运行中的各类结点伪分布模式在“单节点集群”上运行Hadoop，其中所有的守护进程都运行在同一台机器上。该模式在单机模式之上增加了代码调试功能，允许你检查内存使用情况，HDFS输入输出，以及其他的守护进程。</p><h2 id="全分布模式"><a href="#全分布模式" class="headerlink" title="全分布模式"></a>全分布模式</h2><p>Hadoop守护进程运行在一个集群上。  </p><p>部分内容来自：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jsb29kbGMvYXJ0aWNsZS9kZXRhaWxzLzE5OTczMDA5P3V0bV9zb3VyY2U9Y29weQ==" title="https://blog.csdn.net/bloodlc/article/details/19973009?utm_source=copy">https://blog.csdn.net/bloodlc/article/details/19973009?utm_source=copy<i class="fa fa-external-link"></i></span></p><hr><h1 id="安装CentOS-7"><a href="#安装CentOS-7" class="headerlink" title="安装CentOS 7"></a>安装CentOS 7</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI0ODcx" title="https://blog.csdn.net/u010993514/article/details/82924871">VMware虚拟机安装Linux系统<i class="fa fa-external-link"></i></span></p><h1 id="配置Java环境"><a href="#配置Java环境" class="headerlink" title="配置Java环境"></a>配置Java环境</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI2NTE0" title="https://blog.csdn.net/u010993514/article/details/82926514">Linux系统下安装Java环境<i class="fa fa-external-link"></i></span></p><hr><h1 id="Hadoop单机版安装"><a href="#Hadoop单机版安装" class="headerlink" title="Hadoop单机版安装"></a>Hadoop单机版安装</h1><p>本文的代码框解释：#后面的为执行代码，[]内root为登录用户，@后master100表示主机名，~代表当前目录，按下面步骤执行时要注意自己这些信息和我的是不是一样的</p><p>1、下载Hadoop2.7.3<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-2.7.3.tar.gz</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://archive.apache.org/dist/hadoop/common/hadoop-2.7.3/</span><br></pre></td></tr></table></figure><p>2、用root账户登录，创建hadoop用户和hadoop用户组，创建用户的时候会自动创建相应的用户组<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 ~]<span class="comment"># useradd hadoop</span></span><br></pre></td></tr></table></figure></p><p>3、创建完用户之后设置一个用户密码，有些密码太简单会提示无效的密码，提示重新输入时再输一遍就可以强制保存了<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 ~]<span class="comment"># passwd hadoop</span></span><br><span class="line">更改用户 hadoop 的密码 。</span><br><span class="line">新的 密码：</span><br><span class="line">无效的密码： 密码少于 8 个字符</span><br><span class="line">重新输入新的 密码：</span><br><span class="line">passwd：所有的身份验证令牌已经成功更新。</span><br></pre></td></tr></table></figure></p><p>4、为hadoop用户添加sudo权限<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 ~]<span class="comment"># vi /etc/sudoers</span></span><br></pre></td></tr></table></figure></p><p>如下，在root用户下面一行加上hadoop  ALL=(ALL)    ALL，保存并退出（这里需要用wq!强制保存退出）<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Next comes the main part: which users can run what software on</span></span><br><span class="line"><span class="comment">## which machines (the sudoers file can be shared between multiple</span></span><br><span class="line"><span class="comment">## systems).</span></span><br><span class="line"><span class="comment">## Syntax:</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment">##      user    MACHINE=COMMANDS</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment">## The COMMANDS section may have other options added to it.</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment">## Allow root to run any commands anywhere</span></span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">hadoop  ALL=(ALL)       ALL</span><br></pre></td></tr></table></figure></p><p>5、上传第1步下载好的<span class="exturl" data-url="aHR0cHM6Ly9hcmNoaXZlLmFwYWNoZS5vcmcvZGlzdC9oYWRvb3AvY29tbW9uL2hhZG9vcC0yLjcuMy9oYWRvb3AtMi43LjMudGFyLmd6" title="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz">hadoop-2.7.3.tar.gz<i class="fa fa-external-link"></i></span> 包到Linux系统中的/usr/local目录下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sftp:/root&gt; <span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">sftp:/usr/<span class="built_in">local</span>&gt; </span><br><span class="line">Uploading hadoop-2.7.3.tar.gz to remote:/usr/<span class="built_in">local</span>/hadoop-2.7.3.tar.gz</span><br><span class="line">sftp: sent 204 MB <span class="keyword">in</span> 9.38 seconds</span><br></pre></td></tr></table></figure></p><p>6、进入/usr/local目录，解压上传的hadoop安装包<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 ~]<span class="comment"># cd /usr/local</span></span><br><span class="line">[root@master100 <span class="built_in">local</span>]<span class="comment"># tar -zxvf /usr/local/hadoop-2.7.3.tar.gz</span></span><br></pre></td></tr></table></figure></p><p>7、解压完成后可以看到文件夹hadoop-2.7.3，将文件夹名改为hadoop，如果不在/usr/local目录下，命令使用时请加上文件夹的绝对路径<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 <span class="built_in">local</span>]<span class="comment"># ll</span></span><br><span class="line">总用量 556412</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 bin</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 etc</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 games</span><br><span class="line">drwxr-xr-x. 9 root root       149 8月  18 2016 hadoop-2.7.3</span><br><span class="line">-rw-r--r--. 1 root root 214092195 10月  3 11:43 hadoop-2.7.3.tar.gz</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 include</span><br><span class="line">-rwxr-xr-x. 1 root root 170023183 10月  2 17:28 jdk-8u181-linux-x64.rpm</span><br><span class="line">-rw-r--r--. 1 root root 185646832 10月  2 16:31 jdk-8u181-linux-x64.tar.gz</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 lib</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 lib64</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 libexec</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 sbin</span><br><span class="line">drwxr-xr-x. 5 root root        49 10月  2 13:00 share</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 src</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 <span class="built_in">local</span>]<span class="comment"># mv hadoop-2.7.3 hadoop</span></span><br><span class="line">[root@master100 <span class="built_in">local</span>]<span class="comment"># ll</span></span><br><span class="line">总用量 556412</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 bin</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 etc</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 games</span><br><span class="line">drwxr-xr-x. 9 root root       149 8月  18 2016 hadoop</span><br><span class="line">-rw-r--r--. 1 root root 214092195 10月  3 11:43 hadoop-2.7.3.tar.gz</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 include</span><br><span class="line">-rwxr-xr-x. 1 root root 170023183 10月  2 17:28 jdk-8u181-linux-x64.rpm</span><br><span class="line">-rw-r--r--. 1 root root 185646832 10月  2 16:31 jdk-8u181-linux-x64.tar.gz</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 lib</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 lib64</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 libexec</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 sbin</span><br><span class="line">drwxr-xr-x. 5 root root        49 10月  2 13:00 share</span><br><span class="line">drwxr-xr-x. 2 root root         6 4月  11 12:59 src</span><br></pre></td></tr></table></figure><p>8、将hadoop文件夹的主：组设置成hadoop<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 <span class="built_in">local</span>]<span class="comment"># chown -R hadoop:hadoop hadoop</span></span><br><span class="line">[root@master100 <span class="built_in">local</span>]<span class="comment"># ll</span></span><br><span class="line">总用量 556412</span><br><span class="line">drwxr-xr-x. 2 root   root           6 4月  11 12:59 bin</span><br><span class="line">drwxr-xr-x. 2 root   root           6 4月  11 12:59 etc</span><br><span class="line">drwxr-xr-x. 2 root   root           6 4月  11 12:59 games</span><br><span class="line">drwxr-xr-x. 9 hadoop hadoop       149 8月  18 2016 hadoop</span><br><span class="line">-rw-r--r--. 1 root   root   214092195 10月  3 11:43 hadoop-2.7.3.tar.gz</span><br><span class="line">drwxr-xr-x. 2 root   root           6 4月  11 12:59 include</span><br><span class="line">-rwxr-xr-x. 1 root   root   170023183 10月  2 17:28 jdk-8u181-linux-x64.rpm</span><br><span class="line">-rw-r--r--. 1 root   root   185646832 10月  2 16:31 jdk-8u181-linux-x64.tar.gz</span><br><span class="line">drwxr-xr-x. 2 root   root           6 4月  11 12:59 lib</span><br><span class="line">drwxr-xr-x. 2 root   root           6 4月  11 12:59 lib64</span><br><span class="line">drwxr-xr-x. 2 root   root           6 4月  11 12:59 libexec</span><br><span class="line">drwxr-xr-x. 2 root   root           6 4月  11 12:59 sbin</span><br><span class="line">drwxr-xr-x. 5 root   root          49 10月  2 13:00 share</span><br><span class="line">drwxr-xr-x. 2 root   root           6 4月  11 12:59 src</span><br></pre></td></tr></table></figure></p><p>9、/usr目录与/usr/local目录所属主：组均为root，默认权限为755，也就是说其他用户（hadoop）没有写入（w）权限，在这里我们需要将这两个目录其他用户的权限设置为7，命令如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod 757 /usr</span><br><span class="line">chmod 757 /usr/<span class="built_in">local</span></span><br></pre></td></tr></table></figure></p><p>可以看到执行情况如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 <span class="built_in">local</span>]<span class="comment"># cd /</span></span><br><span class="line">[root@master100 /]<span class="comment"># chmod 757 /usr</span></span><br><span class="line">[root@master100 /]<span class="comment"># ll</span></span><br><span class="line">总用量 16</span><br><span class="line">lrwxrwxrwx.   1 root root    7 10月  2 13:00 bin -&gt; usr/bin</span><br><span class="line">dr-xr-xr-x.   5 root root 4096 10月  2 13:06 boot</span><br><span class="line">drwxr-xr-x.  20 root root 3240 10月  3 11:47 dev</span><br><span class="line">drwxr-xr-x.  76 root root 8192 10月  3 11:47 etc</span><br><span class="line">drwxr-xr-x.   3 root root   20 10月  3 10:58 home</span><br><span class="line">lrwxrwxrwx.   1 root root    7 10月  2 13:00 lib -&gt; usr/lib</span><br><span class="line">lrwxrwxrwx.   1 root root    9 10月  2 13:00 lib64 -&gt; usr/lib64</span><br><span class="line">drwxr-xr-x.   2 root root    6 4月  11 12:59 media</span><br><span class="line">drwxr-xr-x.   2 root root    6 4月  11 12:59 mnt</span><br><span class="line">drwxr-xr-x.   2 root root    6 4月  11 12:59 opt</span><br><span class="line">dr-xr-xr-x. 133 root root    0 10月  3 11:46 proc</span><br><span class="line">dr-xr-x---.   3 root root  160 10月  3 11:50 root</span><br><span class="line">drwxr-xr-x.  24 root root  720 10月  3 11:47 run</span><br><span class="line">lrwxrwxrwx.   1 root root    8 10月  2 13:00 sbin -&gt; usr/sbin</span><br><span class="line">drwxr-xr-x.   2 root root    6 4月  11 12:59 srv</span><br><span class="line">dr-xr-xr-x.  13 root root    0 10月  3 11:47 sys</span><br><span class="line">drwxrwxrwt.  10 root root  253 10月  3 11:47 tmp</span><br><span class="line">drwxr-xrwx.  14 root root  167 10月  2 17:57 usr</span><br><span class="line">drwxr-xr-x.  19 root root  267 10月  2 13:08 var</span><br><span class="line">[root@master100 /]<span class="comment"># chmod 757 /usr/local</span></span><br><span class="line">[root@master100 /]<span class="comment"># cd /usr</span></span><br><span class="line">[root@master100 usr]<span class="comment"># ll</span></span><br><span class="line">总用量 104</span><br><span class="line">dr-xr-xr-x.  2 root root 24576 10月  2 17:57 bin</span><br><span class="line">drwxr-xr-x.  2 root root     6 4月  11 12:59 etc</span><br><span class="line">drwxr-xr-x.  2 root root     6 4月  11 12:59 games</span><br><span class="line">drwxr-xr-x.  3 root root    23 10月  2 13:01 include</span><br><span class="line">drwxr-xr-x.  3 root root    61 10月  2 17:57 java</span><br><span class="line">dr-xr-xr-x. 27 root root  4096 10月  2 13:02 lib</span><br><span class="line">dr-xr-xr-x. 37 root root 20480 10月  2 13:02 lib64</span><br><span class="line">drwxr-xr-x. 20 root root  4096 10月  2 13:02 libexec</span><br><span class="line">drwxr-xrwx. 13 root root   237 10月  3 11:55 <span class="built_in">local</span></span><br><span class="line">dr-xr-xr-x.  2 root root 12288 10月  2 13:02 sbin</span><br><span class="line">drwxr-xr-x. 75 root root  4096 10月  2 13:02 share</span><br><span class="line">drwxr-xr-x.  4 root root    34 10月  2 13:00 src</span><br><span class="line">lrwxrwxrwx.  1 root root    10 10月  2 13:00 tmp -&gt; ../var/tmp</span><br></pre></td></tr></table></figure></p><hr><h1 id="Hadoop环境变量配置"><a href="#Hadoop环境变量配置" class="headerlink" title="Hadoop环境变量配置"></a>Hadoop环境变量配置</h1><p>1、编辑/etc/profile文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br></pre></td></tr></table></figure></p><p>2、在末尾加上如下几行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure></p><p>这里注意HADOOP_HOME与PATH的顺序，我这里最后几行的配置如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_181-amd64</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br><span class="line"><span class="built_in">export</span> JRE_HOME=<span class="variable">$JAVA_HOME</span>/jre</span><br></pre></td></tr></table></figure></p><p>3、配置完环境变量之后保存退出，让环境变量立即生效<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></p><hr><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p><strong>环境变量测试</strong></p><p>输入如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop</span><br><span class="line">hadoop version</span><br></pre></td></tr></table></figure></p><p>效果如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 usr]<span class="comment"># hadoop</span></span><br><span class="line">Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]</span><br><span class="line">  CLASSNAME            run the class named CLASSNAME</span><br><span class="line"> or</span><br><span class="line">  <span class="built_in">where</span> COMMAND is one of:</span><br><span class="line">  fs                   run a generic filesystem user client</span><br><span class="line">  version              <span class="built_in">print</span> the version</span><br><span class="line">  jar &lt;jar&gt;            run a jar file</span><br><span class="line">                       note: please use <span class="string">"yarn jar"</span> to launch</span><br><span class="line">                             YARN applications, not this <span class="built_in">command</span>.</span><br><span class="line">  checknative [-a|-h]  check native hadoop and compression libraries availability</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  classpath            prints the class path needed to get the</span><br><span class="line">  credential           interact with credential providers</span><br><span class="line">                       Hadoop jar and the required libraries</span><br><span class="line">  daemonlog            get/<span class="built_in">set</span> the <span class="built_in">log</span> level <span class="keyword">for</span> each daemon</span><br><span class="line">  trace                view and modify Hadoop tracing settings</span><br><span class="line"> </span><br><span class="line">Most commands <span class="built_in">print</span> <span class="built_in">help</span> when invoked w/o parameters.</span><br><span class="line">[root@master100 usr]<span class="comment"># hadoop version</span></span><br><span class="line">Hadoop 2.7.3</span><br><span class="line">Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff</span><br><span class="line">Compiled by root on 2016-08-18T01:41Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From <span class="built_in">source</span> with checksum 2e4ce5f957ea4db193bce3734ff29ff4</span><br><span class="line">This <span class="built_in">command</span> was run using /usr/<span class="built_in">local</span>/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar</span><br></pre></td></tr></table></figure></p><p><strong>演示Hadoop自带的MapReduce例子</strong></p><p>在这里用hadoop账户登录系统进行测试<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Xshell 6 (Build 0095)</span><br><span class="line">Copyright (c) 2002 NetSarang Computer, Inc. All rights reserved.</span><br><span class="line"> </span><br><span class="line">Type `<span class="built_in">help</span><span class="string">' to learn how to use Xshell prompt.</span></span><br><span class="line"><span class="string">[C:\~]$ </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">Connecting to 192.168.33.100:22...</span></span><br><span class="line"><span class="string">Connection established.</span></span><br><span class="line"><span class="string">To escape to local shell, press '</span>Ctrl+Alt+]<span class="string">'.</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">WARNING! The remote SSH server rejected X11 forwarding request.</span></span><br><span class="line"><span class="string">Last login: Wed Oct  3 11:25:59 2018</span></span><br><span class="line"><span class="string">[hadoop@master100 ~]$</span></span><br></pre></td></tr></table></figure></p><p>Hadoop 默认模式为非分布式模式，无需进行其他配置即可运行。非分布式即单 Java 进程，方便进行调试。</p><p>Hadoop 附带了丰富的例子（运行 ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar 可以看到所有例子），包括 wordcount、terasort、join、grep 等。在此我们选择运行 grep 例子，我们将 input 文件夹中的所有文件作为输入，筛选当中符合正则表达式 dfs[a-z.]+ 的单词并统计出现的次数，最后输出结果到 output 文件夹中。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master100 ~]$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"> </span><br><span class="line">[hadoop@master100 hadoop]$ ll</span><br><span class="line">总用量 108</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop   194 8月  18 2016 bin</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop    20 8月  18 2016 etc</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop   106 8月  18 2016 include</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop    20 8月  18 2016 lib</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop   239 8月  18 2016 libexec</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop 84854 8月  18 2016 LICENSE.txt</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop 14978 8月  18 2016 NOTICE.txt</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  1366 8月  18 2016 README.txt</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop  4096 8月  18 2016 sbin</span><br><span class="line">drwxr-xr-x. 4 hadoop hadoop    31 8月  18 2016 share</span><br><span class="line"> </span><br><span class="line">[hadoop@master100 hadoop]$ mkdir ./input</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 将配置文件作为输入文件</span></span><br><span class="line">[hadoop@master100 hadoop]$ cp ./etc/hadoop/* ./input</span><br><span class="line"> </span><br><span class="line">[hadoop@master100 hadoop]$ hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar grep ./input ./output <span class="string">'dfs[a-z.]+'</span></span><br><span class="line"> </span><br><span class="line">...........</span><br><span class="line"> </span><br><span class="line"><span class="comment">#查看运行结果</span></span><br><span class="line">[hadoop@master100 hadoop]$ cat ./output/*</span><br><span class="line">6dfs.audit.logger</span><br><span class="line">4dfs.class</span><br><span class="line">3dfs.server.namenode.</span><br><span class="line">2dfs.period</span><br><span class="line">2dfs.audit.log.maxfilesize</span><br><span class="line">2dfs.audit.log.maxbackupindex</span><br><span class="line">1dfsmetrics.log</span><br><span class="line">1dfsadmin</span><br><span class="line">1dfs.servers</span><br><span class="line">1dfs.file</span><br></pre></td></tr></table></figure></p><p>更多的MapReduce例子在这里就不一一测试了，有兴趣的可以自己去测试</p><hr><h1 id="相关推荐"><a href="#相关推荐" class="headerlink" title="相关推荐"></a>相关推荐</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI0ODcx" title="https://blog.csdn.net/u010993514/article/details/82924871">VMware虚拟机安装Linux系统<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI2NTE0" title="https://blog.csdn.net/u010993514/article/details/82926514">Linux系统下安装Java环境<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMzMzQ2" title="https://blog.csdn.net/u010993514/article/details/82933346">CentOS 7部署Hadoop（伪分布式）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTM1ODM0" title="https://blog.csdn.net/u010993514/article/details/82935834">CentOS 7部署Hadoop集群（完全分布式）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgzMDA5ODIy" title="https://blog.csdn.net/u010993514/article/details/83009822">CentOS 7部署Hadoop集群（HA高可用集群）<i class="fa fa-external-link"></i></span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;测试环境&quot;&gt;&lt;a href=&quot;#测试环境&quot; class=&quot;headerlink&quot; title=&quot;测试环境&quot;&gt;&lt;/a&gt;测试环境&lt;/h1&gt;&lt;p&gt;Linux系统版本：CentOS 7 64位&lt;/p&gt;
&lt;p&gt;Hadoop版本：hadoop-2.7.3&lt;/p&gt;
&lt;p&gt;Jav
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/tags/Hadoop/"/>
    
      <category term="Linux" scheme="https://blog.niclas.cn/tags/Linux/"/>
    
      <category term="Hadoop配置" scheme="https://blog.niclas.cn/tags/Hadoop%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>Linux系统下安装Java环境</title>
    <link href="https://blog.niclas.cn/post/Linux%E7%B3%BB%E7%BB%9F%E4%B8%8B%E5%AE%89%E8%A3%85Java%E7%8E%AF%E5%A2%83/"/>
    <id>https://blog.niclas.cn/post/Linux系统下安装Java环境/</id>
    <published>2018-10-02T10:11:24.000Z</published>
    <updated>2018-12-24T13:15:17.144Z</updated>
    
    <content type="html"><![CDATA[<h2 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h2><p>Linux系统版本：CentOS 7 64位  </p><p>终端模拟软件：Xshell 6  </p><p>Java版本：jdk-8u181-linux-x64  </p><hr><h2 id="下载JDK"><a href="#下载JDK" class="headerlink" title="下载JDK"></a>下载JDK</h2><p>下载地址：<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:<span class="regexp">//</span>www.oracle.com<span class="regexp">/technetwork/</span>java<span class="regexp">/javase/</span>downloads<span class="regexp">/jdk8-downloads-2133151.html</span></span><br></pre></td></tr></table></figure></p><p>进入页面后下载64位的包，<a href="">jdk-8u181-linux-x64.tar.gz</a>与<a href="">jdk-8u181-linux-x64.rpm</a>都可以，下面会分别介绍两种包的安装方法，选择其中一种进行安装即可。  </p><p><img src="/post/Linux系统下安装Java环境/0.png" alt="">  </p><hr><h2 id="终端模拟软件"><a href="#终端模拟软件" class="headerlink" title="终端模拟软件"></a>终端模拟软件</h2><p>我这里使用的是Xshell，使用其他软件也可以，下载安装完成后用root用户连接Linux（SSH连接，默认端口：22），不会操作的自己百度，连接之后界面如下：<br><img src="/post/Linux系统下安装Java环境/1.png" alt=""></p><hr><h2 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h2><p>检查系统是否已经有JDK，输入如下命令查看是否系统中是否已安装，部分人在安装CentOS 7时系统会自动安装JDK：  </p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -<span class="built_in">version</span></span><br></pre></td></tr></table></figure><p>如果系统没有安装，输入命令后提示如下（中文版和英文版在语言上会有些区别，但是提示的意思都一样），没有安装的可以直接跳过这里看下面的安装方法了：  </p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 ~]<span class="comment"># java -version</span></span><br><span class="line">-<span class="keyword">bash: </span><span class="keyword">java: </span>未找到命令</span><br></pre></td></tr></table></figure><p>如果显示如下版本信息说明已经安装，可以直接使用系统的JDK，不需要自己安装了  </p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 ~]# java -version</span><br><span class="line">java version <span class="string">"1.8.0_181"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_181-b13)</span><br><span class="line">Java HotSpot(TM) 64-Bit<span class="built_in"> Server </span>VM (build 25.181-b13, mixed mode)</span><br></pre></td></tr></table></figure><p>如果想使用其他版本的JDK，需要先卸载后再安装，卸载方法可以参考下文各种包的卸载方法。</p><hr><h2 id="tar包的安装方法"><a href="#tar包的安装方法" class="headerlink" title="tar包的安装方法"></a>tar包的安装方法</h2><p>1、将下载到本地的文件上传到远程服务器的/usr/local目录下，  </p><p>在Xshell上新建一个文件传输，如图：<br><img src="/post/Linux系统下安装Java环境/2.png" alt=""></p><p>在sftp文件传输命令框内输入如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br></pre></td></tr></table></figure><p><img src="/post/Linux系统下安装Java环境/3.png" alt=""><br>把下载好的文件拖到黑框里面就可以上传了，上传完成后有如下提示：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Uploading jdk-<span class="number">8</span>u181-linux-x64<span class="selector-class">.tar</span><span class="selector-class">.gz</span> to remote:/usr/local/jdk-<span class="number">8</span>u181-linux-x64<span class="selector-class">.tar</span><span class="selector-class">.gz</span></span><br><span class="line">sftp: sent <span class="number">177</span> MB <span class="keyword">in</span> <span class="number">6.13</span> seconds</span><br></pre></td></tr></table></figure><p>我们也可以打开目录查看一下文件，回到SSH窗口，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">ll</span><br></pre></td></tr></table></figure><p>我们可以看到自己上传的jdk-8u181-linux-x64.tar.gz 文件</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 ~]<span class="comment"># cd /usr/local</span></span><br><span class="line">[root@master100 local]<span class="comment"># ll</span></span><br><span class="line">总用量 181296</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 bin</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 etc</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 games</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 include</span><br><span class="line">-rw-r--r--.<span class="number"> 1 </span>root root<span class="number"> 185646832 </span>10月 <span class="number"> 2 </span>16:31 jdk-8u181-linux-x64.tar.gz</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 lib</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 lib64</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 libexec</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 sbin</span><br><span class="line">drwxr-xr-x.<span class="number"> 5 </span>root root       <span class="number"> 49 </span>10月 <span class="number"> 2 </span>13:00 share</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 src</span><br></pre></td></tr></table></figure><p>2、解压文件，命令如下，输入后会出现一长串的提示：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf /usr/local/jdk-<span class="number">8</span>u181-linux-x64<span class="selector-class">.tar</span><span class="selector-class">.gz</span></span><br></pre></td></tr></table></figure><p>3、解压后文件夹名为：jdk1.8.0_181</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 local]<span class="comment"># ll</span></span><br><span class="line">总用量 181296</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 bin</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 etc</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 games</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 include</span><br><span class="line">drwxr-xr-x.<span class="number"> 7 </span> <span class="number"> 10 </span><span class="number"> 143 </span>     <span class="number"> 245 </span>7月  <span class="number"> 7 </span>16:09 jdk1.8.0_181</span><br><span class="line">-rw-r--r--.<span class="number"> 1 </span>root root<span class="number"> 185646832 </span>10月 <span class="number"> 2 </span>16:31 jdk-8u181-linux-x64.tar.gz</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 lib</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 lib64</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 libexec</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 sbin</span><br><span class="line">drwxr-xr-x.<span class="number"> 5 </span>root root       <span class="number"> 49 </span>10月 <span class="number"> 2 </span>13:00 share</span><br><span class="line">drwxr-xr-x.<span class="number"> 2 </span>root root        <span class="number"> 6 </span>4月 <span class="number"> 11 </span>12:59 src</span><br></pre></td></tr></table></figure><p>在这里修改一下文件名，将jdk1.8.0_181改成java，方便我们后面配置环境变量，在这也可以不修改，在配置环境变量时要注意文件名不能写错，修改文件名命令如下：<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv <span class="regexp">/usr/</span>local<span class="regexp">/jdk1.8.0_181 /u</span>sr<span class="regexp">/local/</span>java</span><br></pre></td></tr></table></figure></p><p>4、修改配置文件，配置环境变量，在命令行输入：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">vi</span> /etc/<span class="keyword">profile</span></span><br></pre></td></tr></table></figure></p><p>输入“G”定位到最后一行，按“i”进入编辑模式，在最下面添加如下几行信息：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/local/java</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$JAVA_HOME</span>/bin:$PATH</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JRE_HOME</span>=<span class="variable">$JAVA_HOME</span>/jre</span><br></pre></td></tr></table></figure></p><p>如图：  </p><p><img src="/post/Linux系统下安装Java环境/4.png" alt=""></p><p>添加完之后按ESC退出编辑模式，输入:wq后回车（保存并退出），如图：<br><img src="/post/Linux系统下安装Java环境/5.png" alt=""></p><p>5、让配置文件生效，可以输入如下命令或者是重启系统<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br><span class="line"></span><br><span class="line">重启命令：</span><br><span class="line">init 6</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure></p><p>6、查看安装情况<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -<span class="built_in">version</span></span><br></pre></td></tr></table></figure></p><p>安装成功后会出现如下版本信息：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 ~]# java -version</span><br><span class="line">java version <span class="string">"1.8.0_181"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_181-b13)</span><br><span class="line">Java HotSpot(TM) 64-Bit<span class="built_in"> Server </span>VM (build 25.181-b13, mixed mode)</span><br></pre></td></tr></table></figure></p><h2 id="tar包的卸载"><a href="#tar包的卸载" class="headerlink" title="tar包的卸载"></a>tar包的卸载</h2><p>将安装包删除，然后把配置文件内添加的环境变量删除</p><p>删除安装包的命令如下：<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">rm</span> -rf /usr/<span class="keyword">local</span>/java</span><br></pre></td></tr></table></figure></p><p>修改配置文件的方法和上述配置环境变量一样</p><hr><h2 id="rpm包的安装方法"><a href="#rpm包的安装方法" class="headerlink" title="rpm包的安装方法"></a>rpm包的安装方法</h2><p>1、将下载到本地的文件上传到远程服务器的/usr/local目录下，</p><p>在Xshell上新建一个文件传输，如图：</p><p><img src="/post/Linux系统下安装Java环境/6.png" alt=""></p><p>在sftp文件传输命令框内输入如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br></pre></td></tr></table></figure></p><p><img src="/post/Linux系统下安装Java环境/7.png" alt=""></p><p>把下载好的文件拖到黑框里面就可以上传了，上传完成提示如下：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">sftp:</span><span class="regexp">/usr/</span>local&gt; </span><br><span class="line">Uploading jdk<span class="number">-8</span>u181-linux-x64.rpm to <span class="string">remote:</span><span class="regexp">/usr/</span>local/jdk<span class="number">-8</span>u181-linux-x64.rpm</span><br><span class="line"><span class="string">sftp:</span> sent <span class="number">162</span> MB <span class="keyword">in</span> <span class="number">1.92</span> seconds</span><br></pre></td></tr></table></figure></p><p>2、上传好之后回到命令框，开始安装我们的rpm包，首先我们要赋予安装包执行的权限，命令如下：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod <span class="number">755</span> /usr/local/jdk<span class="number">-8</span>u181-linux-x64.rpm</span><br></pre></td></tr></table></figure></p><p>3、安装rpm包<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh /usr/<span class="keyword">local</span>/jdk<span class="number">-8</span>u181-linux-x64.rpm</span><br></pre></td></tr></table></figure></p><p>出现如下提示信息：<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 local]# rpm -ivh /usr/local/jdk<span class="number">-8</span>u181-linux-x64.rpm</span><br><span class="line">警告：/usr/local/jdk<span class="number">-8</span>u181-linux-x64.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID ec551f03: NOKEY</span><br><span class="line">准备中...                          ################################# [<span class="number">100</span>%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   <span class="number">1</span>:jdk1<span class="number">.8</span><span class="number">-2000</span>:<span class="number">1.8</span><span class="number">.0</span>_181-fcs        ################################# [<span class="number">100</span>%]</span><br><span class="line">Unpacking JAR files...</span><br><span class="line">tools.jar...</span><br><span class="line">plugin.jar...</span><br><span class="line">javaws.jar...</span><br><span class="line">deploy.jar...</span><br><span class="line">rt.jar...</span><br><span class="line">jsse.jar...</span><br><span class="line">charsets.jar...</span><br><span class="line">localedata.jar...</span><br></pre></td></tr></table></figure></p><p>4、配置环境变量</p><p>在命令行输入：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">vi</span> /etc/<span class="keyword">profile</span></span><br></pre></td></tr></table></figure></p><p>输入“G”定位到最后一行，按“i”进入编辑模式，在最下面添加如下几行信息：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_181-amd64</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$JAVA_HOME</span>/bin:$PATH</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JRE_HOME</span>=<span class="variable">$JAVA_HOME</span>/jre</span><br></pre></td></tr></table></figure></p><p>5、让配置文件生效，可以输入如下命令或者是重启系统<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br><span class="line"> </span><br><span class="line">重启命令：</span><br><span class="line">init 6</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure></p><p>6、查看安装情况<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -<span class="built_in">version</span></span><br></pre></td></tr></table></figure></p><p>安装成功后会出现如下版本信息：<br><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 <span class="keyword">jdk1.8.0_181-amd64]# </span><span class="keyword">java </span>-version</span><br><span class="line"><span class="keyword">java </span>version <span class="string">"1.8.0_181"</span></span><br><span class="line"><span class="keyword">Java(TM) </span>SE Runtime Environment (<span class="keyword">build </span><span class="number">1</span>.<span class="number">8</span>.<span class="number">0</span>_181-<span class="keyword">b13)</span></span><br><span class="line"><span class="keyword">Java </span>HotSpot(TM) <span class="number">64</span>-<span class="keyword">Bit </span>Server VM (<span class="keyword">build </span><span class="number">25</span>.<span class="number">181</span>-<span class="keyword">b13, </span>mixed mode)</span><br></pre></td></tr></table></figure></p><h2 id="rpm包的卸载"><a href="#rpm包的卸载" class="headerlink" title="rpm包的卸载"></a>rpm包的卸载</h2><p>1、输入命令查看rpm包安装信息，如果第一条未出现信息，可以使用第二条命令查看，如果都没有可能是未安装或者是tar包安装的<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -<span class="keyword">qa</span> | <span class="keyword">grep</span> jdk</span><br></pre></td></tr></table></figure></p><p>我用上述rpm包安装之后，用命令查看，提示如下：<br><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="symbol">@master100</span> <span class="keyword">local</span>]<span class="meta"># rpm -qa | grep jdk</span></span><br><span class="line">jdk1<span class="number">.8</span><span class="number">-1.8</span><span class="number">.0</span>_181-fcs.x86_64</span><br></pre></td></tr></table></figure></p><p>2、知道安装的rpm包名后就可以卸载了，卸载命令如下：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">rpm</span> <span class="selector-tag">-e</span> <span class="selector-tag">--nodeps</span> <span class="selector-tag">jdk1</span><span class="selector-class">.8-1</span><span class="selector-class">.8</span><span class="selector-class">.0_181-fcs</span><span class="selector-class">.x86_64</span></span><br></pre></td></tr></table></figure></p><p>3、卸载完成后删除环境变量<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><hr><h2 id="相关推荐"><a href="#相关推荐" class="headerlink" title="相关推荐"></a>相关推荐</h2><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI0ODcx" title="https://blog.csdn.net/u010993514/article/details/82924871">VMware虚拟机安装Linux系统<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMwMzUx" title="https://blog.csdn.net/u010993514/article/details/82930351">CentOS 7部署Hadoop（单机版）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMzMzQ2" title="https://blog.csdn.net/u010993514/article/details/82933346">CentOS 7部署Hadoop（伪分布式）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTM1ODM0" title="https://blog.csdn.net/u010993514/article/details/82935834">CentOS 7部署Hadoop集群（完全分布式）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgzMDA5ODIy" title="https://blog.csdn.net/u010993514/article/details/83009822">CentOS 7部署Hadoop集群（HA高可用集群）<i class="fa fa-external-link"></i></span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;测试环境&quot;&gt;&lt;a href=&quot;#测试环境&quot; class=&quot;headerlink&quot; title=&quot;测试环境&quot;&gt;&lt;/a&gt;测试环境&lt;/h2&gt;&lt;p&gt;Linux系统版本：CentOS 7 64位  &lt;/p&gt;
&lt;p&gt;终端模拟软件：Xshell 6  &lt;/p&gt;
&lt;p&gt;Java版
      
    
    </summary>
    
      <category term="Linux" scheme="https://blog.niclas.cn/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://blog.niclas.cn/tags/Linux/"/>
    
      <category term="JDK" scheme="https://blog.niclas.cn/tags/JDK/"/>
    
      <category term="CentOS" scheme="https://blog.niclas.cn/tags/CentOS/"/>
    
  </entry>
  
  <entry>
    <title>VMware虚拟机安装Linux系统</title>
    <link href="https://blog.niclas.cn/post/VMware%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85Linux%E7%B3%BB%E7%BB%9F/"/>
    <id>https://blog.niclas.cn/post/VMware虚拟机安装Linux系统/</id>
    <published>2018-10-02T06:27:09.000Z</published>
    <updated>2018-12-24T13:15:17.161Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h2><p>操作系统：Windows 10, 64-bit  </p><p>虚拟机：<span class="exturl" data-url="aHR0cHM6Ly9teS52bXdhcmUuY29tL2NuL3dlYi92bXdhcmUvaW5mby9zbHVnL2Rlc2t0b3BfZW5kX3VzZXJfY29tcHV0aW5nL3Ztd2FyZV93b3Jrc3RhdGlvbl9wcm8vMTRfMA==" title="https://my.vmware.com/cn/web/vmware/info/slug/desktop_end_user_computing/vmware_workstation_pro/14_0">VMware® Workstation 14 Pro（版本号：14.0.0 build-6661328）<i class="fa fa-external-link"></i></span>    </p><p>Linux镜像版本：<span class="exturl" data-url="aHR0cDovL21pcnJvcnMuYWxpeXVuLmNvbS9jZW50b3MvNy9pc29zL3g4Nl82NC8=" title="http://mirrors.aliyun.com/centos/7/isos/x86_64/">CentOS-7-x86_64-DVD-1804.iso<i class="fa fa-external-link"></i></span></p><hr><h2 id="VMware虚拟机安装"><a href="#VMware虚拟机安装" class="headerlink" title="VMware虚拟机安装"></a>VMware虚拟机安装</h2><p>1、按照软件提示界面安装软件，安装过程就不做说明了； </p><p>附上软件注册机：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1BlbmdTaHVhaXhpbi9Ub29sc0xpYnJhcnkvdHJlZS9tYXN0ZXIvVm13YXJl" title="https://github.com/PengShuaixin/ToolsLibrary/tree/master/Vmware">https://github.com/PengShuaixin/ToolsLibrary/tree/master/Vmware<i class="fa fa-external-link"></i></span></p><p>2、打开软件—-编辑—-虚拟网络编辑器<br><img src="/post/VMware虚拟机安装Linux系统/1.png" alt="image"></p><p>获取管理员权限即可，如图：<br><img src="/post/VMware虚拟机安装Linux系统/2.png" alt="image"></p><p>3、在这里我们将虚拟机路由网关设置成192.168.33.1，按下图设置：  </p><p>先将子网IP设置成192.168.33.0，子网掩码：255.255.255.0，然后设置“NAT设置”<br><img src="/post/VMware虚拟机安装Linux系统/3.png" alt="image"></p><p>NET设置参数如下：<br><img src="/post/VMware虚拟机安装Linux系统/4.png" alt="image"></p><p>4、打开控制面板—-网络和 Internet—-网络连接，设置VMnet8的IPv4协议；<br><img src="/post/VMware虚拟机安装Linux系统/5.png" alt="image">  </p><hr><h2 id="CentOS安装"><a href="#CentOS安装" class="headerlink" title="CentOS安装"></a>CentOS安装</h2><p>1、新建一个虚拟机，选择自定义安装，根据提示根据自己的实际情况选择配置；<br><img src="/post/VMware虚拟机安装Linux系统/6.png" alt="image">  </p><p>这里选择自己镜像文件的路径，<br><img src="/post/VMware虚拟机安装Linux系统/7.png" alt="image"></p><p>根据自己的喜好命名虚拟机、选择虚拟机文件路径，后面两步分配CPU资源和内存资源根据自己电脑实际情况分配,<br><img src="/post/VMware虚拟机安装Linux系统/8.png" alt="image">  </p><p>注意这里的网络设置要选择NET， IO控制器按照系统推荐的就行，<br><img src="/post/VMware虚拟机安装Linux系统/9.png" alt="image"></p><p>我这里磁盘设置如下图：<br><img src="/post/VMware虚拟机安装Linux系统/10.png" alt="image"><br><img src="/post/VMware虚拟机安装Linux系统/11.png" alt="image"><br><img src="/post/VMware虚拟机安装Linux系统/12.png" alt="image"></p><p>2、配置完成后启动虚拟机，鼠标点进去按上下键选择，选择Install CentOS 7后回车（Alt+Shift键可以释放鼠标）；<br><img src="/post/VMware虚拟机安装Linux系统/13.png" alt="image"><br>等待一会儿就进入安装界面，为了方便展示设置这里语言设置我就选择简体中文了，<br><img src="/post/VMware虚拟机安装Linux系统/14.png" alt="image">  </p><p>3、接下来我们对以下三个选项进行设置；<br><img src="/post/VMware虚拟机安装Linux系统/15.png" alt="image"> </p><p>软件选择我就选“最小安装”了，有兴趣的可以自己选择安装一个桌面，选择完成后点“完成”<br><img src="/post/VMware虚拟机安装Linux系统/16.png" alt="image">  </p><p>安装位置没有特殊需求情况下不需要手动设置，点开设置之后直接点完成即可，<br><img src="/post/VMware虚拟机安装Linux系统/17.png" alt="image"></p><p>下面是网络设置，在这里也可以先跳过这一步，进入系统之后我们可以直接修改配置文件设置，<br><img src="/post/VMware虚拟机安装Linux系统/18.png" alt="image">  </p><p>IPv4按如下设置，将该虚拟机设置成静态IP，IP地址为192.168.33.100：<br><img src="/post/VMware虚拟机安装Linux系统/19.png" alt="image">  </p><p>IPv6设置成忽略，如下图：<br><img src="/post/VMware虚拟机安装Linux系统/20.png" alt="image">  </p><p>设置完成之后保存设置，保存之后打开右上角网络连接，最后点左上角的完成，<br><img src="/post/VMware虚拟机安装Linux系统/21.png" alt="image">  </p><p><strong>在这里补充一下安装过程设置主机名的方法：</strong><br><img src="/post/VMware虚拟机安装Linux系统/22.png" alt="image">  </p><p>4、设置完成后就可以开始安装了；<br><img src="/post/VMware虚拟机安装Linux系统/23.png" alt="image"></p><p>在这儿我们还需要对Root密码进行设置，<br><img src="/post/VMware虚拟机安装Linux系统/24.png" alt="image"></p><p>设置完密码后点完成，在输入密码的过程中注意不要使用小键盘，若系统提示密码过于简单，点两次完成即可保存设置的密码，最后就等待进度条完成安装。<br><img src="/post/VMware虚拟机安装Linux系统/25.png" alt="image"></p><p>5、出现如下界面之后我们点击右下角“重启”按钮重启一下系统就完成安装了。<br><img src="/post/VMware虚拟机安装Linux系统/26.png" alt="image"></p><hr><h2 id="CentOS设置"><a href="#CentOS设置" class="headerlink" title="CentOS设置"></a>CentOS设置</h2><h3 id="主机名设置"><a href="#主机名设置" class="headerlink" title="主机名设置"></a>主机名设置</h3><p>编辑hostname文件，这只是其中一种方法，想了解更多方法可以自己百度</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">vi</span> /etc/<span class="built_in">hostname</span></span><br></pre></td></tr></table></figure><p>按键盘上的字母“i”进入编辑模式，修改主机名：  </p><p><img src="/post/VMware虚拟机安装Linux系统/27.png" alt="image"></p><p>修改完成之后按ESC，输入“:wq”保存并退出，然后重启系统，以下两条命令任意一条都可以重启系统：<br><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br><span class="line"><span class="keyword">init</span> <span class="number">6</span></span><br></pre></td></tr></table></figure></p><p>这里再扩展一下关机命令：<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init <span class="number">0</span></span><br><span class="line"><span class="built_in">shutdown</span> -h now</span><br><span class="line">halt</span><br></pre></td></tr></table></figure></p><p>重启完重新登录就完成修改了，如图：<br><img src="/post/VMware虚拟机安装Linux系统/28.png" alt="image"></p><h3 id="网络设置"><a href="#网络设置" class="headerlink" title="网络设置"></a>网络设置</h3><p>在上述安装过程中没有配置网络的可以在此对网络进行设置，这里代码比较长，可以用Xshell连接虚拟主机进行配置，复制粘贴代码比较方便，此处建议在安装过程中就提前设置好网络。</p><p>修改ifcfg-ens33配置文件<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>sysconfig<span class="regexp">/network-scripts/i</span>fcfg-ens33</span><br></pre></td></tr></table></figure></p><p>配置如下：<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">TYPE</span>=<span class="string">"Ethernet"</span></span><br><span class="line"><span class="attr">PROXY_METHOD</span>=<span class="string">"none"</span></span><br><span class="line"><span class="attr">BROWSER_ONLY</span>=<span class="string">"no"</span></span><br><span class="line"><span class="attr">BOOTPROTO</span>=<span class="string">"none"</span></span><br><span class="line"><span class="attr">DEFROUTE</span>=<span class="string">"yes"</span></span><br><span class="line"><span class="attr">IPV4_FAILURE_FATAL</span>=<span class="string">"no"</span></span><br><span class="line"><span class="attr">IPV6INIT</span>=<span class="string">"no"</span></span><br><span class="line"><span class="attr">IPV6_AUTOCONF</span>=<span class="string">"yes"</span></span><br><span class="line"><span class="attr">IPV6_DEFROUTE</span>=<span class="string">"yes"</span></span><br><span class="line"><span class="attr">IPV6_FAILURE_FATAL</span>=<span class="string">"no"</span></span><br><span class="line"><span class="attr">IPV6_ADDR_GEN_MODE</span>=<span class="string">"stable-privacy"</span></span><br><span class="line"><span class="attr">NAME</span>=<span class="string">"ens33"</span></span><br><span class="line"><span class="attr">UUID</span>=<span class="string">"fa0d7aef-28a6-41d3-9a20-262748c5d4a5"</span></span><br><span class="line"><span class="attr">DEVICE</span>=<span class="string">"ens33"</span></span><br><span class="line"><span class="attr">ONBOOT</span>=<span class="string">"yes"</span></span><br><span class="line"><span class="attr">IPADDR</span>=<span class="string">"192.168.33.100"</span></span><br><span class="line"><span class="attr">PREFIX</span>=<span class="string">"24"</span></span><br><span class="line"><span class="attr">GATEWAY</span>=<span class="string">"192.168.33.1"</span></span><br><span class="line"><span class="attr">DNS1</span>=<span class="string">"192.168.33.1"</span></span><br></pre></td></tr></table></figure></p><p>注释：<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">IPADDR</span>=<span class="string">"192.168.33.100"</span> //IP地址</span><br><span class="line"><span class="attr">PREFIX</span>=<span class="string">"24"</span>//子网掩码<span class="number">255.255</span>.<span class="number">255.0</span>，也可以写成：NETMASK=<span class="string">"255.255.255.0"</span></span><br><span class="line"><span class="attr">GATEWAY</span>=<span class="string">"192.168.33.1"</span>//网关</span><br><span class="line"><span class="attr">DNS1</span>=<span class="string">"192.168.33.1"</span>//DNS服务器，还可以在后面加一个DNS2</span><br></pre></td></tr></table></figure></p><p>修改完之后保存退出，运行如下命令可让网络配置立即生效：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service<span class="built_in"> network </span>restart</span><br></pre></td></tr></table></figure></p><p>还有一个地方的文件也是DNS设置文件，在这里上面已经设置了DNS服务器就不需要修改了，可以查看了解一下<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cat</span> /etc/resolv.<span class="keyword">conf</span></span><br></pre></td></tr></table></figure></p><hr><h2 id="CentOS测试"><a href="#CentOS测试" class="headerlink" title="CentOS测试"></a>CentOS测试</h2><h3 id="系统登录"><a href="#系统登录" class="headerlink" title="系统登录"></a>系统登录</h3><p>输入登录用户名:root,回车，然后输入密码，密码为安装时自己设置的密码。输入密码时不会有任何显示，输入完之后回车即可登录。注意：不要用小键盘输入密码！！<br><img src="/post/VMware虚拟机安装Linux系统/29.png" alt="image"></p><h3 id="网络测试"><a href="#网络测试" class="headerlink" title="网络测试"></a>网络测试</h3><p>查看本机IP<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ip a</span></span><br></pre></td></tr></table></figure></p><p>会显示出本机IP信息：  </p><p><img src="/post/VMware虚拟机安装Linux系统/30.png" alt="image"></p><p>外网测试（测试过程中按Ctrl+c可以终止正在执行的进程）：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping www<span class="selector-class">.baidu</span><span class="selector-class">.com</span></span><br></pre></td></tr></table></figure></p><p> 测试结果如下就证明可以访问外网：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 network-scripts]#<span class="built_in"> ping </span>www.baidu.com</span><br><span class="line">PING www.a.shifen.com (220.181.111.188) 56(84) bytes of data.</span><br><span class="line">64 bytes <span class="keyword">from</span> 220.181.111.188 (220.181.111.188): <span class="attribute">icmp_seq</span>=1 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=10.2 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 220.181.111.188 (220.181.111.188): <span class="attribute">icmp_seq</span>=2 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=3.48 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 220.181.111.188 (220.181.111.188): <span class="attribute">icmp_seq</span>=3 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=4.93 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 220.181.111.188 (220.181.111.188): <span class="attribute">icmp_seq</span>=4 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=12.0 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 220.181.111.188 (220.181.111.188): <span class="attribute">icmp_seq</span>=5 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=3.91 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 220.181.111.188 (220.181.111.188): <span class="attribute">icmp_seq</span>=6 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=3.86 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 220.181.111.188 (220.181.111.188): <span class="attribute">icmp_seq</span>=7 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=3.81 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 220.181.111.188 (220.181.111.188): <span class="attribute">icmp_seq</span>=8 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=10.8 ms</span><br><span class="line">^C</span><br><span class="line">--- www.a.shifen.com<span class="built_in"> ping </span>statistics ---</span><br><span class="line">8 packets transmitted, 8 received, 0% packet loss, time 7017ms</span><br><span class="line">rtt min/avg/max/mdev = 3.484/6.642/12.094/3.464 ms</span><br></pre></td></tr></table></figure></p><p><strong>内网测试：</strong></p><p>ping路由IP地址：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">ping</span> 192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.1</span></span><br></pre></td></tr></table></figure></p><p>结果如下证明网络配置没有问题：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@master100 network-scripts]#<span class="built_in"> ping </span>192.168.33.1</span><br><span class="line">PING 192.168.33.1 (192.168.33.1) 56(84) bytes of data.</span><br><span class="line">64 bytes <span class="keyword">from</span> 192.168.33.1: <span class="attribute">icmp_seq</span>=1 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=0.260 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 192.168.33.1: <span class="attribute">icmp_seq</span>=2 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=0.131 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 192.168.33.1: <span class="attribute">icmp_seq</span>=3 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=0.197 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 192.168.33.1: <span class="attribute">icmp_seq</span>=4 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=0.115 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 192.168.33.1: <span class="attribute">icmp_seq</span>=5 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=0.195 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 192.168.33.1: <span class="attribute">icmp_seq</span>=6 <span class="attribute">ttl</span>=128 <span class="attribute">time</span>=0.198 ms</span><br><span class="line">^C</span><br><span class="line">--- 192.168.33.1<span class="built_in"> ping </span>statistics ---</span><br><span class="line">6 packets transmitted, 6 received, 0% packet loss, time 5000ms</span><br><span class="line">rtt min/avg/max/mdev = 0.115/0.182/0.260/0.050 ms</span><br></pre></td></tr></table></figure></p><hr><h2 id="相关推荐"><a href="#相关推荐" class="headerlink" title="相关推荐"></a>相关推荐</h2><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI2NTE0" title="https://blog.csdn.net/u010993514/article/details/82926514">Linux系统下安装Java环境<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMwMzUx" title="https://blog.csdn.net/u010993514/article/details/82930351">CentOS 7部署Hadoop（单机版）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMzMzQ2" title="https://blog.csdn.net/u010993514/article/details/82933346">CentOS 7部署Hadoop（伪分布式）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTM1ODM0" title="https://blog.csdn.net/u010993514/article/details/82935834">CentOS 7部署Hadoop集群（完全分布式）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgzMDA5ODIy" title="https://blog.csdn.net/u010993514/article/details/83009822">CentOS 7部署Hadoop集群（HA高可用集群）<i class="fa fa-external-link"></i></span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;h2 id=&quot;测试环境&quot;&gt;&lt;a href=&quot;#测试环境&quot; class=&quot;headerlink&quot; title=&quot;测试环境&quot;&gt;&lt;/a&gt;测试环境&lt;/h2&gt;&lt;p&gt;操作系统：Windows 10, 64-bit  &lt;/p&gt;
&lt;p&gt;虚拟机：&lt;span class=&quot;exturl&quot;
      
    
    </summary>
    
      <category term="Linux" scheme="https://blog.niclas.cn/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://blog.niclas.cn/tags/Linux/"/>
    
      <category term="CentOS" scheme="https://blog.niclas.cn/tags/CentOS/"/>
    
      <category term="VMware" scheme="https://blog.niclas.cn/tags/VMware/"/>
    
  </entry>
  
  <entry>
    <title>Eclipse中GitHub插件的简单使用</title>
    <link href="https://blog.niclas.cn/post/Eclipse%E4%B8%ADGitHub%E6%8F%92%E4%BB%B6%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/"/>
    <id>https://blog.niclas.cn/post/Eclipse中GitHub插件的简单使用/</id>
    <published>2018-09-15T03:41:36.000Z</published>
    <updated>2018-12-24T13:15:17.088Z</updated>
    
    <content type="html"><![CDATA[<h3 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h3><p>操作系统：Windows 10<br>软件版本：<span class="exturl" data-url="aHR0cHM6Ly93d3cuZWNsaXBzZS5vcmcvZG93bmxvYWRzL3BhY2thZ2VzL3JlbGVhc2UvbmVvbi8z" title="https://www.eclipse.org/downloads/packages/release/neon/3">Eclipse Neon（4.6）<i class="fa fa-external-link"></i></span>  Eclipse IDE for Java EE </p><h3 id="GitHub简介"><a href="#GitHub简介" class="headerlink" title="GitHub简介"></a>GitHub简介</h3><p>GitHub是用于版本控制和协作的代码托管平台。它可以让您和其他人在任何地方协同工作[1]。</p><p>关于Git和GitHub:</p><p>Github是代码托管平台，是协作的工具;而Git是版本控制工具。<br>Git不需要联网，在本机就可以使用，例如我经常用它来保存论文修改的中间状态文稿；Git也可以和其他的代码托管平台结合使用[2]。</p><p>若想具体了解Git的使用方法，可以自己去网上学习，在这里给大家推荐：<br><span class="exturl" data-url="aHR0cHM6Ly93d3cubGlhb3h1ZWZlbmcuY29tL3dpa2kvMDAxMzczOTUxNjMwNTkyOTYwNmRkMTgzNjEyNDg1NzhjNjdiODA2N2M4YzAxN2IwMDA=" title="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000">Git教程 - 廖雪峰的官方网站<i class="fa fa-external-link"></i></span></p><hr><h3 id="Eclipse中GitHub插件的简单使用"><a href="#Eclipse中GitHub插件的简单使用" class="headerlink" title="Eclipse中GitHub插件的简单使用"></a>Eclipse中GitHub插件的简单使用</h3><p>1、如果还没有GitHub的账号，就先去<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLw==" title="https://github.com/">GitHub<i class="fa fa-external-link"></i></span>注册一个账号，有账号的可以跳过这一步；</p><p><img src="/post/Eclipse中GitHub插件的简单使用/1.jpg" alt="这里写图片描述"></p><p>打开网页可看到该界面，按照提示一步步注册完成即可。也可以点击右上角Sign up进入如下界面进行注册，具体的注册步骤在此就不讨论了。</p><p><img src="/post/Eclipse中GitHub插件的简单使用/2.jpg" alt="这里写图片描述"></p><p>2、注册完成后点击Sign in登录账号；</p><p><img src="/post/Eclipse中GitHub插件的简单使用/3.jpg" alt="这里写图片描述"></p><p>输入注册好的用户名，密码登录账号，出现如下界面：</p><p><img src="/post/Eclipse中GitHub插件的简单使用/4.png" alt="这里写图片描述"></p><p>3、新建一个代码仓库；</p><p>点击Start a project，进入如下界面</p><p><img src="/post/Eclipse中GitHub插件的简单使用/5.jpg" alt="这里写图片描述"></p><p>填写好存储库相关信息后点Create repository即可创建成功</p><p><img src="/post/Eclipse中GitHub插件的简单使用/6.jpg" alt="这里写图片描述"></p><p>4、获取仓库链接；</p><p><img src="/post/Eclipse中GitHub插件的简单使用/7.jpg" alt="这里写图片描述"></p><p>5、打开Eclipse；</p><p>点右上角Open Perspective，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/8.jpg" alt="这里写图片描述"></p><p>选择左边界面中间的选项，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/9.jpg" alt="这里写图片描述"></p><p>在弹出的窗口里面填写相关信息，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/10.jpg" alt="这里写图片描述"></p><p>点Next，出现下面界面，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/11.jpg" alt="这里写图片描述"></p><p>继续点Next，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/12.jpg" alt="这里写图片描述"></p><p>修改路径之后，点Finish，出现如下界面说明GitHub仓库连接成功，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/13.jpg" alt="这里写图片描述"></p><p>6、创建完成后，会自动同步远程仓库中的内容，打开我们刚刚设置的路径就能看到仓库里面的文件已经同步到本地了；</p><p><img src="/post/Eclipse中GitHub插件的简单使用/14.jpg" alt="这里写图片描述"></p><p>7、回到java工程页面，开始上传我们的项目；</p><p><img src="/post/Eclipse中GitHub插件的简单使用/15.jpg" alt="这里写图片描述"></p><p>8、右键项目，选择Team—-Share Project；</p><p><img src="/post/Eclipse中GitHub插件的简单使用/16.jpg" alt="这里写图片描述"></p><p>9、下图的方法会将项目文件移动到Git的本地文件夹中，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/17.jpg" alt="这里写图片描述"></p><p>工程文件也被移动到了我们选择的本地仓库路径下面，如图：</p><p><img src="/post/Eclipse中GitHub插件的简单使用/18.jpg" alt="这里写图片描述"></p><p>10、先将工程提交到本地仓库；</p><p>右键项目文件—-Team—-Commit…</p><p><img src="/post/Eclipse中GitHub插件的简单使用/19.jpg" alt="这里写图片描述"></p><p>选中需要提交的修改，右键—-Add to index，接着填写好Commit Message，选择右下角Commit提交修改到本地仓库（Commit and Push…可以直接提交本地并同步到远程仓库，为方便下面的演示，就先提交到本地）</p><p><img src="/post/Eclipse中GitHub插件的简单使用/20.jpg" alt="这里写图片描述"></p><p>完成后如图：</p><p><img src="/post/Eclipse中GitHub插件的简单使用/21.jpg" alt="这里写图片描述"></p><p>11、提交到远程仓库</p><p>右键项目文件—-Team—-Remote—-Push…</p><p><img src="/post/Eclipse中GitHub插件的简单使用/22.jpg" alt="这里写图片描述"></p><p>选择第一个选项，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/23.jpg" alt="这里写图片描述"></p><p>选择一条分支，Add Spec，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/24.jpg" alt="这里写图片描述"></p><p>Next—-Finish提交，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/25.jpg" alt="这里写图片描述"></p><p>出现下面界面说明提交成功，点OK可以退出界面</p><p><img src="/post/Eclipse中GitHub插件的简单使用/26.jpg" alt="这里写图片描述"></p><p>12、到这里我们=可以去自己的GitHub网页验证一下，有自己提交的项目说明成功了，</p><p><img src="/post/Eclipse中GitHub插件的简单使用/27.jpg" alt="这里写图片描述"></p><p>如果没能成功提交，可以重新尝试，第一次使用该工具不建议用自己的代码进行测试，最好新建一个项目使用熟练后再去提交自己的项目。</p><p>GitHub仓库还有着更多好用的功能，比如说分支提交，在此就不做介绍了，有兴趣的朋友可以自己去研究学习。最后，欢迎大家在评论区对本文的不足之处进行补充说明。</p><hr><h3 id="参考网站"><a href="#参考网站" class="headerlink" title="参考网站"></a>参考网站</h3><h6 id="1-GitHub官方教程：https-guides-github-com-activities-hello-world"><a href="#1-GitHub官方教程：https-guides-github-com-activities-hello-world" class="headerlink" title="[1] GitHub官方教程：https://guides.github.com/activities/hello-world/"></a>[1] GitHub官方教程：<span class="exturl" data-url="aHR0cHM6Ly9ndWlkZXMuZ2l0aHViLmNvbS9hY3Rpdml0aWVzL2hlbGxvLXdvcmxkLw==" title="https://guides.github.com/activities/hello-world/">https://guides.github.com/activities/hello-world/<i class="fa fa-external-link"></i></span></h6><h6 id="2-如何高效入门Github？-https-www-jianshu-com-p-13d356e76659"><a href="#2-如何高效入门Github？-https-www-jianshu-com-p-13d356e76659" class="headerlink" title="[2]如何高效入门Github？:https://www.jianshu.com/p/13d356e76659"></a>[2]如何高效入门Github？:<span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC8xM2QzNTZlNzY2NTk=" title="https://www.jianshu.com/p/13d356e76659">https://www.jianshu.com/p/13d356e76659<i class="fa fa-external-link"></i></span></h6><hr><h6 id="本文部分内容来自于网络，如有侵权，请联系作者删除！"><a href="#本文部分内容来自于网络，如有侵权，请联系作者删除！" class="headerlink" title="本文部分内容来自于网络，如有侵权，请联系作者删除！"></a>本文部分内容来自于网络，如有侵权，请联系作者删除！</h6>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;测试环境&quot;&gt;&lt;a href=&quot;#测试环境&quot; class=&quot;headerlink&quot; title=&quot;测试环境&quot;&gt;&lt;/a&gt;测试环境&lt;/h3&gt;&lt;p&gt;操作系统：Windows 10&lt;br&gt;软件版本：&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM
      
    
    </summary>
    
      <category term="Java" scheme="https://blog.niclas.cn/categories/Java/"/>
    
    
      <category term="Eclipse" scheme="https://blog.niclas.cn/tags/Eclipse/"/>
    
      <category term="Github" scheme="https://blog.niclas.cn/tags/Github/"/>
    
      <category term="Java" scheme="https://blog.niclas.cn/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Linux系统配置SSH免密登录(多主机互通)</title>
    <link href="https://blog.niclas.cn/post/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AESSH%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95-%E5%A4%9A%E4%B8%BB%E6%9C%BA%E4%BA%92%E9%80%9A/"/>
    <id>https://blog.niclas.cn/post/Linux系统配置SSH免密登录-多主机互通/</id>
    <published>2018-08-26T12:16:11.000Z</published>
    <updated>2018-12-24T13:15:17.160Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本文测试环境:</strong></p><p>Linux系统镜像:CentOS-7-x86_64-DVD-1804.iso<br>虚拟机版本:VMware-workstation-full-12.1.0-3272444</p><p><strong>操作成功后的效果:</strong><br>每台主机可以本机SSH免密登录,也可以与其他主机之间实现SSH免密登录,也就是每台主机都可以一对多SSH免密登录.</p><p>现用虚拟机搭建三台主机,IP分别是:<br>192.168.33.201    master1<br>192.168.33.202    master2<br>192.168.33.203    master3</p><p>SSH免密登录的原理在这里就不做介绍了,有兴趣的可以自己去网上找资料了解一下,在这里就直接上方法了.</p><hr><p>PS:<br>authorized_keys:存放远程免密登录的公钥,主要通过这个文件记录多台机器的公钥<br>id_rsa : 生成的私钥文件<br>id_rsa.pub ： 生成的公钥文件<br>know_hosts : 已知的主机公钥清单</p><hr><p><strong>方法一:</strong></p><p>先选择其中一台主机,在该主机上生成公钥和私钥,再将公钥和私钥上传到其他主机上,具体操作如下:<br>在这里我就选择master1进行操作以下操作了:<br>1.登录Linux系统,根据自己实际情况选择登录用户,执行下面代码生成公钥私钥对:<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ssh-keygen -t rsa</span></span><br></pre></td></tr></table></figure></p><p>会出现如下提示,一路回车就行<br><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="meta">@master1</span> ~]<span class="comment"># ssh-keygen -t rsa</span></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/root/.ssh/id_rsa): //这里回车</span><br><span class="line">Enter passphrase (empty for no passphrase): //这里回车</span><br><span class="line">Enter same passphrase again: //这里回车</span><br><span class="line">Your identification has been saved in /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">df:71:f6:3e:bb:bb:6c:38:91:f4:bc:70:a1:dd:86:a9 root<span class="meta">@master1</span></span><br><span class="line">The key's randomart image is:</span><br><span class="line">+--[ RSA 2048]----+</span><br><span class="line">|<span class="string">                 </span>|</span><br><span class="line">|<span class="string">                 </span>|</span><br><span class="line">|<span class="string">                 </span>|</span><br><span class="line">|<span class="string">             . . </span>|</span><br><span class="line">|<span class="string">        S   o Ooo</span>|</span><br><span class="line">|<span class="string">         . . Oo*o</span>|</span><br><span class="line">|<span class="string">          . ..=.o</span>|</span><br><span class="line">|<span class="string">            Eo.= </span>|</span><br><span class="line">|<span class="string">              o*B</span>|</span><br><span class="line">+-----------------+</span><br></pre></td></tr></table></figure></p><p>注意：在程序提示输入passphrase时直接输入回车，表示无证书密码。</p><p>2.生成秘钥的默认目录为:~/.ssh,该目录下会生成下面两个文件:</p><p>id_rsa </p><p>id_rsa.pub</p><p>2.实现本地免密登录,将id_rsa.pub中的内容拷贝到authorized_keys</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-<span class="keyword">copy</span>-<span class="built_in">id</span> localhost</span><br></pre></td></tr></table></figure><p>~/.ssh目录下会生成一个新的文件:authorized_keys</p><p>3.完成上述步骤后就可以本地SSH免密登录了,运行下面代码出现一行登录时间就代表本地SSH免密登录成功</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ssh localhost</span></span><br></pre></td></tr></table></figure><p>下面是本地SSH免密登录成功的标志:<br><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@master1 ~]</span>$ ssh localhost</span><br><span class="line">Last login: Mon Aug <span class="number">27</span> <span class="number">08</span>:<span class="number">41</span>:<span class="number">20</span> <span class="number">2018</span> from <span class="number">192.168.33.2</span></span><br></pre></td></tr></table></figure></p><p>4.如果本机能成功SSH免密登录,<br>先退出SSH登录:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">exit</span></span><br></pre></td></tr></table></figure><p>再执行以下代码将本机的~/.ssh文件夹复制到其他主机上:</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r ~<span class="regexp">/.ssh/</span>* <span class="number">192.168</span>.<span class="number">33.202</span><span class="symbol">:~/</span>.ssh</span><br></pre></td></tr></table></figure><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r ~<span class="regexp">/.ssh/</span>* <span class="number">192.168</span>.<span class="number">33.203</span><span class="symbol">:~/</span>.ssh</span><br></pre></td></tr></table></figure><p>提示输入密码时,输入远程主机密码回车即可</p><p>5.测试SSH免密登录,这里就不发测试了,大家自行测试</p><hr><p><strong>方法二:</strong></p><p>将每台机器生成的id_rsa.pub追加添加到同一个authorized_keys内,然后再将该authorized_keys发送到其他远程主机上.</p><p>具体步骤如下:<br>1.在master1,master2,master3上分别执行:</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ssh-keygen -t rsa</span></span><br></pre></td></tr></table></figure><p>与”方法一”内所述一样,一路回车即可,生成秘钥的默认目录为~/.ssh<br>2.接着制作包含master1,master2,master3中所有id_rsa.pub的authorized_keys文件:<br>此处在master 1上生成authorized_keys文件,<br>在master1上执行:</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">ssh-copy-id</span> <span class="selector-tag">-i</span> 192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.201</span></span><br></pre></td></tr></table></figure><p>在master2上执行:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">ssh-copy-id</span> <span class="selector-tag">-i</span> 192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.201</span></span><br></pre></td></tr></table></figure></p><p>在master3上执行:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">ssh-copy-id</span> <span class="selector-tag">-i</span> 192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.201</span></span><br></pre></td></tr></table></figure></p><p>注意:此处代码中的”-i”千万不要忘记了!!!</p><p>3.通过scp将master1上生成的authorized_keys文件发送给其他主机:<br>在master1上执行<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r ~<span class="regexp">/.ssh/authorized</span>_keys <span class="number">192.168</span>.<span class="number">33.202</span><span class="symbol">:~/</span>.ssh</span><br></pre></td></tr></table></figure></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r ~<span class="regexp">/.ssh/authorized</span>_keys <span class="number">192.168</span>.<span class="number">33.203</span><span class="symbol">:~/</span>.ssh</span><br></pre></td></tr></table></figure><p>提示输入密码时,输入远程主机密码回车即可</p><p>5.测试SSH免密登录,可先测试本机免密登录,再测试远程主机远程登录<br>本机登录可用:<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ssh localhost</span></span><br></pre></td></tr></table></figure></p><p>远程登录将localhost换成远程主机IP即可<br>比如在master1上登录master2,就在master1上执行:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">ssh</span> 192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.202</span></span><br></pre></td></tr></table></figure></p><p><strong>相关故障处理:</strong><br>部分人在配置完成后可能出现无法登录的情况,错误代码我不太记得了,欢迎各位读者在下面补充.<br>造成故障的原因是之前配置过程中配置失败,然后重新对SSH免密登录进行配置,配置完成后无法正常登录,解决方法如下:</p><p>删除各主机下~/.ssh目录中的known_hosts文件:<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf ~<span class="regexp">/.ssh/</span>known_hosts</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;本文测试环境:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Linux系统镜像:CentOS-7-x86_64-DVD-1804.iso&lt;br&gt;虚拟机版本:VMware-workstation-full-12.1.0-3272444&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;操作成
      
    
    </summary>
    
      <category term="Linux" scheme="https://blog.niclas.cn/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://blog.niclas.cn/tags/Linux/"/>
    
      <category term="SSH" scheme="https://blog.niclas.cn/tags/SSH/"/>
    
      <category term="服务器" scheme="https://blog.niclas.cn/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>在Windows中安装Hadoop常见错误解决方法</title>
    <link href="https://blog.niclas.cn/post/%E5%9C%A8Windows%E4%B8%AD%E5%AE%89%E8%A3%85Hadoop%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <id>https://blog.niclas.cn/post/在Windows中安装Hadoop常见错误解决方法/</id>
    <published>2018-08-26T05:31:21.000Z</published>
    <updated>2018-12-24T13:47:32.710Z</updated>
    
    <content type="html"><![CDATA[<p>本文的是在Windows10系统中运行的情况,其他版本的系统需自己尝试以下解决办法;</p><p>Hadoop版本:<span class="exturl" data-url="aHR0cHM6Ly9hcmNoaXZlLmFwYWNoZS5vcmcvZGlzdC9oYWRvb3AvY29tbW9uL2hhZG9vcC0yLjcuMy8=" title="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.3/">hadoop-2.7.3<i class="fa fa-external-link"></i></span></p><p>Windows系统中Hadoop的具体配置方法在此就不赘述了,请自行查阅相关文档,下面直接开始上问题解决方法:</p><p><strong>错误一:</strong><br><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Error: </span>JAVA_HOME is incorrectly set.</span><br><span class="line">       Please update D:\hadoop\hadoop<span class="string">-2</span>.7.3\conf\hadoop-env.cmd</span><br></pre></td></tr></table></figure></p><p>该错误代码是Hadoop中java环境变量配置错误导致的,修改Hadoop配置文件即可解决</p><p>我的Hadoop安装目录在: D:\hadoop\hadoop-2.7.3,下面就以此为例,</p><p>配置文件存放在hadoop中的etc目录下,我们打开D:\hadoop\hadoop-2.7.3\etc\hadoop\hadoop-env.cmd文件,<br>找到如下代码:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">set</span> <span class="attribute">JAVA_HOME</span>=%JAVA_HOME%</span><br></pre></td></tr></table></figure><p>将%JAVA_HOME%用具体的jdk安装路径替代,<br>比如说Java的安装路径为C:\Program Files\Java\,jdk版本为:jdk1.8.0_181<br>则将上面的代码替换成如下代码:<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">set</span> <span class="attribute">JAVA_HOME</span>=C:\PROGRA~1\Java\jdk1.8.0_181</span><br></pre></td></tr></table></figure></p><hr><p>PS:<br>此处的路径C:\Program Files中带有空格,直接写该路径系统无法正常识别,故在此用软链代替,将C:\Program Files写成<br>C:\PROGRA~1;<br>此处也可以用引号包围,即将C:\Program Files写成<br>C:”\Program Files”</p><hr><p><strong>错误二:</strong></p><p>启动hadoop进程时,namenode,nodemanager,datanode进程报如下错误代码:<br><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">java.lang.UnsatisfiedLinkError: </span><span class="keyword">org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native </span>Method)</span><br><span class="line">        <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:609)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:977)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.util.DiskChecker.checkAccessByFileMethods(DiskChecker.java:187)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.util.DiskChecker.checkDirAccess(DiskChecker.java:174)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:157)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.server.datanode.DataNode$DataNodeDiskChecker.checkDir(DataNode.java:2345)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.server.datanode.DataNode.checkStorageLocations(DataNode.java:2387)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2369)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2261)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2308)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2485)</span></span><br><span class="line"><span class="keyword"> </span>       <span class="built_in">at</span> <span class="keyword">org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2509)</span></span><br></pre></td></tr></table></figure></p><p>该错误是电脑java版本导致的错误,部分电脑安装的是32位java环境.<br>本机使用如下版本java(32位)测试时,会报上面所述错误代码,<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java version <span class="string">"1.8.0_161"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_161-b12)</span><br><span class="line">Java HotSpot(TM)<span class="built_in"> Client </span>VM (build 25.161-b12, mixed mode)</span><br></pre></td></tr></table></figure></p><p>具体解决方案如下:<br>1.先用控制面板卸载计算机上的java;<br>2.重新下载安装一个新的64位java;<br>本文使用的是:<span class="exturl" data-url="aHR0cDovL3d3dy5vcmFjbGUuY29tL3RlY2huZXR3b3JrL2phdmEvamF2YXNlL2Rvd25sb2Fkcy9qZGs4LWRvd25sb2Fkcy0yMTMzMTUxLmh0bWw=" title="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">jdk-8u181-windows-x64.exe<i class="fa fa-external-link"></i></span><br>版本信息如下:<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java version <span class="string">"1.8.0_181"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_181-b13)</span><br><span class="line">Java HotSpot(TM) 64-Bit<span class="built_in"> Server </span>VM (build 25.181-b13, mixed mode)</span><br></pre></td></tr></table></figure></p><p>3.删除hadoop生成的namenode,datanode数据文件(文件路径在自己的hdfs-site.xml配置文件内有);<br>比如hdfs-site.xml配置如下:<br><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;configuration&gt;</span></span><br><span class="line"> <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.replication<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">1</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.namenode.name.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>file:/D:<span class="meta-keyword">/hadoopdata/</span>namenode<span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.datanode.data.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>file:/D:<span class="meta-keyword">/hadoopdata/</span>datanode<span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure></p><p>那么就删除D:\hadoopdata文件夹<br>4.重新格式化HDFS<br><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -<span class="built_in">format</span></span><br></pre></td></tr></table></figure></p><p>5.再次启动hadoop进程即可成功启动.</p><p>PS:一般情况3,4步省略也可以成功启动hadoop的4个进程,如果有报错就操作一下3,4步,下面再添加一种数据文件导致错误的解决方法</p><hr><p><strong>错误三:</strong></p><p>hdaoop启动时datanode进程开启失败,系统错误代码如下:<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">java.io.IOException: Incompatible clusterIDs <span class="keyword">in</span> D:\hadoopdata\datanode: namenode clusterID = CID-6f4dc54c-ee55-465a-b484-7a917fa1af74; datanode clusterID = CID-15453d83-8724-4e54-a770-f3a96712f52d</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:775)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:300)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:416)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:395)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:573)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1362)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1327)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.<span class="builtin-name">run</span>(BPServiceActor.java:802)</span><br><span class="line">        at java.lang.Thread.<span class="builtin-name">run</span>(Thread.java:748)</span><br><span class="line">18/08/26 13:04:39 FATAL datanode.DataNode: Initialization failed <span class="keyword">for</span> Block<span class="built_in"> pool </span>&lt;registering&gt; (Datanode Uuid unassigned)<span class="built_in"> service </span><span class="keyword">to</span> localhost/127.0.0.1:9000. Exiting.</span><br><span class="line">java.io.IOException: All specified directories are failed <span class="keyword">to</span> load.</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:574)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1362)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1327)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.<span class="builtin-name">run</span>(BPServiceActor.java:802)</span><br><span class="line">        at java.lang.Thread.<span class="builtin-name">run</span>(Thread.java:748)</span><br></pre></td></tr></table></figure></p><p>首先,我们还是先讨论一下出现该错误的原因吧,<br>我们在安装hadoop的过程中多少会有些问题,也常常会多次格式化HDFS文件系统,也正是因为这种多次格式化的操作才容易导致此错误,不仅仅是在Windows系统,在Linux系统中也很常见.<br>为什么会出现这种情况呢?<br>可以回想一下,我们在操作HDFS格式化时,并没有将datanode的数据文件删掉.从而因为namenode clusterID和datanode clusterID不同而datanode进程无法开启,那要怎么解决呢?</p><p>解决方案如下:<br>1.停掉hadoop所有进程;<br>2.删除datanode文件夹,datanode文件夹具体路径在上述”错误二”中有提到过,在此就不赘述了<br>3.重新启动hadoop即可解决问题</p><p><strong>Hadoop安装方法</strong></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTE0ODI3" title="https://blog.csdn.net/u010993514/article/details/82914827">在Windows中安装Hadoop（非虚拟机安装）<i class="fa fa-external-link"></i></span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文的是在Windows10系统中运行的情况,其他版本的系统需自己尝试以下解决办法;&lt;/p&gt;
&lt;p&gt;Hadoop版本:&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly9hcmNoaXZlLmFwYWNoZS5vcmcvZGlzdC9oYWR
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://blog.niclas.cn/tags/Hadoop/"/>
    
  </entry>
  
</feed>
