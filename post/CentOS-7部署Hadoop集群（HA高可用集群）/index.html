<!DOCTYPE html><html class="theme-next mist use-motion" lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="Sy3TMdbnDCisIWfT1qLOOtS_OTgKr-wzvoYKQjJRQK0"><meta name="google-site-verification" content="qFAHaQZH5KtooP4JuggC5HDn_yKFaG_oUQI4lzdbJvs"><meta name="baidu-site-verification" content="2Efu4AQucc"><meta name="baidu-site-verification" content="CybbkpmZkE"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=6.5.0" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.5.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.5.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.5.0"><link rel="mask-icon" href="/images/logo.svg?v=6.5.0" color="#222"><link rel="manifest" href="/images/manifest.json"><meta name="msapplication-config" content="/images/browserconfig.xml"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",version:"6.5.0",sidebar:{position:"left",display:"hide",offset:12,b2t:!1,scrollpercent:!0,onmobile:!0},fancybox:!1,fastclick:!1,lazyload:!1,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="测试环境Linux系统版本：CentOS 7 64位 Hadoop版本：hadoop-2.7.3 Java版本：jdk-8u181-linux-x64 ZooKeeper版本：zookeeper-3.4.10.tar.gz 配置HA高可用集群建议先看一下完全分布式集群的部署过程，整个流程大致一样。 CentOS 7部署Hadoop集群（完全分布式）  Hadoop 组织框架Hadoop主要包括两部"><meta name="keywords" content="Hadoop,Linux,HA高可用集群,Zookeeper"><meta property="og:type" content="article"><meta property="og:title" content="CentOS 7部署Hadoop集群（HA高可用集群）"><meta property="og:url" content="https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/index.html"><meta property="og:site_name" content="Niclas"><meta property="og:description" content="测试环境Linux系统版本：CentOS 7 64位 Hadoop版本：hadoop-2.7.3 Java版本：jdk-8u181-linux-x64 ZooKeeper版本：zookeeper-3.4.10.tar.gz 配置HA高可用集群建议先看一下完全分布式集群的部署过程，整个流程大致一样。 CentOS 7部署Hadoop集群（完全分布式）  Hadoop 组织框架Hadoop主要包括两部"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/2018101111564592.jpg"><meta property="og:image" content="https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181011115137233.jpg"><meta property="og:image" content="https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181011134257285.jpg"><meta property="og:image" content="https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181012103629681.jpg"><meta property="og:image" content="https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181012103909917.jpg"><meta property="og:image" content="https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181012104647139.jpg"><meta property="og:updated_time" content="2018-12-24T13:46:23.842Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="CentOS 7部署Hadoop集群（HA高可用集群）"><meta name="twitter:description" content="测试环境Linux系统版本：CentOS 7 64位 Hadoop版本：hadoop-2.7.3 Java版本：jdk-8u181-linux-x64 ZooKeeper版本：zookeeper-3.4.10.tar.gz 配置HA高可用集群建议先看一下完全分布式集群的部署过程，整个流程大致一样。 CentOS 7部署Hadoop集群（完全分布式）  Hadoop 组织框架Hadoop主要包括两部"><meta name="twitter:image" content="https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/2018101111564592.jpg"><link rel="alternate" href="/atom.xml" title="Niclas" type="application/atom+xml"><link rel="canonical" href="https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>CentOS 7部署Hadoop集群（HA高可用集群） | Niclas</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-129104805-1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-129104805-1")</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-129104805-2"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-129104805-2")</script><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?5637b3223b9a5a6ea263a030335ce71d";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?801a98ea015efc5c911bef9c4aed3b18";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript></head><body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Niclas</span><span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">Blog</h1></div><div class="site-nav-toggle"> <button aria-label="切换导航栏"><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i></span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"> <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-categories" itemscope="" itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://blog.niclas.cn/post/CentOS-7部署Hadoop集群（HA高可用集群）/"><span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="PengShuaixin"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="Niclas"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">CentOS 7部署Hadoop集群（HA高可用集群）</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-10-12 11:00:25" itemprop="dateCreated datePublished" datetime="2018-10-12T11:00:25+08:00">2018-10-12</time> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2018-12-24 21:46:23" itemprop="dateModified" datetime="2018-12-24T21:46:23+08:00">2018-12-24</time></span> <span class="post-category"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a></span></span> <span class="post-comments-count"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-comment-o"></i></span> <a href="/post/CentOS-7部署Hadoop集群（HA高可用集群）/#comments" itemprop="discussionUrl"><span class="post-meta-item-text">评论数：</span><span class="post-comments-count valine-comment-count" data-xid="/post/CentOS-7部署Hadoop集群（HA高可用集群）/" itemprop="commentCount"></span></a></span> <span id="/post/CentOS-7部署Hadoop集群（HA高可用集群）/" class="leancloud_visitors" data-flag-title="CentOS 7部署Hadoop集群（HA高可用集群）"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span class="leancloud-visitors-count"></span></span><div class="post-symbolscount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span title="本文字数">64k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">59 分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><p>Linux系统版本：CentOS 7 64位</p><p>Hadoop版本：<span class="exturl" data-url="aHR0cHM6Ly9hcmNoaXZlLmFwYWNoZS5vcmcvZGlzdC9oYWRvb3AvY29tbW9uL2hhZG9vcC0yLjcuMy8=" title="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.3/">hadoop-2.7.3<i class="fa fa-external-link"></i></span></p><p>Java版本：<span class="exturl" data-url="aHR0cHM6Ly93d3cub3JhY2xlLmNvbS90ZWNobmV0d29yay9qYXZhL2phdmFzZS9kb3dubG9hZHMvamRrOC1kb3dubG9hZHMtMjEzMzE1MS5odG1s" title="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">jdk-8u181-linux-x64<i class="fa fa-external-link"></i></span></p><p>ZooKeeper版本：<span class="exturl" data-url="aHR0cDovL21pcnJvcnMuc2h1LmVkdS5jbi9hcGFjaGUvem9va2VlcGVyL3pvb2tlZXBlci0zLjQuMTAv" title="http://mirrors.shu.edu.cn/apache/zookeeper/zookeeper-3.4.10/">zookeeper-3.4.10.tar.gz<i class="fa fa-external-link"></i></span></p><p>配置HA高可用集群建议先看一下完全分布式集群的部署过程，整个流程大致一样。</p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTM1ODM0" title="https://blog.csdn.net/u010993514/article/details/82935834">CentOS 7部署Hadoop集群（完全分布式）<i class="fa fa-external-link"></i></span></p><hr><h1 id="Hadoop-组织框架"><a href="#Hadoop-组织框架" class="headerlink" title="Hadoop 组织框架"></a>Hadoop 组织框架</h1><p>Hadoop主要包括两部分：</p><blockquote><p>一部分是HDFS（Hadoop Distributed File System），主要负责分布式存储和计算；</p><p>另一部分是YARN（Yet Another Resource Negotiator， 从Hadoop2.0开始引入），主要负责集群的资源管理和调度。</p></blockquote><h2 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h2><blockquote><p><strong>架构图：</strong></p><p><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/2018101111564592.jpg" alt=""></p><p><strong>1. Active Name Node</strong></p><p>主Master，整个Hadoop集群只能有一个</p><p>管理HDFS文件系统的命名空间</p><p>维护元数据信息</p><p>管理副本的配置和信息（默认三个副本）</p><p>处理客户端读写请求</p><p><strong>2. Standby Name Node</strong></p><p>Active Name Node的热备节点</p><p>Active Name Node故障时可快速切换成新的Active Name Node</p><p>周期性同步edits编辑日志，定期合并fsimage与edits到本地磁盘</p><p><strong>3. Journal Node</strong></p><p>可以被Active Name Node和StandBy Name Node同时访问，用以支持Active Name Node高可用</p><p>Active Name Node在文件系统被修改时，会向Journal Node写入操作日志（edits）</p><p>Standby Name Node同步Journal Node edits日志，使集群中的更新操作可以被共享和同步。</p><p><strong>4. Data Node</strong></p><p>Slave 工作节点，集群一般会启动多个</p><p>负责存储数据块和数据块校验</p><p>执行客户端的读写请求</p><p>通过心跳机制定期向NameNode汇报运行状态和本地所有块的列表信息</p><p>在集群启动时DataNode项NameNode提供存储Block块的列表信息</p><p><strong>5. Block数据块</strong></p><p>HDSF固定的最小的存储单元（默认128M，可配置修改）</p><p>写入到HDFS的文件会被切分成Block数据块（若文件大小小于数据块大小，则不会占用整个数据块）</p><p>默认配置下，每个block有三个副本</p><p><strong>6. Client</strong></p><p>与Name Node交互获取文件的元数据信息</p><p>与Data Node，读取或者写入数据</p><p>通过客户端可以管理HDFS</p></blockquote><h2 id="YARN架构"><a href="#YARN架构" class="headerlink" title="YARN架构"></a>YARN架构</h2><blockquote><p><strong>架构图：</strong></p><p><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181011115137233.jpg" alt=""></p><p><strong>1. Resource Manager</strong></p><p>整个集群只有一个Master。Slave可以有多个，支持高可用</p><p>处理客户端Client请求</p><p>启动／管理／监控ApplicationMaster</p><p>监控NodeManager</p><p>资源的分配和调度</p><p><strong>2. Node Manager</strong></p><p>每个节点只有一个，一般与Data Node部署在同一台机器上且一一对应</p><p>定时向Resource Manager汇报本机资源的使用状况</p><p>处理来自Resource Manager的作业请求，为作业分配Container</p><p>处理来自Application Master的请求，启动和停止Container</p><p><strong>3. Application Master</strong></p><p>每个任务只有一个，负责任务的管理，资源的申请和任务调度</p><p>与Resource Manager协商，为任务申请资源</p><p>与Node Manager通信，启动／停止任务</p><p>监控任务的运行状态和失败处理</p><p><strong>4. Container</strong></p><p>任务运行环境的抽象，只有在分配任务时才会抽象生成一个Container</p><p>负责任务运行资源和环境的维护（节点，内存，CPU）</p><p>负责任务的启动</p><p>虽然在架构图中没有画出，但Hadoop高可用都是基于Zookeeper来实现的。如NameNode高可用，Block高可用，ResourceManager高可用等</p><p>以上部分内容来自：<span class="exturl" data-url="aHR0cHM6Ly9iYWlqaWFoYW8uYmFpZHUuY29tL3M/aWQ9MTU4OTE3NTU1NDI0NjEwMTYxOSZhbXA7d2ZyPXNwaWRlciZhbXA7Zm9yPXBj" title="https://baijiahao.baidu.com/s?id=1589175554246101619&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1589175554246101619&amp;wfr=spider&amp;for=pc<i class="fa fa-external-link"></i></span></p></blockquote><hr><h1 id="HA集群部署规划"><a href="#HA集群部署规划" class="headerlink" title="HA集群部署规划"></a>HA集群部署规划</h1><table><thead><tr><th style="text-align:center">主机名称</th><th style="text-align:center">IP地址</th><th style="text-align:center">用户名称</th><th style="text-align:center">进程</th><th style="text-align:center">安装的软件</th></tr></thead><tbody><tr><td style="text-align:center">node200</td><td style="text-align:center">192.168.33.200</td><td style="text-align:center">hadoop</td><td style="text-align:center">NameNode（Active）、ResourceManager（StandBy）、ZKFC、JobHistoryServer</td><td style="text-align:center">JDK、Hadoop</td></tr><tr><td style="text-align:center">node201</td><td style="text-align:center">192.168.33.201</td><td style="text-align:center">hadoop</td><td style="text-align:center">NameNode（StandBy）、ResourceManager（Active）、ZKFC、WebProxyServer</td><td style="text-align:center">JDK、Hadoop</td></tr><tr><td style="text-align:center">node202</td><td style="text-align:center">192.168.33.202</td><td style="text-align:center">hadoop</td><td style="text-align:center">DataNode、NodeManager、JournalNode、QuorumPeerMain</td><td style="text-align:center">JDK、Hadoop、Zookeeper</td></tr><tr><td style="text-align:center">node203</td><td style="text-align:center">192.168.33.203</td><td style="text-align:center">hadoop</td><td style="text-align:center">DataNode、NodeManager、JournalNode、QuorumPeerMain</td><td style="text-align:center">JDK、Hadoop、Zookeeper</td></tr><tr><td style="text-align:center">node204</td><td style="text-align:center">192.168.33.204</td><td style="text-align:center">hadoop</td><td style="text-align:center">DataNode、NodeManager、JournalNode、QuorumPeerMain</td><td style="text-align:center">JDK、Hadoop、Zookeeper</td></tr></tbody></table><p><strong>规划说明：</strong></p><blockquote><p>HDFS HA通常由两个NameNode组成，一个处于Active状态，另一个处于Standby状态。</p><p>Active NameNode对外提供服务，而Standby NameNode则不对外提供服务，仅同步Active NameNode的状态，以便能够在它失败时快速进行切换。</p><p>Hadoop 2.0官方提供了两种HDFS HA的解决方案，一种是NFS，另一种是QJM。这里我们使用简单的QJM。在该方案中，主备NameNode之间通过一组JournalNode同步元数据信息，一条数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode，这里还配置了一个Zookeeper集群，用于ZKFC故障转移，当Active NameNode挂掉了，会自动切换Standby NameNode为Active状态。</p><p>YARN的ResourceManager也存在单点故障问题，这个问题在hadoop-2.4.1得到了解决：有两个ResourceManager，一个是Active，一个是Standby，状态由Zookeeper进行协调。</p><p>YARN框架下的MapReduce可以开启JobHistoryServer来记录历史任务信息，否则只能查看当前正在执行的任务信息。</p><p>Zookeeper的作用是负责HDFS中NameNode主备节点的选举，和YARN框架下ResourceManaer主备节点的选举。</p><p>部分内容来自：<span class="exturl" data-url="aHR0cHM6Ly93d3cubGludXhpZGMuY29tL0xpbnV4LzIwMTYtMDgvMTM0MTgwLmh0bQ==" title="https://www.linuxidc.com/Linux/2016-08/134180.htm">https://www.linuxidc.com/Linux/2016-08/134180.htm<i class="fa fa-external-link"></i></span></p></blockquote><hr><h1 id="自动故障转移"><a href="#自动故障转移" class="headerlink" title="自动故障转移"></a>自动故障转移</h1><blockquote><p><strong>Zookeeper集群作用：</strong></p><p>一是故障监控。每个NameNode将会和Zookeeper建立一个持久session，如果NameNode失效，那么此session将会过期失效，此后Zookeeper将会通知另一个Namenode，然后触发Failover；</p><p>二是NameNode选举。ZooKeeper提供了简单的机制来实现Acitve Node选举，如果当前Active失效，Standby将会获取一个特定的排他锁，那么获取锁的Node接下来将会成为Active。</p><p><strong>ZKFC：</strong></p><p>ZKFC是一个Zookeeper的客户端，它主要用来监测和管理NameNodes的状态，每个NameNode机器上都会运行一个ZKFC程序</p><p><strong>主要职责：</strong></p><p>一是健康监控。ZKFC间歇性的ping NameNode，得到NameNode返回状态，如果NameNode失效或者不健康，那么ZKFS将会标记其为不健康；</p><p>二是Zookeeper会话管理。当本地NaneNode运行良好时，ZKFC将会持有一个Zookeeper session，如果本地NameNode为Active，它同时也持有一个“排他锁”znode，如果session过期，那么次lock所对应的znode也将被删除；</p><p>三是选举。当集群中其中一个NameNode宕机，Zookeeper会自动将另一个激活。</p><p>此处内容来自：<span class="exturl" data-url="aHR0cHM6Ly93d3cubGludXhpZGMuY29tL0xpbnV4LzIwMTYtMDgvMTM0MTgwLmh0bQ==" title="https://www.linuxidc.com/Linux/2016-08/134180.htm">https://www.linuxidc.com/Linux/2016-08/134180.htm<i class="fa fa-external-link"></i></span></p></blockquote><hr><h1 id="关于集群主机时间"><a href="#关于集群主机时间" class="headerlink" title="关于集群主机时间"></a>关于集群主机时间</h1><p>因为高可用集群的机制，<strong>各主机在集群中的时间需一致</strong>。</p><p>在下面Linux搭建前将虚拟机进行设置，设置方法如下：<br><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181011134257285.jpg" alt=""></p><p>安装完成后对每台主机的时间进行确认，确保每台主机时间一致。</p><hr><h1 id="Linux环境搭建"><a href="#Linux环境搭建" class="headerlink" title="Linux环境搭建"></a>Linux环境搭建</h1><p>按如下方法部署五台主机，主机名与IP地址的对应关系见上文<strong>集群部署规划</strong></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI0ODcx" title="https://blog.csdn.net/u010993514/article/details/82924871">VMware虚拟机安装Linux系统<i class="fa fa-external-link"></i></span></p><p>配置完成之后各主机IP、主机名与时间信息如下：（<strong>时间不一致的自己百度同步集群时间的方法</strong>）</p><p><strong>命令：</strong><br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看系统ip信息</span></span><br><span class="line">ip a</span><br><span class="line"><span class="comment">#查看系统时间</span></span><br><span class="line">date</span><br></pre></td></tr></table></figure><p></p><p><strong>执行结果：</strong><br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node200 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:6a:0e:74 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.200/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe6a:e74/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@node200 ~]# date</span><br><span class="line">2018年 10月 11日 星期四 16:57:56 CST</span><br></pre></td></tr></table></figure><p></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node201 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:60:36:3c brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.201/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe60:363c/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@node201 ~]# date</span><br><span class="line">2018年 10月 11日 星期四 16:57:48 CST</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node202 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:41:4a:f4 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.202/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe41:4af4/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@node202 ~]# date</span><br><span class="line">2018年 10月 11日 星期四 16:58:00 CST</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node203 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:53:27:40 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.203/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe53:2740/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@node203 ~]# date</span><br><span class="line">2018年 10月 11日 星期四 16:58:01 CST</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node204 ~]#<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 00:0c:29:6e:ad:fa brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.33.204/24 brd 192.168.33.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe6e:adfa/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@node204 ~]# date</span><br><span class="line">2018年 10月 11日 星期四 16:57:54 CST</span><br></pre></td></tr></table></figure><p><strong>网络测试：</strong></p><p>配置完成之后测试各主机网络互通情况，在每台主机上执行下面两条命令，运行过程中按Ctrl+C可以终止进程，下面就不贴测试效果了<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ping 192.168.33.1</span><br><span class="line">ping www.baidu.com</span><br></pre></td></tr></table></figure><p></p><hr><h1 id="配置Java环境"><a href="#配置Java环境" class="headerlink" title="配置Java环境"></a>配置Java环境</h1><p><strong>node200、node201、node202、node203、node204都需要安装</strong></p><p>为上面安装的系统配置Java环境变量，本文中就写关键配置步骤与执行命令了，想了解详细的配置过程可以查看：</p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTI2NTE0" title="https://blog.csdn.net/u010993514/article/details/82926514">Linux系统下安装Java环境<i class="fa fa-external-link"></i></span></p><p>为了方便，本文就直接使用rpm包安装了，/etc/profile文件暂时不进行配置，到后面配置hadoop单机版时再进行配置</p><p><strong>[1-3]均使用root用户执行</strong></p><p>1、将安装包jdk-8u181-linux-x64.rpm上传到/usr/local目录下</p><p>2、安装rpm包，先设置权限，然后执行rpm命令安装<br></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod <span class="number">755</span> /usr/local/jdk<span class="number">-8</span>u181-linux-x64.rpm</span><br><span class="line">rpm -ivh /usr/local/jdk<span class="number">-8</span>u181-linux-x64.rpm</span><br></pre></td></tr></table></figure><p></p><p>3、校验安装情况<br></p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -<span class="built_in">version</span></span><br></pre></td></tr></table></figure><p></p><hr><h1 id="安装单机版Hadoop"><a href="#安装单机版Hadoop" class="headerlink" title="安装单机版Hadoop"></a>安装单机版Hadoop</h1><p><strong>node200、node201、node202、node203、node204都需要安装</strong></p><p>详细步骤查看：Hadoop部署（三）——CentOS 7部署Hadoop（单机版），这里只简单介绍安装步骤</p><p><strong>[1-5]均使用root用户执行</strong></p><p>1、将压缩包hadoop-2.7.3.tar.gz上传到/usr/local目录下</p><p>2、解压压缩包，进入/usr/local目录，对文件夹重命名<br></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf /usr/local/hadoop<span class="number">-2.7</span><span class="number">.3</span>.tar.gz</span><br><span class="line">cd /usr/local</span><br><span class="line">mv hadoop<span class="number">-2.7</span><span class="number">.3</span> hadoop</span><br></pre></td></tr></table></figure><p></p><p>3、创建hadoop用户和hadoop用户组，并设置hadoop用户密码<br></p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">useradd hadoop</span></span><br><span class="line"><span class="attribute">passwd hadoop</span></span><br></pre></td></tr></table></figure><p></p><p>4、为hadoop用户添加sudo权限<br></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>sudoers</span><br></pre></td></tr></table></figure><p></p><p>在root用户下面一行加上hadoop ALL=(ALL) ALL，保存并退出（这里需要用wq!强制保存退出）<br></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Next comes the main part: which users can run what software on</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># which machines (the sudoers file can be shared between multiple</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># systems).</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Syntax:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># user MACHINE=COMMANDS</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># The COMMANDS section may have other options added to it.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allow root to run any commands anywhere</span></span></span><br><span class="line">root    ALL=(ALL)   ALL</span><br><span class="line">hadoop  ALL=(ALL)   ALL</span><br></pre></td></tr></table></figure><p></p><p>5、将hadoop文件夹的主：组设置成hadoop，/usr目录与/usr/local目录所属主：组均为root，默认权限为755，也就是说其他用户（hadoop）没有写入（w）权限，在这里我们需要将这两个目录其他用户的权限设置为7<br></p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">chown</span> -R hadoop:hadoop hadoop</span><br><span class="line"><span class="keyword">chmod</span> <span class="number">757</span> /usr</span><br><span class="line"><span class="keyword">chmod</span> <span class="number">757</span> /usr/<span class="keyword">local</span></span><br></pre></td></tr></table></figure><p></p><hr><h1 id="Zookeeper集群安装"><a href="#Zookeeper集群安装" class="headerlink" title="Zookeeper集群安装"></a>Zookeeper集群安装</h1><p><strong>在node202、node203、node204上安装</strong></p><p>Zookeeper是一个开源分布式协调服务，其独特的Leader-Follower集群结构，很好的解决了分布式单点问题。目前主要用于诸如：统一命名服务、配置管理、锁服务、集群管理等场景。大数据应用中主要使用Zookeeper的集群管理功能。</p><p><strong>[1-5]均使用root用户执行</strong></p><p>1、将压缩包zookeeper-3.4.10.tar.gz上传到node202的/usr/local目录下</p><p>2、解压压缩包，进入/usr/local目录，对文件夹重命名<br></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf /usr/local/zookeeper<span class="number">-3.4</span><span class="number">.10</span>.tar.gz</span><br><span class="line">cd /usr/local</span><br><span class="line">mv zookeeper<span class="number">-3.4</span><span class="number">.10</span> zookeeper</span><br></pre></td></tr></table></figure><p></p><p>3、修改zookeeper的配置文件，命令如下：<br></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/zookeeper/conf/</span><br><span class="line">cp zoo_sample<span class="selector-class">.cfg</span> zoo.cfg</span><br><span class="line">vi zoo.cfg</span><br></pre></td></tr></table></figure><p></p><p>配置文件如下：<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 客户端心跳时间(毫秒)</span></span><br><span class="line"><span class="attribute">tickTime</span>=2000</span><br><span class="line"><span class="comment"># 允许心跳间隔的最大时间</span></span><br><span class="line"><span class="attribute">initLimit</span>=10</span><br><span class="line"><span class="comment"># 同步时限</span></span><br><span class="line"><span class="attribute">syncLimit</span>=5</span><br><span class="line"><span class="comment"># 数据存储目录</span></span><br><span class="line"><span class="attribute">dataDir</span>=/usr/local/zookeeperdata</span><br><span class="line"><span class="comment"># 数据日志存储目录</span></span><br><span class="line"><span class="attribute">dataLogDir</span>=/usr/local/tmp/zookeeperlogs</span><br><span class="line"><span class="comment"># 端口号</span></span><br><span class="line"><span class="attribute">clientPort</span>=2181</span><br><span class="line"><span class="comment"># 集群节点和服务端口配置</span></span><br><span class="line">server.<span class="attribute">1</span>=node202:2888:3888</span><br><span class="line">server.<span class="attribute">2</span>=node203:2888:3888</span><br><span class="line">server.<span class="attribute">3</span>=node204:2888:3888</span><br><span class="line"><span class="comment"># 以下为优化配置</span></span><br><span class="line"><span class="comment"># 服务器最大连接数，默认为10，改为0表示无限制</span></span><br><span class="line"><span class="attribute">maxClientCnxns</span>=0</span><br><span class="line"><span class="comment"># 快照数</span></span><br><span class="line">autopurge.<span class="attribute">snapRetainCount</span>=3</span><br><span class="line"><span class="comment"># 快照清理时间，默认为0</span></span><br><span class="line">autopurge.<span class="attribute">purgeInterval</span>=1</span><br></pre></td></tr></table></figure><p></p><p>3、修改完zookeeper的配置文件，将<strong>node202</strong>上的zookeeper上传到<strong>其他两台</strong>服务器：<br></p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@node202 conf]<span class="comment"># scp -r /usr/local/zookeeper 192.168.33.203:/usr/local/</span></span><br><span class="line">[root@node202 conf]<span class="comment"># scp -r /usr/local/zookeeper 192.168.33.204:/usr/local/</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#这儿输入yes回车</span></span><br><span class="line">Are you sure you want <span class="keyword">to</span> <span class="keyword">continue</span> connecting (<span class="literal">yes</span>/<span class="literal">no</span>)? <span class="literal">yes</span></span><br><span class="line"><span class="comment">#这里输入远程主机的root密码</span></span><br><span class="line">root@<span class="number">192.168</span>.<span class="number">33.204</span><span class="string">'s password:</span></span><br></pre></td></tr></table></figure><p></p><p>4、在三台主机上创建zookeeper数据存储目录：<br></p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /usr/<span class="built_in">local</span>/zookeeperdata</span><br></pre></td></tr></table></figure><p></p><p>在文件夹下面创建一个文件，叫myid，并且在文件里写入server.X对应的X<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 集群节点和服务端口配置</span></span><br><span class="line">server.<span class="attribute">1</span>=node202:2888:3888</span><br><span class="line">server.<span class="attribute">2</span>=node203:2888:3888</span><br><span class="line">server.<span class="attribute">3</span>=node204:2888:3888</span><br></pre></td></tr></table></figure><p></p><p>上述配置中<strong>node202是1，node203是2，node204是3</strong>，所以按如下操作：</p><p>在<strong>node202</strong> 上执行：<br></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo <span class="string">"1"</span> &gt; <span class="regexp">/usr/</span>local<span class="regexp">/zookeeperdata/myi</span>d</span><br></pre></td></tr></table></figure><p></p><p>在<strong>node203</strong> 上执行：<br></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo <span class="string">"2"</span> &gt; <span class="regexp">/usr/</span>local<span class="regexp">/zookeeperdata/myi</span>d</span><br></pre></td></tr></table></figure><p></p><p>在<strong>node204</strong> 上执行：<br></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo <span class="string">"3"</span> &gt; <span class="regexp">/usr/</span>local<span class="regexp">/zookeeperdata/myi</span>d</span><br></pre></td></tr></table></figure><p></p><p>5、将zookeeper文件夹的主：组设置成hadoop<br></p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R <span class="string">hadoop:</span>hadoop <span class="regexp">/usr/</span>local/zookeeper</span><br><span class="line">chown -R <span class="string">hadoop:</span>hadoop <span class="regexp">/usr/</span>local/zookeeperdata</span><br></pre></td></tr></table></figure><p></p><hr><h1 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h1><p><strong>node200、node201、node202、node203、node204都需要配置，第2步有所区别</strong></p><p><strong>[1-3]均使用root用户执行</strong></p><p>1、编辑/etc/profile文件<br></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">vi</span> /etc/<span class="keyword">profile</span></span><br></pre></td></tr></table></figure><p></p><p>2、在末尾加上如下代码</p><p><strong>node200、node201添加如下代码：</strong><br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_181-amd64</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/usr/local/hadoop</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$JAVA_HOME</span>/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JRE_HOME</span>=<span class="variable">$JAVA_HOME</span>/jre</span><br></pre></td></tr></table></figure><p></p><p><strong>node202、node203、node204添加如下代码：</strong><br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_181-amd64</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/usr/local/hadoop</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">ZOOKEEPER_HOME</span>=/usr/local/zookeeper</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$JAVA_HOME</span>/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZOOKEEPER_HOME/bin:$PATH</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JRE_HOME</span>=<span class="variable">$JAVA_HOME</span>/jre</span><br></pre></td></tr></table></figure><p></p><p>3、配置完环境变量之后保存退出，让环境变量立即生效<br></p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span> <span class="regexp">/etc/</span>profile</span><br></pre></td></tr></table></figure><p></p><h1 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h1><p><strong>node200、node201、node202、node203、node204都需要配置</strong></p><p>CentOS 7使用的是firewalld作为防火墙，与CentOS 6 有所不同</p><p><strong>下面三步均使用root用户执行</strong></p><p>查看防火墙状态：<br></p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">systemctl status firewalld</span></span><br></pre></td></tr></table></figure><p></p><p>关闭防火墙：<br></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">stop</span> firewalld</span><br></pre></td></tr></table></figure><p></p><p>关闭防火墙开机自动启动：<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="builtin-name">disable</span> firewalld</span><br></pre></td></tr></table></figure><p></p><p>更多详情可以了解：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMzMzQ2" title="https://blog.csdn.net/u010993514/article/details/82933346">CentOS 7部署Hadoop（伪分布式）<i class="fa fa-external-link"></i></span></p><hr><h1 id="修改hosts文件"><a href="#修改hosts文件" class="headerlink" title="修改hosts文件"></a>修改hosts文件</h1><p>修改所有主机的/etc/hosts文件，这里使用root用户操作<br></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>hosts</span><br></pre></td></tr></table></figure><p></p><p>在文件最后面加上：<br></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.200</span>    <span class="selector-tag">node200</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.201</span>    <span class="selector-tag">node201</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.202</span>    <span class="selector-tag">node202</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.203</span>    <span class="selector-tag">node203</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.33</span><span class="selector-class">.204</span>    <span class="selector-tag">node204</span></span><br></pre></td></tr></table></figure><p></p><p><strong>注意：IP后面是Tab制表符，而不是空格，这里配置完后最好测试一下网络。如果复制粘贴配置完后无法ping通，可能是IP地址后面的空格问题。</strong></p><p>以下为测试方法：<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ping node200</span><br><span class="line">ping node201</span><br><span class="line">ping node202</span><br><span class="line">ping node203</span><br><span class="line">ping node204</span><br></pre></td></tr></table></figure><p></p><hr><p><strong>配置到这里，我们切换到hadoop用户，使用hadoop用户进行下面的操作</strong></p><hr><h1 id="配置SSH免密登录"><a href="#配置SSH免密登录" class="headerlink" title="配置SSH免密登录"></a>配置SSH免密登录</h1><p>具体方法参照：</p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyMDgzMDI3" title="https://blog.csdn.net/u010993514/article/details/82083027">Linux系统配置SSH免密登录(多主机互通)<i class="fa fa-external-link"></i></span></p><p>这里贴关键代码，不展示操作过程：</p><p>在<strong>node200、node201、node202、node203、node204</strong>上分别操作，一路回车就可以了：<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> ~]<span class="variable">$ </span>ssh-keygen -t rsa</span><br><span class="line">[hadoop<span class="variable">@node201</span> ~]<span class="variable">$ </span>ssh-keygen -t rsa</span><br><span class="line">[hadoop<span class="variable">@node202</span> ~]<span class="variable">$ </span>ssh-keygen -t rsa</span><br><span class="line">[hadoop<span class="variable">@node203</span> ~]<span class="variable">$ </span>ssh-keygen -t rsa</span><br><span class="line">[hadoop<span class="variable">@node204</span> ~]<span class="variable">$ </span>ssh-keygen -t rsa</span><br></pre></td></tr></table></figure><p></p><p>在<strong>node200</strong>上操作：<br></p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ ssh-copy-id localhost</span><br><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ scp <span class="regexp">~/.ssh/</span>* <span class="string">node201:</span>~/.ssh</span><br><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ scp <span class="regexp">~/.ssh/</span>* <span class="string">node202:</span>~/.ssh</span><br><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ scp <span class="regexp">~/.ssh/</span>* <span class="string">node203:</span>~/.ssh</span><br><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ scp <span class="regexp">~/.ssh/</span>* <span class="string">node204:</span>~/.ssh</span><br></pre></td></tr></table></figure><p></p><hr><h1 id="修改Hadoop配置文件"><a href="#修改Hadoop配置文件" class="headerlink" title="修改Hadoop配置文件"></a>修改Hadoop配置文件</h1><p><strong>均使用hadoop用户操作，只需要在++node200++上修改即可</strong></p><p>先进入/usr/local/hadoop/etc/hadoop/文件<br></p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ cd <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span></span><br></pre></td></tr></table></figure><p></p><p>1、修改hadoop-env.sh文件<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> hadoop]<span class="variable">$ </span>vi hadoop-env.sh</span><br></pre></td></tr></table></figure><p></p><p>找到export JAVA_HOME=${JAVA_HOME}，在前面加个#注释掉，将JAVA_HOME用路径代替，如下：<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#export JAVA_HOME=$&#123;JAVA_HOME&#125;</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_181-amd64</span><br></pre></td></tr></table></figure><p></p><p>2、修改core-site.xml文件<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> hadoop]<span class="variable">$ </span>vi core-site.xml</span><br></pre></td></tr></table></figure><p></p><p>配置文件如下：<br></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 指定hdfs的nameservices名称为mycluster，与hdfs-site.xml的HA配置相同 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">&lt;!-- 指定缓存文件存储的路径 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/tmp/hadoop/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">&lt;!-- 配置hdfs文件被永久删除前保留的时间（单位：分钟），默认值为0表明垃圾回收站功能关闭 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">&lt;!-- 指定zookeeper地址，配置HA时需要 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>node202:2181,node203:2181,node204:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>3、修改hdfs-site.xml<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> hadoop]<span class="variable">$ </span>vi hdfs-site.xml</span><br></pre></td></tr></table></figure><p></p><p>配置文件如下：<br></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定hdfs元数据存储的路径 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/hadoopdata/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 指定hdfs数据存储的路径 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/hadoopdata/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 数据备份的个数 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 关闭权限验证 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 开启WebHDFS功能（基于REST的接口服务） --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- //////////////以下为HDFS HA的配置////////////// --&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定hdfs的nameservices名称为mycluster --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 指定mycluster的两个namenode的名称分别为nn1,nn2 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置nn1,nn2的rpc通信端口 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node200:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node201:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置nn1,nn2的http通信端口 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node200:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node201:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 指定namenode元数据存储在journalnode中的路径 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://node202:8485;node203:8485;node204:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 指定journalnode日志文件存储的路径 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/tmp/journalnodelogs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 指定HDFS客户端连接active namenode的java类 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置隔离机制为ssh --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 指定秘钥的位置 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 开启自动故障转移 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>4、修改mapred-site.xml</p><p>/usr/local/hadoop/etc/hadoop文件夹中并没有mapred-site.xml文件，但提供了模板mapred-site.xml.template，将其复制一份重命名为mapred-site.xml 即可<br></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node200 hadoop]$ cp mapred-site<span class="selector-class">.xml</span><span class="selector-class">.template</span> mapred-site.xml</span><br><span class="line">[hadoop@node200 hadoop]$ vi mapred-site.xml</span><br></pre></td></tr></table></figure><p></p><p>配置文件如下：<br></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定MapReduce计算框架使用YARN --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 指定jobhistory server的rpc地址 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node200:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 指定jobhistory server的http地址 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node200:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 开启uber模式（针对小作业的优化） --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置启动uber模式的最大map数 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxmaps<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>9<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置启动uber模式的最大reduce数 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxreduces<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>5、修改yarn-site.xml<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@master200</span> hadoop]<span class="variable">$ </span>vi yarn-site.xml</span><br></pre></td></tr></table></figure><p></p><p>配置文件如下：<br></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- NodeManager上运行的附属服务，需配置成mapreduce_shuffle才可运行MapReduce程序 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置Web Application Proxy安全代理（防止yarn被攻击） --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.web-proxy.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node201:8888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 开启日志 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置日志删除时间为7天，-1为禁用，单位为秒 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 修改日志目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/tmp/hadooplogs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> 	</span><br><span class="line"><span class="comment">&lt;!--配置nodemanager可用的资源内存 </span></span><br><span class="line"><span class="comment">	&lt;property&gt;</span></span><br><span class="line"><span class="comment">		&lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;</span></span><br><span class="line"><span class="comment">		&lt;value&gt;2048&lt;/value&gt;</span></span><br><span class="line"><span class="comment">	&lt;/property&gt;</span></span><br><span class="line"><span class="comment">	配置nodemanager可用的资源CPU </span></span><br><span class="line"><span class="comment">	&lt;property&gt;</span></span><br><span class="line"><span class="comment">		&lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;</span></span><br><span class="line"><span class="comment">		&lt;value&gt;2&lt;/value&gt;</span></span><br><span class="line"><span class="comment">	&lt;/property&gt; </span></span><br><span class="line"><span class="comment"> --&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- //////////////以下为YARN HA的配置////////////// --&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 开启YARN HA --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 启用自动故障转移 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 指定YARN HA的名称 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarncluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 指定两个resourcemanager的名称 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置rm1，rm2的主机 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node201<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node200<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置YARN的http端口 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node201:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span>	</span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node200:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置zookeeper的地址 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node202:2181,node203:2181,node204:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置zookeeper的存储位置 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-state-store.parent-path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/zookeeperdata/rmstore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 开启yarn resourcemanager restart --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置resourcemanager的状态存储到zookeeper中 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 开启yarn nodemanager restart --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">	<span class="comment">&lt;!-- 配置nodemanager IPC的通信端口 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:45454<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>6、修改slaves文件<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> hadoop]<span class="variable">$ </span>vi slaves</span><br></pre></td></tr></table></figure><p></p><p>配置文件如下：<br></p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">node202</span></span><br><span class="line"><span class="symbol">node203</span></span><br><span class="line"><span class="symbol">node204</span></span><br></pre></td></tr></table></figure><p></p><p><strong>上述关键的配置文件我已经上传至：</strong><br><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1BlbmdTaHVhaXhpbi9oYWRvb3AtMi43LjNfY2VudG9zNw==" title="https://github.com/PengShuaixin/hadoop-2.7.3_centos7">https://github.com/PengShuaixin/hadoop-2.7.3_centos7<i class="fa fa-external-link"></i></span></p><p>可以直接下载下来，通过上传到Linux直接覆盖原来文件的方式进行配置</p><p>7、通过scp将配置文件上传到其他主机<br></p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@node</span>200 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node201:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br><span class="line">[hadoop<span class="meta">@node</span>200 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node202:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br><span class="line">[hadoop<span class="meta">@node</span>200 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node203:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br><span class="line">[hadoop<span class="meta">@node</span>200 hadoop]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>* <span class="string">node204:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop</span><br></pre></td></tr></table></figure><p></p><hr><h1 id="Hadoop集群的初始化"><a href="#Hadoop集群的初始化" class="headerlink" title="Hadoop集群的初始化"></a>Hadoop集群的初始化</h1><p>1、启动zookeeper集群（<strong>分别在node202、node203和node204上执行</strong>）<br></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer<span class="selector-class">.sh</span> start</span><br></pre></td></tr></table></figure><p></p><p>ps：zookeeper其他命令<br></p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看状态</span></span><br><span class="line">zkServer.<span class="keyword">sh </span>status</span><br><span class="line"><span class="comment">#关闭</span></span><br><span class="line">zkServer.<span class="keyword">sh </span>stop</span><br></pre></td></tr></table></figure><p></p><p>启动后查看状态如下：<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#node202</span></span><br><span class="line">[hadoop@node202 ~]$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/<span class="built_in">..</span>/conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line"><span class="comment">#node203</span></span><br><span class="line">[hadoop@node203 ~]$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/<span class="built_in">..</span>/conf/zoo.cfg</span><br><span class="line">Mode: leader</span><br><span class="line"></span><br><span class="line"><span class="comment">#node204</span></span><br><span class="line">[hadoop@node204 ~]$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/<span class="built_in">..</span>/conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line"><span class="comment">#只有一台主机为leader，剩下的都是follower</span></span><br><span class="line"><span class="comment">#zookeeper配置的主机数一般为2n+1台，且最少需要3台</span></span><br></pre></td></tr></table></figure><p></p><p>2、格式化ZKFC（在node200上执行）<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> ~]<span class="variable">$ </span>hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure><p></p><p>出现如下代码说明执行成功：<br></p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">11</span> INFO tools.<span class="string">DFSZKFailoverController:</span> Failover controller configured <span class="keyword">for</span> NameNode NameNode at node200/<span class="number">192.168</span><span class="number">.33</span><span class="number">.200</span>:<span class="number">9000</span></span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>zookeeper.version=<span class="number">3.4</span><span class="number">.6</span><span class="number">-1569965</span>, built on <span class="number">02</span><span class="regexp">/20/</span><span class="number">2014</span> <span class="number">09</span>:<span class="number">09</span> GMT</span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>host.name=node200</span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>java.version=<span class="number">1.8</span><span class="number">.0</span>_181</span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>java.vendor=Oracle Corporation</span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>java.home=<span class="regexp">/usr/</span>java<span class="regexp">/jdk1.8.0_181-amd64/</span>jre</span><br><span class="line"><span class="number">18</span><span class="regexp">/10/</span><span class="number">12</span> <span class="number">09</span>:<span class="number">19</span>:<span class="number">12</span> INFO zookeeper.<span class="string">ZooKeeper:</span> Client <span class="string">environment:</span>java.<span class="keyword">class</span>.path=<span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jaxb-impl-2.2.3-1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jaxb-api-2.2.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/stax-api-1.0-2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/activation-1.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jackson-core-asl-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jackson-mapper-asl-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jackson-jaxrs-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jackson-xc-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jersey-server-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/asm-3.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/log4j-1.2.17.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jets3t-0.9.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/httpclient-4.2.5.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/httpcore-4.2.5.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/java-xmlbuilder-0.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-lang-2.6.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-configuration-1.6.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-digester-1.8.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-beanutils-1.7.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-beanutils-core-1.8.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/slf4j-api-1.7.10.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/slf4j-log4j12-1.7.10.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/avro-1.7.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/paranamer-2.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/snappy-java-1.0.4.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-compress-1.4.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/xz-1.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/protobuf-java-2.5.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/gson-2.2.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/hadoop-auth-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/apacheds-kerberos-codec-2.0.0-M15.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/apacheds-i18n-2.0.0-M15.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/api-asn1-api-1.0.0-M20.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/api-util-1.0.0-M20.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/zookeeper-3.4.6.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/netty-3.6.2.Final.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/curator-framework-2.7.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/curator-client-2.7.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jsch-0.1.42.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/curator-recipes-2.7.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/htrace-core-3.1.0-incubating.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/junit-4.11.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/hamcrest-core-1.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/mockito-all-1.8.5.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/hadoop-annotations-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/guava-11.0.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jsr305-3.0.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-cli-1.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-math3-3.1.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/xmlenc-0.52.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-httpclient-3.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-logging-1.1.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-codec-1.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-io-2.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-net-3.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/commons-collections-3.2.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/servlet-api-2.5.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jetty-6.1.26.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jetty-util-6.1.26.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jsp-api-2.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jersey-core-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jersey-json-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>lib<span class="regexp">/jettison-1.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>hadoop-common<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>common<span class="regexp">/hadoop-common-2.7.3-tests.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/common/</span>hadoop-nfs<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span><span class="string">hdfs:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-codec<span class="number">-1.4</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>log4j<span class="number">-1.2</span><span class="number">.17</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-logging<span class="number">-1.1</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>netty<span class="number">-3.6</span><span class="number">.2</span>.Final.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>guava<span class="number">-11.0</span><span class="number">.2</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jsr305<span class="number">-3.0</span><span class="number">.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-cli<span class="number">-1.2</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>xmlenc<span class="number">-0.52</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-io<span class="number">-2.4</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>servlet-api<span class="number">-2.5</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jetty<span class="number">-6.1</span><span class="number">.26</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jetty-util<span class="number">-6.1</span><span class="number">.26</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jersey-core<span class="number">-1.9</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jackson-core-asl<span class="number">-1.9</span><span class="number">.13</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jackson-mapper-asl<span class="number">-1.9</span><span class="number">.13</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>jersey-server<span class="number">-1.9</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>asm<span class="number">-3.2</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-lang<span class="number">-2.6</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>protobuf-java<span class="number">-2.5</span><span class="number">.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>htrace-core<span class="number">-3.1</span><span class="number">.0</span>-incubating.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>commons-daemon<span class="number">-1.0</span><span class="number">.13</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>netty-all<span class="number">-4.0</span><span class="number">.23</span>.Final.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>xercesImpl<span class="number">-2.9</span><span class="number">.1</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>xml-apis<span class="number">-1.3</span><span class="number">.04</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/lib/</span>leveldbjni-all<span class="number">-1.8</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/hadoop-hdfs-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/hdfs/</span>hadoop-hdfs<span class="number">-2.7</span><span class="number">.3</span>-tests.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>hdfs<span class="regexp">/hadoop-hdfs-nfs-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/zookeeper-3.4.6-tests.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-lang-2.6.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/guava-11.0.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jsr305-3.0.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-logging-1.1.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/protobuf-java-2.5.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-cli-1.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/log4j-1.2.17.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jaxb-api-2.2.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/stax-api-1.0-2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/activation-1.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-compress-1.4.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/xz-1.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/servlet-api-2.5.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-codec-1.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jetty-util-6.1.26.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jersey-core-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jersey-client-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jackson-core-asl-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jackson-mapper-asl-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jackson-jaxrs-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jackson-xc-1.9.13.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/guice-servlet-3.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/guice-3.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/javax.inject-1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/aopalliance-1.0.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-io-2.4.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jersey-server-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/asm-3.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jersey-json-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jettison-1.1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jaxb-impl-2.2.3-1.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jersey-guice-1.9.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/zookeeper-3.4.6.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/netty-3.6.2.Final.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/leveldbjni-all-1.8.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/commons-collections-3.2.2.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>lib<span class="regexp">/jetty-6.1.26.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-api<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-common-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-server-common<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-server-nodemanager-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-server-web-proxy<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-server-resourcemanager<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-server-tests-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-client<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-applications-distributedshell<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>yarn<span class="regexp">/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/yarn/</span>hadoop-yarn-registry<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>protobuf-java<span class="number">-2.5</span><span class="number">.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>avro<span class="number">-1.7</span><span class="number">.4</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>jackson-core-asl<span class="number">-1.9</span><span class="number">.13</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>jackson-mapper-asl<span class="number">-1.9</span><span class="number">.13</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>paranamer<span class="number">-2.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>snappy-java<span class="number">-1.0</span><span class="number">.4</span><span class="number">.1</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>commons-compress<span class="number">-1.4</span><span class="number">.1</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>xz<span class="number">-1.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>hadoop-annotations<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>commons-io<span class="number">-2.4</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>jersey-core<span class="number">-1.9</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>jersey-server<span class="number">-1.9</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>asm<span class="number">-3.2</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>log4j<span class="number">-1.2</span><span class="number">.17</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>netty<span class="number">-3.6</span><span class="number">.2</span>.Final.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>leveldbjni-all<span class="number">-1.8</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>guice<span class="number">-3.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>javax.inject<span class="number">-1.</span><span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>aopalliance<span class="number">-1.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>jersey-guice<span class="number">-1.9</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>guice-servlet<span class="number">-3.0</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>junit<span class="number">-4.11</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/lib/</span>hamcrest-core<span class="number">-1.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-client-core-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/mapreduce/</span>hadoop-mapreduce-client-common<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-client-shuffle-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/mapreduce/</span>hadoop-mapreduce-client-app<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-client-hs-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/mapreduce/</span>hadoop-mapreduce-client-jobclient<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/share/</span>hadoop<span class="regexp">/mapreduce/</span>hadoop-mapreduce-examples<span class="number">-2.7</span><span class="number">.3</span>.<span class="string">jar:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/contrib/</span>capacity-scheduler<span class="comment">/*.jar</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop/lib/native</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:java.compiler=&lt;NA&gt;</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:os.name=Linux</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:os.arch=amd64</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:os.version=3.10.0-862.el7.x86_64</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:user.name=hadoop</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=node202:2181,node203:2181,node204:2181 sessionTimeout=5000 watcher=org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef@57a3af25</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ClientCnxn: Opening socket connection to server node202/192.168.33.202:2181. Will not attempt to authenticate using SASL (unknown error)</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ClientCnxn: Socket connection established to node202/192.168.33.202:2181, initiating session</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ClientCnxn: Session establishment complete on server node202/192.168.33.202:2181, sessionid = 0x16665c138780001, negotiated timeout = 5000</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO ha.ActiveStandbyElector: Successfully created /hadoop-ha/mycluster in ZK.</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ZooKeeper: Session: 0x16665c138780001 closed</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 WARN ha.ActiveStandbyElector: Ignoring stale result from old client with sessionId 0x16665c138780001</span></span><br><span class="line"><span class="comment">18/10/12 09:19:12 INFO zookeeper.ClientCnxn: EventThread shut down</span></span><br></pre></td></tr></table></figure><p></p><p>3、启动journalnode（<strong>分别在node202、node203和node204上执行</strong>）<br></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon<span class="selector-class">.sh</span> start journalnode</span><br></pre></td></tr></table></figure><p></p><p>执行过程如下：<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node202 ~]$ hadoop-daemon.sh start journalnode</span><br><span class="line">starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node202.out</span><br><span class="line">[hadoop@node202 ~]$ jps</span><br><span class="line">1508 QuorumPeerMain</span><br><span class="line">3239 Jps</span><br><span class="line">3182 JournalNode</span><br><span class="line"> </span><br><span class="line">[hadoop@node203 ~]$ hadoop-daemon.sh start journalnode</span><br><span class="line">starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node203.out</span><br><span class="line">[hadoop@node203 ~]$ jps</span><br><span class="line">3289 Jps</span><br><span class="line">1484 QuorumPeerMain</span><br><span class="line">3231 JournalNode</span><br><span class="line"> </span><br><span class="line">[hadoop@node204 ~]$ hadoop-daemon.sh start journalnode</span><br><span class="line">starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node204.out</span><br><span class="line">[hadoop@node204 ~]$ jps</span><br><span class="line">3296 Jps</span><br><span class="line">1490 QuorumPeerMain</span><br><span class="line">3237 JournalNode</span><br><span class="line"> </span><br><span class="line"><span class="comment">#这里用jps命令确认JournalNode进程启动情况</span></span><br><span class="line"><span class="comment">#QuorumPeerMain是第1步操作启动的zookeeper的进程</span></span><br></pre></td></tr></table></figure><p></p><p>4、格式化HDFS（<strong>在node200上执行</strong>）<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> ~]<span class="variable">$ </span>hdfs namenode -format</span><br></pre></td></tr></table></figure><p></p><p>执行出现如下代码说明执行成功：<br></p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node200 ~]$ hdfs namenode -format</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">22</span> INFO namenode.<span class="symbol">NameNode:</span> <span class="symbol">STARTUP_MSG:</span> </span><br><span class="line">/************************************************************</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span> Starting NameNode</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   host = node200/<span class="number">192.168</span>.<span class="number">33.200</span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   args = [-format]</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   version = <span class="number">2.7</span>.<span class="number">3</span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   classpath = <span class="regexp">/usr/local</span><span class="regexp">/hadoop/etc</span><span class="regexp">/hadoop:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jaxb-impl-2.2.3-1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jaxb-api-2.2.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/stax-api-1.0-2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/activation-1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-core-asl-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-mapper-asl-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-jaxrs-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jackson-xc-1.9.13.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-server-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/asm-3.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/log4j-1.2.17.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jets3t-0.9.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/httpclient-4.2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/httpcore-4.2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/java-xmlbuilder-0.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-lang-2.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-configuration-1.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-digester-1.8.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-beanutils-1.7.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-beanutils-core-1.8.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/slf4j-api-1.7.10.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/slf4j-log4j12-1.7.10.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/avro-1.7.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/paranamer-2.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/snappy-java-1.0.4.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-compress-1.4.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/xz-1.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/protobuf-java-2.5.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/gson-2.2.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hadoop-auth-2.7.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/apacheds-kerberos-codec-2.0.0-M15.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/apacheds-i18n-2.0.0-M15.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/api-asn1-api-1.0.0-M20.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/api-util-1.0.0-M20.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/zookeeper-3.4.6.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/netty-3.6.2.Final.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-framework-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-client-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsch-0.1.42.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/curator-recipes-2.7.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/htrace-core-3.1.0-incubating.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/junit-4.11.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hamcrest-core-1.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/mockito-all-1.8.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/hadoop-annotations-2.7.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/guava-11.0.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsr305-3.0.0.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-cli-1.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-math3-3.1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/xmlenc-0.52.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-httpclient-3.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-logging-1.1.3.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-codec-1.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-io-2.4.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-net-3.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/commons-collections-3.2.2.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/servlet-api-2.5.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jetty-6.1.26.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jetty-util-6.1.26.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jsp-api-2.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-core-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jersey-json-1.9.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/lib</span><span class="regexp">/jettison-1.1.jar:/usr</span><span class="regexp">/local/hadoop</span><span class="regexp">/share/hadoop</span><span class="regexp">/common/hadoop</span>-common-<span class="number">2.7</span>.<span class="number">3</span>.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/common/hadoop-common-<span class="number">2.7</span>.<span class="number">3</span>-tests.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/common/hadoop-nfs-<span class="number">2.7</span>.<span class="number">3</span>.<span class="symbol">jar:</span>/usr/local/hadoop/share/hadoop/<span class="symbol">hdfs:</span>/usr/local/hadoop/share/hadoop/hdfs/<span class="class"><span class="keyword">lib</span>/<span class="title">commons</span>-<span class="title">codec</span>-1.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">logging</span>-1.1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">guava</span>-11.0.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jsr305</span>-3.0.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">cli</span>-1.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xmlenc</span>-0.52.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">servlet</span>-<span class="title">api</span>-2.5.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jetty</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jetty</span>-<span class="title">util</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">lang</span>-2.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">htrace</span>-<span class="title">core</span>-3.1.0-<span class="title">incubating</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">daemon</span>-1.0.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">netty</span>-<span class="title">all</span>-4.0.23.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xercesImpl</span>-2.9.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">xml</span>-<span class="title">apis</span>-1.3.04.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-2.7.3-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">hdfs</span>/<span class="title">hadoop</span>-<span class="title">hdfs</span>-<span class="title">nfs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">zookeeper</span>-3.4.6-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">lang</span>-2.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guava</span>-11.0.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jsr305</span>-3.0.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">logging</span>-1.1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">cli</span>-1.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jaxb</span>-<span class="title">api</span>-2.2.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">stax</span>-<span class="title">api</span>-1.0-2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">activation</span>-1.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">compress</span>-1.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">xz</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">servlet</span>-<span class="title">api</span>-2.5.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">codec</span>-1.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jetty</span>-<span class="title">util</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">client</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">jaxrs</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">xc</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guice</span>-<span class="title">servlet</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">guice</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">javax</span>.<span class="title">inject</span>-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">aopalliance</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">json</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jettison</span>-1.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jaxb</span>-<span class="title">impl</span>-2.2.3-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">guice</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">zookeeper</span>-3.4.6.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">collections</span>-3.2.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">lib</span>/<span class="title">jetty</span>-6.1.26.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">api</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">nodemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">web</span>-<span class="title">proxy</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">applicationhistoryservice</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">resourcemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">tests</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">client</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">server</span>-<span class="title">sharedcachemanager</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">applications</span>-<span class="title">distributedshell</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">applications</span>-<span class="title">unmanaged</span>-<span class="title">am</span>-<span class="title">launcher</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">yarn</span>/<span class="title">hadoop</span>-<span class="title">yarn</span>-<span class="title">registry</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">protobuf</span>-<span class="title">java</span>-2.5.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">avro</span>-1.7.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">core</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jackson</span>-<span class="title">mapper</span>-<span class="title">asl</span>-1.9.13.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">paranamer</span>-2.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">snappy</span>-<span class="title">java</span>-1.0.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">compress</span>-1.4.1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">xz</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">hadoop</span>-<span class="title">annotations</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">commons</span>-<span class="title">io</span>-2.4.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">core</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">server</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">asm</span>-3.2.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">log4j</span>-1.2.17.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">netty</span>-3.6.2.<span class="title">Final</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">leveldbjni</span>-<span class="title">all</span>-1.8.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">guice</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">javax</span>.<span class="title">inject</span>-1.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">aopalliance</span>-1.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">jersey</span>-<span class="title">guice</span>-1.9.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">guice</span>-<span class="title">servlet</span>-3.0.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">junit</span>-4.11.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">lib</span>/<span class="title">hamcrest</span>-<span class="title">core</span>-1.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">core</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">common</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">shuffle</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">app</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">hs</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">jobclient</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">hs</span>-<span class="title">plugins</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">examples</span>-2.7.3.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">share</span>/<span class="title">hadoop</span>/<span class="title">mapreduce</span>/<span class="title">hadoop</span>-<span class="title">mapreduce</span>-<span class="title">client</span>-<span class="title">jobclient</span>-2.7.3-<span class="title">tests</span>.<span class="title">jar</span>:/<span class="title">usr</span>/<span class="title">local</span>/<span class="title">hadoop</span>/<span class="title">contrib</span>/<span class="title">capacity</span>-<span class="title">scheduler</span>/*.<span class="title">jar</span></span></span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   build = <span class="symbol">https:</span>/<span class="regexp">/git-wip-us.apache.org/repos</span><span class="regexp">/asf/hadoop</span>.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by <span class="string">'root'</span> on <span class="number">2016</span>-<span class="number">08</span>-<span class="number">18</span><span class="symbol">T01:</span><span class="number">41</span>Z</span><br><span class="line"><span class="symbol">STARTUP_MSG:</span>   java = <span class="number">1.8</span>.<span class="number">0_181</span></span><br><span class="line">************************************************************<span class="regexp">/</span></span><br><span class="line"><span class="regexp">18/</span><span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">22</span> INFO namenode.<span class="symbol">NameNode:</span> registered UNIX signal handlers <span class="keyword">for</span> [TERM, HUP, INT]</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">22</span> INFO namenode.<span class="symbol">NameNode:</span> createNameNode [-format]</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> WARN common.<span class="symbol">Util:</span> Path /usr/local/hadoopdata/namenode should be specified <span class="keyword">as</span> a URI in configuration files. Please update hdfs configuration.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> WARN common.<span class="symbol">Util:</span> Path /usr/local/hadoopdata/namenode should be specified <span class="keyword">as</span> a URI in configuration files. Please update hdfs configuration.</span><br><span class="line">Formatting using <span class="symbol">clusterid:</span> CID-<span class="number">882887</span>d1-b39c-<span class="number">419</span>c-<span class="number">8945</span>-f9c753f516ae</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> No KeyProvider found.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> fsLock is <span class="symbol">fair:</span><span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">DatanodeManager:</span> dfs.block.invalidate.limit=<span class="number">1000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">DatanodeManager:</span> dfs.namenode.datanode.registration.ip-hostname-check=<span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> dfs.namenode.startup.delay.block.deletion.sec is set to <span class="number">000</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00.000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> The block deletion will start around <span class="number">2018</span> 十月 <span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map BlocksMap</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> <span class="number">2.0</span>% max memory <span class="number">966.7</span> MB = <span class="number">19.3</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">21</span> = <span class="number">2097152</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> dfs.block.access.token.enable=<span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> defaultReplication         = <span class="number">3</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxReplication             = <span class="number">512</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> minReplication             = <span class="number">1</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxReplicationStreams      = <span class="number">2</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> replicationRecheckInterval = <span class="number">3000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> encryptDataTransfer        = <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO blockmanagement.<span class="symbol">BlockManager:</span> maxNumBlocksToLog          = <span class="number">1000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> fsOwner             = hadoop (<span class="symbol">auth:</span>SIMPLE)</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> supergroup          = supergroup</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> isPermissionEnabled = <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Determined nameservice <span class="symbol">ID:</span> mycluster</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> HA <span class="symbol">Enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Append <span class="symbol">Enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map INodeMap</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> <span class="number">1.0</span>% max memory <span class="number">966.7</span> MB = <span class="number">9.7</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">20</span> = <span class="number">1048576</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSDirectory:</span> ACLs enabled? <span class="literal">false</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSDirectory:</span> XAttrs enabled? <span class="literal">true</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSDirectory:</span> Maximum size <span class="keyword">of</span> an <span class="symbol">xattr:</span> <span class="number">16384</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">NameNode:</span> Caching file names occuring more than <span class="number">10</span> times</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map cachedBlocks</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> <span class="number">0.25</span>% max memory <span class="number">966.7</span> MB = <span class="number">2.4</span> MB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">18</span> = <span class="number">262144</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.threshold-pct = <span class="number">0.9990000128746033</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.min.datanodes = <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> dfs.namenode.safemode.extension     = <span class="number">30000</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.window.num.buckets = <span class="number">10</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.num.users = <span class="number">10</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO metrics.<span class="symbol">TopMetrics:</span> NNTop <span class="symbol">conf:</span> dfs.namenode.top.windows.minutes = <span class="number">1</span>,<span class="number">5</span>,<span class="number">25</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Retry cache on namenode is enabled</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO namenode.<span class="symbol">FSNamesystem:</span> Retry cache will use <span class="number">0.03</span> <span class="keyword">of</span> total heap and retry cache entry expiry time is <span class="number">600000</span> millis</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> Computing capacity <span class="keyword">for</span> map NameNodeRetryCache</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> VM <span class="keyword">type</span>       = <span class="number">64</span>-bit</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> <span class="number">0.029999999329447746</span>% max memory <span class="number">966.7</span> MB = <span class="number">297.0</span> KB</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">23</span> INFO util.<span class="symbol">GSet:</span> capacity      = <span class="number">2</span>^<span class="number">15</span> = <span class="number">32768</span> entries</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO namenode.<span class="symbol">FSImage:</span> Allocated new <span class="symbol">BlockPoolId:</span> BP-<span class="number">1162737530</span>-<span class="number">192.168</span>.<span class="number">33.200</span>-<span class="number">1539308185287</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO common.<span class="symbol">Storage:</span> Storage directory /usr/local/hadoopdata/namenode has been successfully formatted.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO namenode.<span class="symbol">FSImageFormatProtobuf:</span> Saving image file /usr/local/hadoopdata/namenode/current/fsimage.ckpt_0000000000000000000 using no compression</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO namenode.<span class="symbol">FSImageFormatProtobuf:</span> Image file /usr/local/hadoopdata/namenode/current/fsimage.ckpt_0000000000000000000 <span class="keyword">of</span> size <span class="number">352</span> bytes saved in <span class="number">0</span> seconds.</span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO namenode.<span class="symbol">NNStorageRetentionManager:</span> Going to retain <span class="number">1</span> images <span class="keyword">with</span> txid &gt;= <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO util.<span class="symbol">ExitUtil:</span> Exiting <span class="keyword">with</span> status <span class="number">0</span></span><br><span class="line"><span class="number">18</span>/<span class="number">10</span>/<span class="number">12</span> <span class="number">09</span>:<span class="number">36</span>:<span class="number">25</span> INFO namenode.<span class="symbol">NameNode:</span> <span class="symbol">SHUTDOWN_MSG:</span> </span><br><span class="line">/************************************************************</span><br><span class="line"><span class="symbol">SHUTDOWN_MSG:</span> Shutting down NameNode at node200/<span class="number">192.168</span>.<span class="number">33.200</span></span><br><span class="line">************************************************************<span class="regexp">/</span></span><br></pre></td></tr></table></figure><p></p><p>5、将格式化后<strong>node200</strong>节点hadoop工作目录中的元数据目录复制到<strong>node201</strong>节点<br></p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="meta">@node</span>200 ~]$ scp -r <span class="regexp">/usr/</span>local<span class="regexp">/hadoopdata node201:/</span>usr<span class="regexp">/local/</span></span><br></pre></td></tr></table></figure><p></p><p>6、初始化完毕后可关闭journalnode（<strong>分别在node202、node203和node204上执行</strong>）<br></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon<span class="selector-class">.sh</span> stop journalnode</span><br></pre></td></tr></table></figure><p></p><hr><h1 id="Hadoop集群的启动"><a href="#Hadoop集群的启动" class="headerlink" title="Hadoop集群的启动"></a>Hadoop集群的启动</h1><p>配置了好久，看到可以启动了是不是特别开心，下面就一步步启动我们的集群吧</p><h2 id="启动步骤"><a href="#启动步骤" class="headerlink" title="启动步骤"></a>启动步骤</h2><p>1、启动zookeeper集群（<strong>分别在node202、node203和node204上执行</strong>）<br></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer<span class="selector-class">.sh</span> start</span><br></pre></td></tr></table></figure><p></p><p>在初始化过程中，如果启动了zookeeper没有关闭进程，在这里就不用重复启动了</p><p>2、启动HDFS（<strong>在node200上执行</strong>）<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> ~]<span class="variable">$ </span>start-dfs.sh</span><br></pre></td></tr></table></figure><p></p><p>此命令分别在<strong>node200、node201</strong>节点启动了<strong>NameNode</strong>和<strong>ZKFC</strong>，分别在<strong>node202、node203、node204</strong>节点启动了<strong>DataNode</strong>和<strong>JournalNode</strong>，如下所示。<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node200 ~]$ start-dfs.sh</span><br><span class="line">Starting namenodes on [node200 node201]</span><br><span class="line">node200: starting namenode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-namenode-node200.out</span><br><span class="line">node201: starting namenode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-namenode-node201.out</span><br><span class="line">node204: starting datanode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-datanode-node204.out</span><br><span class="line">node202: starting datanode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-datanode-node202.out</span><br><span class="line">node203: starting datanode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-datanode-node203.out</span><br><span class="line">Starting journal nodes [node202 node203 node204]</span><br><span class="line">node202: starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node202.out</span><br><span class="line">node204: starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node204.out</span><br><span class="line">node203: starting journalnode,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-journalnode-node203.out</span><br><span class="line">Starting ZK Failover Controllers on NN hosts [node200 node201]</span><br><span class="line">node200: starting zkfc,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-zkfc-node200.out</span><br><span class="line">node201: starting zkfc,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/hadoop-hadoop-zkfc-node201.out</span><br></pre></td></tr></table></figure><p></p><p>3、启动YARN（<strong>在node201上执行</strong>）<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node201</span> ~]<span class="variable">$ </span>start-yarn.sh</span><br></pre></td></tr></table></figure><p></p><p>此命令在<strong>node201</strong>节点启动了<strong>ResourceManager</strong>，分别在<strong>node202、node203、node204</strong>节点启动了<strong>NodeManager</strong>。<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node201 ~]$ start-yarn.sh</span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-resourcemanager-node201.out</span><br><span class="line">node202: starting nodemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-nodemanager-node202.out</span><br><span class="line">node203: starting nodemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-nodemanager-node203.out</span><br><span class="line">node204: starting nodemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-nodemanager-node204.out</span><br></pre></td></tr></table></figure><p></p><p>4、启动YARN的另一个ResourceManager（在<strong>node200</strong>执行，用于容灾）<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node200</span> ~]<span class="variable">$ </span>yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure><p></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#执行过程如下</span></span><br><span class="line">starting resourcemanager,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-resourcemanager-node200.out</span><br></pre></td></tr></table></figure><p>5、启动YARN的安全代理（在<strong>node201</strong>执行）<br></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@node201</span> ~]<span class="variable">$ </span>yarn-daemon.sh start proxyserver</span><br></pre></td></tr></table></figure><p></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#执行过程如下</span></span><br><span class="line">starting proxyserver,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/yarn-hadoop-proxyserver-node201.out</span><br></pre></td></tr></table></figure><p><strong>备注：proxyserver充当防火墙的角色，可以提高访问集群的安全性</strong></p><p>6、启动YARN的历史任务服务（在<strong>node200</strong>执行）<br></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#方法一：</span></span><br><span class="line">[hadoop@node200 ~]$ mr-jobhistory-daemon.sh start historyserver</span><br><span class="line"> </span><br><span class="line"><span class="comment">#执行过程如下</span></span><br><span class="line">starting historyserver,<span class="built_in"> logging </span><span class="keyword">to</span> /usr/local/hadoop/logs/mapred-hadoop-historyserver-node200.out</span><br><span class="line"> </span><br><span class="line"><span class="comment">#方法二：</span></span><br><span class="line">[hadoop@node200 ~]$ yarn-daemon.sh start historyserver</span><br></pre></td></tr></table></figure><p></p><p>备注：<strong>yarn-daemon.sh start historyserver</strong>已被弃用；CDH版本似乎有个问题，即mapred-site.xml配置的的mapreduce.jobhistory.address和mapreduce.jobhistory.webapp.address参数似乎不起作用，实际对应的端口号是10200和8188，而且部需要配置就可以在任意节点上开启历史任务服务。</p><h2 id="集群进程查看"><a href="#集群进程查看" class="headerlink" title="集群进程查看"></a>集群进程查看</h2><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node200 ~]$ jps</span><br><span class="line"><span class="number">5313</span> DFSZKFailoverController</span><br><span class="line"><span class="number">5842</span> ResourceManager</span><br><span class="line"><span class="number">7049</span> Jps</span><br><span class="line"><span class="number">5002</span> NameNode</span><br><span class="line"><span class="number">6733</span> JobHistoryServer</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node201 ~]$ jps</span><br><span class="line"><span class="number">4726</span> NameNode</span><br><span class="line"><span class="number">4839</span> DFSZKFailoverController</span><br><span class="line"><span class="number">6794</span> Jps</span><br><span class="line"><span class="number">5181</span> ResourceManager</span><br><span class="line"><span class="number">6110</span> WebAppProxyServer</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node202 ~]$ jps</span><br><span class="line"><span class="number">1508</span> QuorumPeerMain</span><br><span class="line"><span class="number">5111</span> NodeManager</span><br><span class="line"><span class="number">4696</span> DataNode</span><br><span class="line"><span class="number">4794</span> JournalNode</span><br><span class="line"><span class="number">6318</span> Jps</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node203 ~]$ jps</span><br><span class="line"><span class="number">5080</span> NodeManager</span><br><span class="line"><span class="number">1484</span> QuorumPeerMain</span><br><span class="line"><span class="number">4668</span> DataNode</span><br><span class="line"><span class="number">4767</span> JournalNode</span><br><span class="line"><span class="number">6303</span> Jps</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node204 ~]$ jps</span><br><span class="line"><span class="number">1490</span> QuorumPeerMain</span><br><span class="line"><span class="number">6307</span> Jps</span><br><span class="line"><span class="number">4647</span> DataNode</span><br><span class="line"><span class="number">5064</span> NodeManager</span><br><span class="line"><span class="number">4746</span> JournalNode</span><br></pre></td></tr></table></figure><h2 id="Web界面截图"><a href="#Web界面截图" class="headerlink" title="Web界面截图"></a>Web界面截图</h2><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p><strong>node200：</strong><span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMjAwOjUwMDcwLw==" title="http://192.168.33.200:50070/">http://192.168.33.200:50070<i class="fa fa-external-link"></i></span>，可看到NameNode为active状态</p><p><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181012103629681.jpg" alt=""></p><p><strong>node201：</strong><span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMjAxOjUwMDcwLw==" title="http://192.168.33.201:50070/">http://192.168.33.201:50070<i class="fa fa-external-link"></i></span>，可看到NameNode为standby状态</p><p><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181012103909917.jpg" alt=""></p><h3 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h3><p><strong>node201:</strong><span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMjAxOjgwODgvY2x1c3Rlcg==" title="http://192.168.33.201:8088/cluster">http://192.168.33.201:8088<i class="fa fa-external-link"></i></span>，可看到ResourceManager为active状态</p><p><img src="/post/CentOS-7部署Hadoop集群（HA高可用集群）/20181012104647139.jpg" alt=""></p><p><strong>node200:</strong><span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMzMuMjAwOjgwODgvY2x1c3Rlcg==" title="http://192.168.33.200:8088/cluster">http://192.168.33.200:8088<i class="fa fa-external-link"></i></span>，此时ResourceManager为standby状态，</p><p>网页无法直接访问，会自动跳转到node201的页面</p><hr><h1 id="相关推荐"><a href="#相关推荐" class="headerlink" title="相关推荐"></a>相关推荐</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTE0ODI3" title="https://blog.csdn.net/u010993514/article/details/82914827">在Windows中安装Hadoop（非虚拟机安装）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMwMzUx" title="https://blog.csdn.net/u010993514/article/details/82930351">CentOS 7部署Hadoop（单机版）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTMzMzQ2" title="https://blog.csdn.net/u010993514/article/details/82933346">CentOS 7部署Hadoop（伪分布式）<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQvYXJ0aWNsZS9kZXRhaWxzLzgyOTM1ODM0" title="https://blog.csdn.net/u010993514/article/details/82935834">CentOS 7部署Hadoop集群（完全分布式）<i class="fa fa-external-link"></i></span></p><hr><p>到这里就配置完整个集群啦，若在配置过程中遇到什么问题，欢迎在下方评论区留言一起讨论！</p></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div></div> <button id="rewardButton" disable="enable" onclick='var qr=document.getElementById("QR");"none"===qr.style.display?qr.style.display="block":qr.style.display="none"'> <span>打赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"> <img id="wechat_qr" src="/images/wechatpay.png" alt="PengShuaixin 微信支付"><p>微信支付</p></div><div id="alipay" style="display:inline-block"> <img id="alipay_qr" src="/images/alipay.png" alt="PengShuaixin 支付宝"><p>支付宝</p></div></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Hadoop/" rel="tag"><i class="fa fa-tag"></i> Hadoop</a><a href="/tags/Linux/" rel="tag"><i class="fa fa-tag"></i> Linux</a><a href="/tags/HA高可用集群/" rel="tag"><i class="fa fa-tag"></i> HA高可用集群</a><a href="/tags/Zookeeper/" rel="tag"><i class="fa fa-tag"></i> Zookeeper</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/post/CentOS-7部署Hadoop集群（完全分布式）/" rel="next" title="CentOS 7部署Hadoop集群（完全分布式）"><i class="fa fa-chevron-left"></i> CentOS 7部署Hadoop集群（完全分布式）</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/post/CentOS-7常用基本命令整理/" rel="prev" title="CentOS 7常用基本命令整理">CentOS 7常用基本命令整理<i class="fa fa-chevron-right"></i></a></div></div></footer></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">------ 本文结束------</div></div></div></article></div></div><div class="comments" id="comments"></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div id="sidebar-dimmer"></div><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap"> 文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap"> 站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="PengShuaixin"><p class="site-author-name" itemprop="name">PengShuaixin</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">14</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/index.html"><span class="site-state-item-count">5</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/index.html"><span class="site-state-item-count">27</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1BlbmdTaHVhaXhpbg==" title="GitHub &rarr; https://github.com/PengShuaixin"><i class="fa fa-fw fa-github"></i> GitHub</span></span><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5OTM1MTQ=" title="CSDN &rarr; https://blog.csdn.net/u010993514"><i class="fa fa-fw fa-globe"></i> CSDN</span></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#测试环境"><span class="nav-text">测试环境</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop-组织框架"><span class="nav-text">Hadoop 组织框架</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS架构"><span class="nav-text">HDFS架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YARN架构"><span class="nav-text">YARN架构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HA集群部署规划"><span class="nav-text">HA集群部署规划</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#自动故障转移"><span class="nav-text">自动故障转移</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#关于集群主机时间"><span class="nav-text">关于集群主机时间</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Linux环境搭建"><span class="nav-text">Linux环境搭建</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#配置Java环境"><span class="nav-text">配置Java环境</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#安装单机版Hadoop"><span class="nav-text">安装单机版Hadoop</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Zookeeper集群安装"><span class="nav-text">Zookeeper集群安装</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#配置环境变量"><span class="nav-text">配置环境变量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#关闭防火墙"><span class="nav-text">关闭防火墙</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#修改hosts文件"><span class="nav-text">修改hosts文件</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#配置SSH免密登录"><span class="nav-text">配置SSH免密登录</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#修改Hadoop配置文件"><span class="nav-text">修改Hadoop配置文件</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop集群的初始化"><span class="nav-text">Hadoop集群的初始化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop集群的启动"><span class="nav-text">Hadoop集群的启动</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#启动步骤"><span class="nav-text">启动步骤</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#集群进程查看"><span class="nav-text">集群进程查看</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Web界面截图"><span class="nav-text">Web界面截图</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS"><span class="nav-text">HDFS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YARN"><span class="nav-text">YARN</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#相关推荐"><span class="nav-text">相关推荐</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span><span class="with-love" id="animate"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">PengShuaixin</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">200k</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv" title="总访客量"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span><span class="site-pv" title="总访问量"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div><script type="text/javascript">!function(){var t=document.createElement("script");t.type="text/javascript",t.src="http://tajs.qq.com/stats?sId=66106613",t.charset="UTF-8";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script><script type="text/javascript">!function(){var t=document.createElement("script");t.type="text/javascript",t.src="http://tajs.qq.com/stats?sId=66107215",t.charset="UTF-8";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" color="0,0,0" opacity="0.3" zindex="-1" count="80" src="//cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-nest@1.0.0/canvas-nest-nomobile.min.js"></script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/js/src/utils.js?v=6.5.0"></script><script type="text/javascript" src="/js/src/motion.js?v=6.5.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=6.5.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=6.5.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=6.5.0"></script><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine/dist/Valine.min.js"></script><script type="text/javascript">var GUEST=["nick","mail","link"],guest="nick,mail,link";guest=guest.split(",").filter(function(e){return-1<GUEST.indexOf(e)}),new Valine({el:"#comments",verify:!0,notify:!1,appId:"yFTiPXVcVQ7XCx0ccCI9u9UV-gzGzoHsz",appKey:"yYG26hWbUNuiaQJBn91mWLBD",placeholder:"Just go go",avatar:"mm",meta:guest,pageSize:"10",visitor:!1})</script><script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      
        // ref: https://github.com/ForbesLindesay/unescape-html
        var unescapeHtml = function(html) {
          return String(html)
            .replace(/&quot;/g, '"')
            .replace(/&#39;/g, '\'')
            .replace(/&#x3A;/g, ':')
            // replace all the other &#x; chars
            .replace(/&#(\d+);/g, function (m, p) { return String.fromCharCode(p); })
            .replace(/&lt;/g, '<')
            .replace(/&gt;/g, '>')
            .replace(/&amp;/g, '&');
        };
      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                content = unescapeHtml(content);
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script><script>
    
    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function ({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text(counter.time + 1);
            
            Counter('put', `/classes/Counter/${counter.objectId}`, JSON.stringify({ time: { "__op":"Increment", "amount":1 } }))
            
            .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
            })
          } else {
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text('Counter not initialized! See more at console err msg.');
              console.error('ATTENTION! LeanCloud counter has security bug, see here how to solve it: https://github.com/theme-next/hexo-leancloud-counter-security. \n But you also can use LeanCloud without security, by set \'security\' option to \'false\'.');
            
          }
        })
      .fail(function ({ responseJSON }) {
        console.log('LeanCloud Counter Error:' + responseJSON.code + " " + responseJSON.error);
      });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + "yFTiPXVcVQ7XCx0ccCI9u9UV-gzGzoHsz")
        .done(function ({ api_server }) {
          var Counter = function (method, url, data) {
            return $.ajax({
              method: method,
              url: `https://${api_server}/1.1${url}`,
              headers: {
                'X-LC-Id': "yFTiPXVcVQ7XCx0ccCI9u9UV-gzGzoHsz",
                'X-LC-Key': "yYG26hWbUNuiaQJBn91mWLBD",
                'Content-Type': 'application/json',
              },
              data: data,
            });
          };
          
          addCount(Counter);
          
        })
    });
  </script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/javascript" src="/js/src/js.cookie.js?v=6.5.0"></script><script type="text/javascript" src="/js/src/scroll-cookie.js?v=6.5.0"></script><script type="text/javascript" src="/js/src/exturl.js?v=6.5.0"></script><style>.copy-btn{display:inline-block;padding:6px 12px;font-size:13px;font-weight:700;line-height:20px;color:#333;white-space:nowrap;vertical-align:middle;cursor:pointer;background-color:#eee;background-image:linear-gradient(#fcfcfc,#eee);border:1px solid #d5d5d5;border-radius:3px;user-select:none;outline:0}.highlight-wrap .copy-btn{transition:opacity .3s ease-in-out;opacity:0;padding:2px 6px;position:absolute;right:4px;top:8px}.highlight-wrap .copy-btn:focus,.highlight-wrap:hover .copy-btn{opacity:1}.highlight-wrap{position:relative}</style><script>$(".highlight").each(function(t,e){var n=$("<div>").addClass("highlight-wrap");$(e).after(n),n.append($("<button>").addClass("copy-btn").append("复制").on("click",function(t){var e=$(this).parent().find(".code").find(".line").map(function(t,e){return $(e).text()}).toArray().join("\n"),n=document.createElement("textarea");document.body.appendChild(n),n.style.position="absolute",n.style.top="0px",n.style.left="0px",n.value=e,n.select(),n.focus();var o=document.execCommand("copy");document.body.removeChild(n),o?$(this).text("复制成功"):$(this).text("复制失败"),$(this).blur()})).on("mouseleave",function(t){var e=$(this).find(".copy-btn");setTimeout(function(){e.text("复制")},300)}).append(e)})</script></body></html>